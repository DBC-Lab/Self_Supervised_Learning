nohup: ignoring input
I0630 14:51:17.611157 47538 caffe.cpp:185] Using GPUs 6
I0630 14:51:17.960543 47538 caffe.cpp:190] GPU 6: TITAN Xp
I0630 14:51:19.123097 47538 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.005
display: 100
max_iter: 1000000
lr_policy: "step"
gamma: 0.1
power: 0.75
momentum: 0.9
weight_decay: 0.0005
stepsize: 5000
snapshot: 1000
snapshot_prefix: "/shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/"
solver_mode: GPU
device_id: 6
net: "infant_train.prototxt"
regularization_type: "L2"
iter_size: 3
I0630 14:51:19.124256 47538 solver.cpp:91] Creating training net from net file: infant_train.prototxt
I0630 14:51:19.145427 47538 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0630 14:51:19.145609 47538 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0630 14:51:19.145622 47538 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer loss
I0630 14:51:19.147580 47538 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "dataT1"
  top: "dataT2"
  top: "dataSeg"
  top: "dataCp"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "trainInfant3D_list-BCP18-cp.txt"
    batch_size: 3
    shuffle: true
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "dataT1"
  bottom: "dataT2"
  top: "data"
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1a_bn"
  top: "conv1a_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a_bn"
  top: "conv1a_bn"
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "conv1a_bn"
  top: "Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "BatchNorm1"
  top: "Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "Dropout1"
  type: "Dropout"
  bottom: "Convolution2"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Convolution1"
  bottom: "Dropout1"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Concat1"
  top: "BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "BatchNorm2"
  top: "Convolution3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "Dropout2"
  type: "Dropout"
  bottom: "Convolution3"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Concat1"
  bottom: "Dropout2"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Concat2"
  top: "BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "BatchNorm3"
  top: "BatchNorm3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "BatchNorm3"
  top: "BatchNorm3"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "BatchNorm3"
  top: "Convolution4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "Dropout3"
  type: "Dropout"
  bottom: "Convolution4"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "Concat2"
  bottom: "Dropout3"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "Concat3"
  top: "conv1b_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv2"
  type: "Scale"
  bottom: "conv1b_bn"
  top: "conv1b_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1b"
  type: "ReLU"
  bottom: "conv1b_bn"
  top: "conv1b_bn"
}
layer {
  name: "conv1c"
  type: "Convolution"
  bottom: "conv1b_bn"
  top: "conv1c"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv1c"
  top: "conv1c_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv3"
  type: "Scale"
  bottom: "conv1c_bn"
  top: "conv1c_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1c"
  type: "ReLU"
  bottom: "conv1c_bn"
  top: "conv1c_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1c_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: CUDNN
  }
}
layer {
  name: "conv2a-Convolution1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2a-Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2a-BatchNorm1"
  type: "BatchNorm"
  bottom: "conv2a-Convolution1"
  top: "conv2a-BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2a-Scale1"
  type: "Scale"
  bottom: "conv2a-BatchNorm1"
  top: "conv2a-BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2a-ReLU1"
  type: "ReLU"
  bottom: "conv2a-BatchNorm1"
  top: "conv2a-BatchNorm1"
}
layer {
  name: "conv2a-Convolution2"
  type: "Convolution"
  bottom: "conv2a-BatchNorm1"
  top: "conv2a-Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2a-Dropout1"
  type: "Dropout"
  bottom: "conv2a-Convolution2"
  top: "conv2a-Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2a-Concat1"
  type: "Concat"
  bottom: "conv2a-Convolution1"
  bottom: "conv2a-Dropout1"
  top: "conv2a-Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2a-BatchNorm2"
  type: "BatchNorm"
  bottom: "conv2a-Concat1"
  top: "conv2a-BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2a-Scale2"
  type: "Scale"
  bottom: "conv2a-BatchNorm2"
  top: "conv2a-BatchNorm2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2a-ReLU2"
  type: "ReLU"
  bottom: "conv2a-BatchNorm2"
  top: "conv2a-BatchNorm2"
}
layer {
  name: "conv2a-Convolution3"
  type: "Convolution"
  bottom: "conv2a-BatchNorm2"
  top: "conv2a-Convolution3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2a-Dropout2"
  type: "Dropout"
  bottom: "conv2a-Convolution3"
  top: "conv2a-Dropout2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2a-Concat2"
  type: "Concat"
  bottom: "conv2a-Concat1"
  bottom: "conv2a-Dropout2"
  top: "conv2a-Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2a-BatchNorm3"
  type: "BatchNorm"
  bottom: "conv2a-Concat2"
  top: "conv2a-BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2a-Scale3"
  type: "Scale"
  bottom: "conv2a-BatchNorm3"
  top: "conv2a-BatchNorm3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2a-ReLU3"
  type: "ReLU"
  bottom: "conv2a-BatchNorm3"
  top: "conv2a-BatchNorm3"
}
layer {
  name: "conv2a-Convolution4"
  type: "Convolution"
  bottom: "conv2a-BatchNorm3"
  top: "conv2a-Convolution4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2a-Dropout3"
  type: "Dropout"
  bottom: "conv2a-Convolution4"
  top: "conv2a-Dropout3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2a-Concat3"
  type: "Concat"
  bottom: "conv2a-Concat2"
  bottom: "conv2a-Dropout3"
  top: "conv2a"
  concat_param {
    axis: 1
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv2a"
  top: "conv2a_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv4"
  type: "Scale"
  bottom: "conv2a_bn"
  top: "conv2a_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a_bn"
  top: "conv2a_bn"
}
layer {
  name: "conv2b"
  type: "Convolution"
  bottom: "conv2a_bn"
  top: "conv2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv2b"
  top: "conv2b_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv5_fine"
  type: "Scale"
  bottom: "conv2b_bn"
  top: "conv2b_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2b"
  type: "ReLU"
  bottom: "conv2b_bn"
  top: "conv2b_bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2b_bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: CUDNN
  }
}
layer {
  name: "conv3a"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "conv3a"
  top: "conv3a_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv6"
  type: "Scale"
  bottom: "conv3a_bn"
  top: "conv3a_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a_bn"
  top: "conv3a_bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3a_bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: CUDNN
  }
}
layer {
  name: "deconv4"
  type: "Deconvolution"
  bottom: "pool3"
  top: "deconv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "xavier"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat8"
  type: "Concat"
  bottom: "conv3a"
  bottom: "deconv4"
  top: "concat8"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "conv4-Convolution1"
  type: "Convolution"
  bottom: "concat8"
  top: "conv4-Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv4-BatchNorm1"
  type: "BatchNorm"
  bottom: "conv4-Convolution1"
  top: "conv4-BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4-Scale1"
  type: "Scale"
  bottom: "conv4-BatchNorm1"
  top: "conv4-BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4-ReLU1"
  type: "ReLU"
  bottom: "conv4-BatchNorm1"
  top: "conv4-BatchNorm1"
}
layer {
  name: "conv4-Convolution2"
  type: "Convolution"
  bottom: "conv4-BatchNorm1"
  top: "conv4-Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv4-Dropout1"
  type: "Dropout"
  bottom: "conv4-Convolution2"
  top: "conv4-Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4-Concat1"
  type: "Concat"
  bottom: "conv4-Convolution1"
  bottom: "conv4-Dropout1"
  top: "conv4-Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv4-BatchNorm2"
  type: "BatchNorm"
  bottom: "conv4-Concat1"
  top: "conv4-BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4-Scale2"
  type: "Scale"
  bottom: "conv4-BatchNorm2"
  top: "conv4-BatchNorm2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4-ReLU2"
  type: "ReLU"
  bottom: "conv4-BatchNorm2"
  top: "conv4-BatchNorm2"
}
layer {
  name: "conv4-Convolution3"
  type: "Convolution"
  bottom: "conv4-BatchNorm2"
  top: "conv4-Convolution3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv4-Dropout2"
  type: "Dropout"
  bottom: "conv4-Convolution3"
  top: "conv4-Dropout2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4-Concat2"
  type: "Concat"
  bottom: "conv4-Concat1"
  bottom: "conv4-Dropout2"
  top: "conv4-Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv4-BatchNorm3"
  type: "BatchNorm"
  bottom: "conv4-Concat2"
  top: "conv4-BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4-Scale3"
  type: "Scale"
  bottom: "conv4-BatchNorm3"
  top: "conv4-BatchNorm3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4-ReLU3"
  type: "ReLU"
  bottom: "conv4-BatchNorm3"
  top: "conv4-BatchNorm3"
}
layer {
  name: "conv4-Convolution4"
  type: "Convolution"
  bottom: "conv4-BatchNorm3"
  top: "conv4-Convolution4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv4-Dropout3"
  type: "Dropout"
  bottom: "conv4-Convolution4"
  top: "conv4-Dropout3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4-Concat3"
  type: "Concat"
  bottom: "conv4-Concat2"
  bottom: "conv4-Dropout3"
  top: "conv4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv4_bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv4_fine"
  type: "Scale"
  bottom: "conv4_bn"
  top: "conv4_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4_bn"
  top: "conv4_bn"
}
layer {
  name: "deconv5"
  type: "Deconvolution"
  bottom: "conv4_bn"
  top: "deconv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "xavier"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat16"
  type: "Concat"
  bottom: "conv2b"
  bottom: "deconv5"
  top: "concat16"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "conv5-Convolution1"
  type: "Convolution"
  bottom: "concat16"
  top: "conv5-Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5-BatchNorm1"
  type: "BatchNorm"
  bottom: "conv5-Convolution1"
  top: "conv5-BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5-Scale1"
  type: "Scale"
  bottom: "conv5-BatchNorm1"
  top: "conv5-BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5-ReLU1"
  type: "ReLU"
  bottom: "conv5-BatchNorm1"
  top: "conv5-BatchNorm1"
}
layer {
  name: "conv5-Convolution2"
  type: "Convolution"
  bottom: "conv5-BatchNorm1"
  top: "conv5-Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5-Dropout1"
  type: "Dropout"
  bottom: "conv5-Convolution2"
  top: "conv5-Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5-Concat1"
  type: "Concat"
  bottom: "conv5-Convolution1"
  bottom: "conv5-Dropout1"
  top: "conv5-Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5-BatchNorm2"
  type: "BatchNorm"
  bottom: "conv5-Concat1"
  top: "conv5-BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5-Scale2"
  type: "Scale"
  bottom: "conv5-BatchNorm2"
  top: "conv5-BatchNorm2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5-ReLU2"
  type: "ReLU"
  bottom: "conv5-BatchNorm2"
  top: "conv5-BatchNorm2"
}
layer {
  name: "conv5-Convolution3"
  type: "Convolution"
  bottom: "conv5-BatchNorm2"
  top: "conv5-Convolution3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5-Dropout2"
  type: "Dropout"
  bottom: "conv5-Convolution3"
  top: "conv5-Dropout2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5-Concat2"
  type: "Concat"
  bottom: "conv5-Concat1"
  bottom: "conv5-Dropout2"
  top: "conv5-Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5-BatchNorm3"
  type: "BatchNorm"
  bottom: "conv5-Concat2"
  top: "conv5-BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5-Scale3"
  type: "Scale"
  bottom: "conv5-BatchNorm3"
  top: "conv5-BatchNorm3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5-ReLU3"
  type: "ReLU"
  bottom: "conv5-BatchNorm3"
  top: "conv5-BatchNorm3"
}
layer {
  name: "conv5-Convolution4"
  type: "Convolution"
  bottom: "conv5-BatchNorm3"
  top: "conv5-Convolution4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5-Dropout3"
  type: "Dropout"
  bottom: "conv5-Convolution4"
  top: "conv5-Dropout3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5-Concat3"
  type: "Concat"
  bottom: "conv5-Concat2"
  bottom: "conv5-Dropout3"
  top: "conv5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5_bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv5"
  type: "Scale"
  bottom: "conv5_bn"
  top: "conv5_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5_bn"
  top: "conv5_bn"
}
layer {
  name: "conv5_2-Convolution1"
  type: "Convolution"
  bottom: "conv5_bn"
  top: "conv5_2-Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5_2-BatchNorm1"
  type: "BatchNorm"
  bottom: "conv5_2-Convolution1"
  top: "conv5_2-BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2-Scale1"
  type: "Scale"
  bottom: "conv5_2-BatchNorm1"
  top: "conv5_2-BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2-ReLU1"
  type: "ReLU"
  bottom: "conv5_2-BatchNorm1"
  top: "conv5_2-BatchNorm1"
}
layer {
  name: "conv5_2-Convolution2"
  type: "Convolution"
  bottom: "conv5_2-BatchNorm1"
  top: "conv5_2-Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5_2-Dropout1"
  type: "Dropout"
  bottom: "conv5_2-Convolution2"
  top: "conv5_2-Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5_2-Concat1"
  type: "Concat"
  bottom: "conv5_2-Convolution1"
  bottom: "conv5_2-Dropout1"
  top: "conv5_2-Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5_2-BatchNorm2"
  type: "BatchNorm"
  bottom: "conv5_2-Concat1"
  top: "conv5_2-BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2-Scale2"
  type: "Scale"
  bottom: "conv5_2-BatchNorm2"
  top: "conv5_2-BatchNorm2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2-ReLU2"
  type: "ReLU"
  bottom: "conv5_2-BatchNorm2"
  top: "conv5_2-BatchNorm2"
}
layer {
  name: "conv5_2-Convolution3"
  type: "Convolution"
  bottom: "conv5_2-BatchNorm2"
  top: "conv5_2-Convolution3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5_2-Dropout2"
  type: "Dropout"
  bottom: "conv5_2-Convolution3"
  top: "conv5_2-Dropout2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5_2-Concat2"
  type: "Concat"
  bottom: "conv5_2-Concat1"
  bottom: "conv5_2-Dropout2"
  top: "conv5_2-Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5_2-BatchNorm3"
  type: "BatchNorm"
  bottom: "conv5_2-Concat2"
  top: "conv5_2-BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2-Scale3"
  type: "Scale"
  bottom: "conv5_2-BatchNorm3"
  top: "conv5_2-BatchNorm3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2-ReLU3"
  type: "ReLU"
  bottom: "conv5_2-BatchNorm3"
  top: "conv5_2-BatchNorm3"
}
layer {
  name: "conv5_2-Convolution4"
  type: "Convolution"
  bottom: "conv5_2-BatchNorm3"
  top: "conv5_2-Convolution4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5_2-Dropout3"
  type: "Dropout"
  bottom: "conv5_2-Convolution4"
  top: "conv5_2-Dropout3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5_2-Concat3"
  type: "Concat"
  bottom: "conv5_2-Concat2"
  bottom: "conv5_2-Dropout3"
  top: "conv5_2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5_2_bn"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv5_2"
  type: "Scale"
  bottom: "conv5_2_bn"
  top: "conv5_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5a_2"
  type: "ReLU"
  bottom: "conv5_2_bn"
  top: "conv5_2_bn"
}
layer {
  name: "deconv6"
  type: "Deconvolution"
  bottom: "conv5_2_bn"
  top: "deconv6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "xavier"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat32"
  type: "Concat"
  bottom: "conv1c"
  bottom: "deconv6"
  top: "concat32"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "conv6-Convolution1"
  type: "Convolution"
  bottom: "concat32"
  top: "conv6-Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv6-BatchNorm1"
  type: "BatchNorm"
  bottom: "conv6-Convolution1"
  top: "conv6-BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv6-Scale1"
  type: "Scale"
  bottom: "conv6-BatchNorm1"
  top: "conv6-BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6-ReLU1"
  type: "ReLU"
  bottom: "conv6-BatchNorm1"
  top: "conv6-BatchNorm1"
}
layer {
  name: "conv6-Convolution2"
  type: "Convolution"
  bottom: "conv6-BatchNorm1"
  top: "conv6-Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv6-Dropout1"
  type: "Dropout"
  bottom: "conv6-Convolution2"
  top: "conv6-Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv6-Concat1"
  type: "Concat"
  bottom: "conv6-Convolution1"
  bottom: "conv6-Dropout1"
  top: "conv6-Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv6-BatchNorm2"
  type: "BatchNorm"
  bottom: "conv6-Concat1"
  top: "conv6-BatchNorm2"
  param {
    lr_mult: 
I0630 14:51:19.149521 47538 layer_factory.hpp:77] Creating layer data
I0630 14:51:19.149557 47538 net.cpp:91] Creating Layer data
I0630 14:51:19.149572 47538 net.cpp:399] data -> dataT1
I0630 14:51:19.149627 47538 net.cpp:399] data -> dataT2
I0630 14:51:19.149652 47538 net.cpp:399] data -> dataSeg
I0630 14:51:19.149669 47538 net.cpp:399] data -> dataCp
I0630 14:51:19.149694 47538 hdf5_data_layer.cpp:81] Loading list of HDF5 filenames from: trainInfant3D_list-BCP18-cp.txt
I0630 14:51:19.167241 47538 hdf5_data_layer.cpp:95] Number of HDF5 files: 9
I0630 14:51:19.180569 47538 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0630 14:51:24.562669 47538 net.cpp:141] Setting up data
I0630 14:51:24.562731 47538 net.cpp:148] Top shape: 3 1 32 32 32 (98304)
I0630 14:51:24.562739 47538 net.cpp:148] Top shape: 3 1 32 32 32 (98304)
I0630 14:51:24.562747 47538 net.cpp:148] Top shape: 3 1 32 32 32 (98304)
I0630 14:51:24.562755 47538 net.cpp:148] Top shape: 3 1 32 32 32 (98304)
I0630 14:51:24.562762 47538 net.cpp:156] Memory required for data: 1572864
I0630 14:51:24.562780 47538 layer_factory.hpp:77] Creating layer concat
I0630 14:51:24.562809 47538 net.cpp:91] Creating Layer concat
I0630 14:51:24.562824 47538 net.cpp:425] concat <- dataT1
I0630 14:51:24.562849 47538 net.cpp:425] concat <- dataT2
I0630 14:51:24.562860 47538 net.cpp:399] concat -> data
I0630 14:51:24.562911 47538 net.cpp:141] Setting up concat
I0630 14:51:24.562922 47538 net.cpp:148] Top shape: 3 2 32 32 32 (196608)
I0630 14:51:24.562928 47538 net.cpp:156] Memory required for data: 2359296
I0630 14:51:24.562937 47538 layer_factory.hpp:77] Creating layer conv1a
I0630 14:51:24.562964 47538 net.cpp:91] Creating Layer conv1a
I0630 14:51:24.563004 47538 net.cpp:425] conv1a <- data
I0630 14:51:24.563019 47538 net.cpp:399] conv1a -> conv1a
I0630 14:51:25.252353 47538 net.cpp:141] Setting up conv1a
I0630 14:51:25.252398 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.252405 47538 net.cpp:156] Memory required for data: 27525120
I0630 14:51:25.252455 47538 layer_factory.hpp:77] Creating layer bn1
I0630 14:51:25.252475 47538 net.cpp:91] Creating Layer bn1
I0630 14:51:25.252482 47538 net.cpp:425] bn1 <- conv1a
I0630 14:51:25.252494 47538 net.cpp:399] bn1 -> conv1a_bn
I0630 14:51:25.252807 47538 net.cpp:141] Setting up bn1
I0630 14:51:25.252818 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.252823 47538 net.cpp:156] Memory required for data: 52690944
I0630 14:51:25.252840 47538 layer_factory.hpp:77] Creating layer scale_conv1
I0630 14:51:25.252854 47538 net.cpp:91] Creating Layer scale_conv1
I0630 14:51:25.252861 47538 net.cpp:425] scale_conv1 <- conv1a_bn
I0630 14:51:25.252868 47538 net.cpp:386] scale_conv1 -> conv1a_bn (in-place)
I0630 14:51:25.252933 47538 layer_factory.hpp:77] Creating layer scale_conv1
I0630 14:51:25.253132 47538 net.cpp:141] Setting up scale_conv1
I0630 14:51:25.253144 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.253149 47538 net.cpp:156] Memory required for data: 77856768
I0630 14:51:25.253160 47538 layer_factory.hpp:77] Creating layer relu1a
I0630 14:51:25.253178 47538 net.cpp:91] Creating Layer relu1a
I0630 14:51:25.253185 47538 net.cpp:425] relu1a <- conv1a_bn
I0630 14:51:25.253192 47538 net.cpp:386] relu1a -> conv1a_bn (in-place)
I0630 14:51:25.253463 47538 net.cpp:141] Setting up relu1a
I0630 14:51:25.253476 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.253481 47538 net.cpp:156] Memory required for data: 103022592
I0630 14:51:25.253489 47538 layer_factory.hpp:77] Creating layer Convolution1
I0630 14:51:25.253509 47538 net.cpp:91] Creating Layer Convolution1
I0630 14:51:25.253515 47538 net.cpp:425] Convolution1 <- conv1a_bn
I0630 14:51:25.253528 47538 net.cpp:399] Convolution1 -> Convolution1
I0630 14:51:25.260799 47538 net.cpp:141] Setting up Convolution1
I0630 14:51:25.260823 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.260828 47538 net.cpp:156] Memory required for data: 128188416
I0630 14:51:25.260843 47538 layer_factory.hpp:77] Creating layer Convolution1_Convolution1_0_split
I0630 14:51:25.260854 47538 net.cpp:91] Creating Layer Convolution1_Convolution1_0_split
I0630 14:51:25.260861 47538 net.cpp:425] Convolution1_Convolution1_0_split <- Convolution1
I0630 14:51:25.260874 47538 net.cpp:399] Convolution1_Convolution1_0_split -> Convolution1_Convolution1_0_split_0
I0630 14:51:25.260887 47538 net.cpp:399] Convolution1_Convolution1_0_split -> Convolution1_Convolution1_0_split_1
I0630 14:51:25.260949 47538 net.cpp:141] Setting up Convolution1_Convolution1_0_split
I0630 14:51:25.260960 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.260967 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.260972 47538 net.cpp:156] Memory required for data: 178520064
I0630 14:51:25.260977 47538 layer_factory.hpp:77] Creating layer BatchNorm1
I0630 14:51:25.260990 47538 net.cpp:91] Creating Layer BatchNorm1
I0630 14:51:25.260996 47538 net.cpp:425] BatchNorm1 <- Convolution1_Convolution1_0_split_0
I0630 14:51:25.261004 47538 net.cpp:399] BatchNorm1 -> BatchNorm1
I0630 14:51:25.261296 47538 net.cpp:141] Setting up BatchNorm1
I0630 14:51:25.261307 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.261312 47538 net.cpp:156] Memory required for data: 203685888
I0630 14:51:25.261327 47538 layer_factory.hpp:77] Creating layer Scale1
I0630 14:51:25.261338 47538 net.cpp:91] Creating Layer Scale1
I0630 14:51:25.261345 47538 net.cpp:425] Scale1 <- BatchNorm1
I0630 14:51:25.261353 47538 net.cpp:386] Scale1 -> BatchNorm1 (in-place)
I0630 14:51:25.261410 47538 layer_factory.hpp:77] Creating layer Scale1
I0630 14:51:25.261613 47538 net.cpp:141] Setting up Scale1
I0630 14:51:25.261624 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.261636 47538 net.cpp:156] Memory required for data: 228851712
I0630 14:51:25.261672 47538 layer_factory.hpp:77] Creating layer ReLU1
I0630 14:51:25.261683 47538 net.cpp:91] Creating Layer ReLU1
I0630 14:51:25.261690 47538 net.cpp:425] ReLU1 <- BatchNorm1
I0630 14:51:25.261698 47538 net.cpp:386] ReLU1 -> BatchNorm1 (in-place)
I0630 14:51:25.261955 47538 net.cpp:141] Setting up ReLU1
I0630 14:51:25.261967 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.261973 47538 net.cpp:156] Memory required for data: 254017536
I0630 14:51:25.261978 47538 layer_factory.hpp:77] Creating layer Convolution2
I0630 14:51:25.261994 47538 net.cpp:91] Creating Layer Convolution2
I0630 14:51:25.262001 47538 net.cpp:425] Convolution2 <- BatchNorm1
I0630 14:51:25.262013 47538 net.cpp:399] Convolution2 -> Convolution2
I0630 14:51:25.265959 47538 net.cpp:141] Setting up Convolution2
I0630 14:51:25.265978 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.265985 47538 net.cpp:156] Memory required for data: 260308992
I0630 14:51:25.265996 47538 layer_factory.hpp:77] Creating layer Dropout1
I0630 14:51:25.266007 47538 net.cpp:91] Creating Layer Dropout1
I0630 14:51:25.266016 47538 net.cpp:425] Dropout1 <- Convolution2
I0630 14:51:25.266028 47538 net.cpp:399] Dropout1 -> Dropout1
I0630 14:51:25.266098 47538 net.cpp:141] Setting up Dropout1
I0630 14:51:25.266108 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.266113 47538 net.cpp:156] Memory required for data: 266600448
I0630 14:51:25.266120 47538 layer_factory.hpp:77] Creating layer Concat1
I0630 14:51:25.266130 47538 net.cpp:91] Creating Layer Concat1
I0630 14:51:25.266136 47538 net.cpp:425] Concat1 <- Convolution1_Convolution1_0_split_1
I0630 14:51:25.266144 47538 net.cpp:425] Concat1 <- Dropout1
I0630 14:51:25.266153 47538 net.cpp:399] Concat1 -> Concat1
I0630 14:51:25.266188 47538 net.cpp:141] Setting up Concat1
I0630 14:51:25.266198 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.266203 47538 net.cpp:156] Memory required for data: 298057728
I0630 14:51:25.266208 47538 layer_factory.hpp:77] Creating layer Concat1_Concat1_0_split
I0630 14:51:25.266218 47538 net.cpp:91] Creating Layer Concat1_Concat1_0_split
I0630 14:51:25.266223 47538 net.cpp:425] Concat1_Concat1_0_split <- Concat1
I0630 14:51:25.266232 47538 net.cpp:399] Concat1_Concat1_0_split -> Concat1_Concat1_0_split_0
I0630 14:51:25.266244 47538 net.cpp:399] Concat1_Concat1_0_split -> Concat1_Concat1_0_split_1
I0630 14:51:25.266289 47538 net.cpp:141] Setting up Concat1_Concat1_0_split
I0630 14:51:25.266297 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.266304 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.266309 47538 net.cpp:156] Memory required for data: 360972288
I0630 14:51:25.266314 47538 layer_factory.hpp:77] Creating layer BatchNorm2
I0630 14:51:25.266326 47538 net.cpp:91] Creating Layer BatchNorm2
I0630 14:51:25.266331 47538 net.cpp:425] BatchNorm2 <- Concat1_Concat1_0_split_0
I0630 14:51:25.266342 47538 net.cpp:399] BatchNorm2 -> BatchNorm2
I0630 14:51:25.266633 47538 net.cpp:141] Setting up BatchNorm2
I0630 14:51:25.266644 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.266649 47538 net.cpp:156] Memory required for data: 392429568
I0630 14:51:25.266665 47538 layer_factory.hpp:77] Creating layer Scale2
I0630 14:51:25.266680 47538 net.cpp:91] Creating Layer Scale2
I0630 14:51:25.266685 47538 net.cpp:425] Scale2 <- BatchNorm2
I0630 14:51:25.266692 47538 net.cpp:386] Scale2 -> BatchNorm2 (in-place)
I0630 14:51:25.266748 47538 layer_factory.hpp:77] Creating layer Scale2
I0630 14:51:25.266957 47538 net.cpp:141] Setting up Scale2
I0630 14:51:25.266968 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.266984 47538 net.cpp:156] Memory required for data: 423886848
I0630 14:51:25.266995 47538 layer_factory.hpp:77] Creating layer ReLU2
I0630 14:51:25.267004 47538 net.cpp:91] Creating Layer ReLU2
I0630 14:51:25.267010 47538 net.cpp:425] ReLU2 <- BatchNorm2
I0630 14:51:25.267025 47538 net.cpp:386] ReLU2 -> BatchNorm2 (in-place)
I0630 14:51:25.267302 47538 net.cpp:141] Setting up ReLU2
I0630 14:51:25.267315 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.267320 47538 net.cpp:156] Memory required for data: 455344128
I0630 14:51:25.267326 47538 layer_factory.hpp:77] Creating layer Convolution3
I0630 14:51:25.267343 47538 net.cpp:91] Creating Layer Convolution3
I0630 14:51:25.267349 47538 net.cpp:425] Convolution3 <- BatchNorm2
I0630 14:51:25.267361 47538 net.cpp:399] Convolution3 -> Convolution3
I0630 14:51:25.270527 47538 net.cpp:141] Setting up Convolution3
I0630 14:51:25.270545 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.270552 47538 net.cpp:156] Memory required for data: 461635584
I0630 14:51:25.270562 47538 layer_factory.hpp:77] Creating layer Dropout2
I0630 14:51:25.270571 47538 net.cpp:91] Creating Layer Dropout2
I0630 14:51:25.270577 47538 net.cpp:425] Dropout2 <- Convolution3
I0630 14:51:25.270589 47538 net.cpp:399] Dropout2 -> Dropout2
I0630 14:51:25.270649 47538 net.cpp:141] Setting up Dropout2
I0630 14:51:25.270658 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.270663 47538 net.cpp:156] Memory required for data: 467927040
I0630 14:51:25.270671 47538 layer_factory.hpp:77] Creating layer Concat2
I0630 14:51:25.270684 47538 net.cpp:91] Creating Layer Concat2
I0630 14:51:25.270689 47538 net.cpp:425] Concat2 <- Concat1_Concat1_0_split_1
I0630 14:51:25.270695 47538 net.cpp:425] Concat2 <- Dropout2
I0630 14:51:25.270704 47538 net.cpp:399] Concat2 -> Concat2
I0630 14:51:25.270737 47538 net.cpp:141] Setting up Concat2
I0630 14:51:25.270745 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.270750 47538 net.cpp:156] Memory required for data: 505675776
I0630 14:51:25.270756 47538 layer_factory.hpp:77] Creating layer Concat2_Concat2_0_split
I0630 14:51:25.270763 47538 net.cpp:91] Creating Layer Concat2_Concat2_0_split
I0630 14:51:25.270768 47538 net.cpp:425] Concat2_Concat2_0_split <- Concat2
I0630 14:51:25.270781 47538 net.cpp:399] Concat2_Concat2_0_split -> Concat2_Concat2_0_split_0
I0630 14:51:25.270792 47538 net.cpp:399] Concat2_Concat2_0_split -> Concat2_Concat2_0_split_1
I0630 14:51:25.270838 47538 net.cpp:141] Setting up Concat2_Concat2_0_split
I0630 14:51:25.270848 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.270853 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.270859 47538 net.cpp:156] Memory required for data: 581173248
I0630 14:51:25.270864 47538 layer_factory.hpp:77] Creating layer BatchNorm3
I0630 14:51:25.270875 47538 net.cpp:91] Creating Layer BatchNorm3
I0630 14:51:25.270880 47538 net.cpp:425] BatchNorm3 <- Concat2_Concat2_0_split_0
I0630 14:51:25.270889 47538 net.cpp:399] BatchNorm3 -> BatchNorm3
I0630 14:51:25.271193 47538 net.cpp:141] Setting up BatchNorm3
I0630 14:51:25.271203 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.271207 47538 net.cpp:156] Memory required for data: 618921984
I0630 14:51:25.271219 47538 layer_factory.hpp:77] Creating layer Scale3
I0630 14:51:25.271230 47538 net.cpp:91] Creating Layer Scale3
I0630 14:51:25.271236 47538 net.cpp:425] Scale3 <- BatchNorm3
I0630 14:51:25.271245 47538 net.cpp:386] Scale3 -> BatchNorm3 (in-place)
I0630 14:51:25.271302 47538 layer_factory.hpp:77] Creating layer Scale3
I0630 14:51:25.274721 47538 net.cpp:141] Setting up Scale3
I0630 14:51:25.274742 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.274749 47538 net.cpp:156] Memory required for data: 656670720
I0630 14:51:25.274762 47538 layer_factory.hpp:77] Creating layer ReLU3
I0630 14:51:25.274771 47538 net.cpp:91] Creating Layer ReLU3
I0630 14:51:25.274777 47538 net.cpp:425] ReLU3 <- BatchNorm3
I0630 14:51:25.274785 47538 net.cpp:386] ReLU3 -> BatchNorm3 (in-place)
I0630 14:51:25.275063 47538 net.cpp:141] Setting up ReLU3
I0630 14:51:25.275075 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.275080 47538 net.cpp:156] Memory required for data: 694419456
I0630 14:51:25.275091 47538 layer_factory.hpp:77] Creating layer Convolution4
I0630 14:51:25.275127 47538 net.cpp:91] Creating Layer Convolution4
I0630 14:51:25.275135 47538 net.cpp:425] Convolution4 <- BatchNorm3
I0630 14:51:25.275144 47538 net.cpp:399] Convolution4 -> Convolution4
I0630 14:51:25.279894 47538 net.cpp:141] Setting up Convolution4
I0630 14:51:25.279913 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.279919 47538 net.cpp:156] Memory required for data: 700710912
I0630 14:51:25.279929 47538 layer_factory.hpp:77] Creating layer Dropout3
I0630 14:51:25.279939 47538 net.cpp:91] Creating Layer Dropout3
I0630 14:51:25.279947 47538 net.cpp:425] Dropout3 <- Convolution4
I0630 14:51:25.279958 47538 net.cpp:399] Dropout3 -> Dropout3
I0630 14:51:25.280025 47538 net.cpp:141] Setting up Dropout3
I0630 14:51:25.280032 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.280038 47538 net.cpp:156] Memory required for data: 707002368
I0630 14:51:25.280043 47538 layer_factory.hpp:77] Creating layer Concat3
I0630 14:51:25.280051 47538 net.cpp:91] Creating Layer Concat3
I0630 14:51:25.280057 47538 net.cpp:425] Concat3 <- Concat2_Concat2_0_split_1
I0630 14:51:25.280064 47538 net.cpp:425] Concat3 <- Dropout3
I0630 14:51:25.280074 47538 net.cpp:399] Concat3 -> Concat3
I0630 14:51:25.280105 47538 net.cpp:141] Setting up Concat3
I0630 14:51:25.280112 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:25.280118 47538 net.cpp:156] Memory required for data: 751042560
I0630 14:51:25.280126 47538 layer_factory.hpp:77] Creating layer bn2
I0630 14:51:25.280138 47538 net.cpp:91] Creating Layer bn2
I0630 14:51:25.280143 47538 net.cpp:425] bn2 <- Concat3
I0630 14:51:25.280154 47538 net.cpp:399] bn2 -> conv1b_bn
I0630 14:51:25.280441 47538 net.cpp:141] Setting up bn2
I0630 14:51:25.280450 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:25.280455 47538 net.cpp:156] Memory required for data: 795082752
I0630 14:51:25.280473 47538 layer_factory.hpp:77] Creating layer scale_conv2
I0630 14:51:25.280485 47538 net.cpp:91] Creating Layer scale_conv2
I0630 14:51:25.280491 47538 net.cpp:425] scale_conv2 <- conv1b_bn
I0630 14:51:25.280498 47538 net.cpp:386] scale_conv2 -> conv1b_bn (in-place)
I0630 14:51:25.280555 47538 layer_factory.hpp:77] Creating layer scale_conv2
I0630 14:51:25.280755 47538 net.cpp:141] Setting up scale_conv2
I0630 14:51:25.280766 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:25.280771 47538 net.cpp:156] Memory required for data: 839122944
I0630 14:51:25.280779 47538 layer_factory.hpp:77] Creating layer relu1b
I0630 14:51:25.280786 47538 net.cpp:91] Creating Layer relu1b
I0630 14:51:25.280791 47538 net.cpp:425] relu1b <- conv1b_bn
I0630 14:51:25.280802 47538 net.cpp:386] relu1b -> conv1b_bn (in-place)
I0630 14:51:25.283504 47538 net.cpp:141] Setting up relu1b
I0630 14:51:25.283520 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:25.283525 47538 net.cpp:156] Memory required for data: 883163136
I0630 14:51:25.283531 47538 layer_factory.hpp:77] Creating layer conv1c
I0630 14:51:25.283550 47538 net.cpp:91] Creating Layer conv1c
I0630 14:51:25.283556 47538 net.cpp:425] conv1c <- conv1b_bn
I0630 14:51:25.283572 47538 net.cpp:399] conv1c -> conv1c
I0630 14:51:25.288772 47538 net.cpp:141] Setting up conv1c
I0630 14:51:25.288797 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.288803 47538 net.cpp:156] Memory required for data: 908328960
I0630 14:51:25.288815 47538 layer_factory.hpp:77] Creating layer conv1c_conv1c_0_split
I0630 14:51:25.288832 47538 net.cpp:91] Creating Layer conv1c_conv1c_0_split
I0630 14:51:25.288841 47538 net.cpp:425] conv1c_conv1c_0_split <- conv1c
I0630 14:51:25.288848 47538 net.cpp:399] conv1c_conv1c_0_split -> conv1c_conv1c_0_split_0
I0630 14:51:25.288861 47538 net.cpp:399] conv1c_conv1c_0_split -> conv1c_conv1c_0_split_1
I0630 14:51:25.288924 47538 net.cpp:141] Setting up conv1c_conv1c_0_split
I0630 14:51:25.288934 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.288946 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.288969 47538 net.cpp:156] Memory required for data: 958660608
I0630 14:51:25.288975 47538 layer_factory.hpp:77] Creating layer bn3
I0630 14:51:25.288990 47538 net.cpp:91] Creating Layer bn3
I0630 14:51:25.288995 47538 net.cpp:425] bn3 <- conv1c_conv1c_0_split_0
I0630 14:51:25.289005 47538 net.cpp:399] bn3 -> conv1c_bn
I0630 14:51:25.289310 47538 net.cpp:141] Setting up bn3
I0630 14:51:25.289320 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.289325 47538 net.cpp:156] Memory required for data: 983826432
I0630 14:51:25.289335 47538 layer_factory.hpp:77] Creating layer scale_conv3
I0630 14:51:25.289350 47538 net.cpp:91] Creating Layer scale_conv3
I0630 14:51:25.289357 47538 net.cpp:425] scale_conv3 <- conv1c_bn
I0630 14:51:25.289364 47538 net.cpp:386] scale_conv3 -> conv1c_bn (in-place)
I0630 14:51:25.289418 47538 layer_factory.hpp:77] Creating layer scale_conv3
I0630 14:51:25.289640 47538 net.cpp:141] Setting up scale_conv3
I0630 14:51:25.289650 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.289655 47538 net.cpp:156] Memory required for data: 1008992256
I0630 14:51:25.289664 47538 layer_factory.hpp:77] Creating layer relu1c
I0630 14:51:25.289674 47538 net.cpp:91] Creating Layer relu1c
I0630 14:51:25.289680 47538 net.cpp:425] relu1c <- conv1c_bn
I0630 14:51:25.289687 47538 net.cpp:386] relu1c -> conv1c_bn (in-place)
I0630 14:51:25.290822 47538 net.cpp:141] Setting up relu1c
I0630 14:51:25.290838 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.290843 47538 net.cpp:156] Memory required for data: 1034158080
I0630 14:51:25.290849 47538 layer_factory.hpp:77] Creating layer pool1
I0630 14:51:25.290863 47538 net.cpp:91] Creating Layer pool1
I0630 14:51:25.290868 47538 net.cpp:425] pool1 <- conv1c_bn
I0630 14:51:25.290879 47538 net.cpp:399] pool1 -> pool1
I0630 14:51:25.291218 47538 net.cpp:141] Setting up pool1
I0630 14:51:25.291235 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:25.291240 47538 net.cpp:156] Memory required for data: 1037303808
I0630 14:51:25.291245 47538 layer_factory.hpp:77] Creating layer conv2a-Convolution1
I0630 14:51:25.291262 47538 net.cpp:91] Creating Layer conv2a-Convolution1
I0630 14:51:25.291268 47538 net.cpp:425] conv2a-Convolution1 <- pool1
I0630 14:51:25.291280 47538 net.cpp:399] conv2a-Convolution1 -> conv2a-Convolution1
I0630 14:51:25.298223 47538 net.cpp:141] Setting up conv2a-Convolution1
I0630 14:51:25.298243 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:25.298247 47538 net.cpp:156] Memory required for data: 1040449536
I0630 14:51:25.298260 47538 layer_factory.hpp:77] Creating layer conv2a-Convolution1_conv2a-Convolution1_0_split
I0630 14:51:25.298274 47538 net.cpp:91] Creating Layer conv2a-Convolution1_conv2a-Convolution1_0_split
I0630 14:51:25.298280 47538 net.cpp:425] conv2a-Convolution1_conv2a-Convolution1_0_split <- conv2a-Convolution1
I0630 14:51:25.298291 47538 net.cpp:399] conv2a-Convolution1_conv2a-Convolution1_0_split -> conv2a-Convolution1_conv2a-Convolution1_0_split_0
I0630 14:51:25.298302 47538 net.cpp:399] conv2a-Convolution1_conv2a-Convolution1_0_split -> conv2a-Convolution1_conv2a-Convolution1_0_split_1
I0630 14:51:25.298359 47538 net.cpp:141] Setting up conv2a-Convolution1_conv2a-Convolution1_0_split
I0630 14:51:25.298372 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:25.298378 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:25.298382 47538 net.cpp:156] Memory required for data: 1046740992
I0630 14:51:25.298388 47538 layer_factory.hpp:77] Creating layer conv2a-BatchNorm1
I0630 14:51:25.298398 47538 net.cpp:91] Creating Layer conv2a-BatchNorm1
I0630 14:51:25.298403 47538 net.cpp:425] conv2a-BatchNorm1 <- conv2a-Convolution1_conv2a-Convolution1_0_split_0
I0630 14:51:25.298413 47538 net.cpp:399] conv2a-BatchNorm1 -> conv2a-BatchNorm1
I0630 14:51:25.298674 47538 net.cpp:141] Setting up conv2a-BatchNorm1
I0630 14:51:25.298683 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:25.298692 47538 net.cpp:156] Memory required for data: 1049886720
I0630 14:51:25.298717 47538 layer_factory.hpp:77] Creating layer conv2a-Scale1
I0630 14:51:25.298727 47538 net.cpp:91] Creating Layer conv2a-Scale1
I0630 14:51:25.298732 47538 net.cpp:425] conv2a-Scale1 <- conv2a-BatchNorm1
I0630 14:51:25.298739 47538 net.cpp:386] conv2a-Scale1 -> conv2a-BatchNorm1 (in-place)
I0630 14:51:25.298795 47538 layer_factory.hpp:77] Creating layer conv2a-Scale1
I0630 14:51:25.298955 47538 net.cpp:141] Setting up conv2a-Scale1
I0630 14:51:25.298964 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:25.298979 47538 net.cpp:156] Memory required for data: 1053032448
I0630 14:51:25.298998 47538 layer_factory.hpp:77] Creating layer conv2a-ReLU1
I0630 14:51:25.299018 47538 net.cpp:91] Creating Layer conv2a-ReLU1
I0630 14:51:25.299024 47538 net.cpp:425] conv2a-ReLU1 <- conv2a-BatchNorm1
I0630 14:51:25.299034 47538 net.cpp:386] conv2a-ReLU1 -> conv2a-BatchNorm1 (in-place)
I0630 14:51:25.299289 47538 net.cpp:141] Setting up conv2a-ReLU1
I0630 14:51:25.299300 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:25.299305 47538 net.cpp:156] Memory required for data: 1056178176
I0630 14:51:25.299311 47538 layer_factory.hpp:77] Creating layer conv2a-Convolution2
I0630 14:51:25.299327 47538 net.cpp:91] Creating Layer conv2a-Convolution2
I0630 14:51:25.299332 47538 net.cpp:425] conv2a-Convolution2 <- conv2a-BatchNorm1
I0630 14:51:25.299345 47538 net.cpp:399] conv2a-Convolution2 -> conv2a-Convolution2
I0630 14:51:25.305671 47538 net.cpp:141] Setting up conv2a-Convolution2
I0630 14:51:25.305691 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.305696 47538 net.cpp:156] Memory required for data: 1057751040
I0630 14:51:25.305706 47538 layer_factory.hpp:77] Creating layer conv2a-Dropout1
I0630 14:51:25.305716 47538 net.cpp:91] Creating Layer conv2a-Dropout1
I0630 14:51:25.305721 47538 net.cpp:425] conv2a-Dropout1 <- conv2a-Convolution2
I0630 14:51:25.305732 47538 net.cpp:399] conv2a-Dropout1 -> conv2a-Dropout1
I0630 14:51:25.305788 47538 net.cpp:141] Setting up conv2a-Dropout1
I0630 14:51:25.305799 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.305802 47538 net.cpp:156] Memory required for data: 1059323904
I0630 14:51:25.305807 47538 layer_factory.hpp:77] Creating layer conv2a-Concat1
I0630 14:51:25.305816 47538 net.cpp:91] Creating Layer conv2a-Concat1
I0630 14:51:25.305821 47538 net.cpp:425] conv2a-Concat1 <- conv2a-Convolution1_conv2a-Convolution1_0_split_1
I0630 14:51:25.305827 47538 net.cpp:425] conv2a-Concat1 <- conv2a-Dropout1
I0630 14:51:25.305835 47538 net.cpp:399] conv2a-Concat1 -> conv2a-Concat1
I0630 14:51:25.305869 47538 net.cpp:141] Setting up conv2a-Concat1
I0630 14:51:25.305876 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:25.305881 47538 net.cpp:156] Memory required for data: 1064042496
I0630 14:51:25.305887 47538 layer_factory.hpp:77] Creating layer conv2a-Concat1_conv2a-Concat1_0_split
I0630 14:51:25.305898 47538 net.cpp:91] Creating Layer conv2a-Concat1_conv2a-Concat1_0_split
I0630 14:51:25.305903 47538 net.cpp:425] conv2a-Concat1_conv2a-Concat1_0_split <- conv2a-Concat1
I0630 14:51:25.305910 47538 net.cpp:399] conv2a-Concat1_conv2a-Concat1_0_split -> conv2a-Concat1_conv2a-Concat1_0_split_0
I0630 14:51:25.305919 47538 net.cpp:399] conv2a-Concat1_conv2a-Concat1_0_split -> conv2a-Concat1_conv2a-Concat1_0_split_1
I0630 14:51:25.305966 47538 net.cpp:141] Setting up conv2a-Concat1_conv2a-Concat1_0_split
I0630 14:51:25.305974 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:25.305979 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:25.305984 47538 net.cpp:156] Memory required for data: 1073479680
I0630 14:51:25.305989 47538 layer_factory.hpp:77] Creating layer conv2a-BatchNorm2
I0630 14:51:25.306003 47538 net.cpp:91] Creating Layer conv2a-BatchNorm2
I0630 14:51:25.306008 47538 net.cpp:425] conv2a-BatchNorm2 <- conv2a-Concat1_conv2a-Concat1_0_split_0
I0630 14:51:25.306018 47538 net.cpp:399] conv2a-BatchNorm2 -> conv2a-BatchNorm2
I0630 14:51:25.306277 47538 net.cpp:141] Setting up conv2a-BatchNorm2
I0630 14:51:25.306299 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:25.306304 47538 net.cpp:156] Memory required for data: 1078198272
I0630 14:51:25.306314 47538 layer_factory.hpp:77] Creating layer conv2a-Scale2
I0630 14:51:25.306324 47538 net.cpp:91] Creating Layer conv2a-Scale2
I0630 14:51:25.306329 47538 net.cpp:425] conv2a-Scale2 <- conv2a-BatchNorm2
I0630 14:51:25.306339 47538 net.cpp:386] conv2a-Scale2 -> conv2a-BatchNorm2 (in-place)
I0630 14:51:25.306392 47538 layer_factory.hpp:77] Creating layer conv2a-Scale2
I0630 14:51:25.306541 47538 net.cpp:141] Setting up conv2a-Scale2
I0630 14:51:25.306553 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:25.306557 47538 net.cpp:156] Memory required for data: 1082916864
I0630 14:51:25.306565 47538 layer_factory.hpp:77] Creating layer conv2a-ReLU2
I0630 14:51:25.306573 47538 net.cpp:91] Creating Layer conv2a-ReLU2
I0630 14:51:25.306578 47538 net.cpp:425] conv2a-ReLU2 <- conv2a-BatchNorm2
I0630 14:51:25.306586 47538 net.cpp:386] conv2a-ReLU2 -> conv2a-BatchNorm2 (in-place)
I0630 14:51:25.306823 47538 net.cpp:141] Setting up conv2a-ReLU2
I0630 14:51:25.306835 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:25.306839 47538 net.cpp:156] Memory required for data: 1087635456
I0630 14:51:25.306846 47538 layer_factory.hpp:77] Creating layer conv2a-Convolution3
I0630 14:51:25.306865 47538 net.cpp:91] Creating Layer conv2a-Convolution3
I0630 14:51:25.306871 47538 net.cpp:425] conv2a-Convolution3 <- conv2a-BatchNorm2
I0630 14:51:25.306880 47538 net.cpp:399] conv2a-Convolution3 -> conv2a-Convolution3
I0630 14:51:25.309408 47538 net.cpp:141] Setting up conv2a-Convolution3
I0630 14:51:25.309427 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.309433 47538 net.cpp:156] Memory required for data: 1089208320
I0630 14:51:25.309443 47538 layer_factory.hpp:77] Creating layer conv2a-Dropout2
I0630 14:51:25.309453 47538 net.cpp:91] Creating Layer conv2a-Dropout2
I0630 14:51:25.309458 47538 net.cpp:425] conv2a-Dropout2 <- conv2a-Convolution3
I0630 14:51:25.309466 47538 net.cpp:399] conv2a-Dropout2 -> conv2a-Dropout2
I0630 14:51:25.309523 47538 net.cpp:141] Setting up conv2a-Dropout2
I0630 14:51:25.309531 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.309535 47538 net.cpp:156] Memory required for data: 1090781184
I0630 14:51:25.309541 47538 layer_factory.hpp:77] Creating layer conv2a-Concat2
I0630 14:51:25.309548 47538 net.cpp:91] Creating Layer conv2a-Concat2
I0630 14:51:25.309554 47538 net.cpp:425] conv2a-Concat2 <- conv2a-Concat1_conv2a-Concat1_0_split_1
I0630 14:51:25.309561 47538 net.cpp:425] conv2a-Concat2 <- conv2a-Dropout2
I0630 14:51:25.309571 47538 net.cpp:399] conv2a-Concat2 -> conv2a-Concat2
I0630 14:51:25.309602 47538 net.cpp:141] Setting up conv2a-Concat2
I0630 14:51:25.309608 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.309612 47538 net.cpp:156] Memory required for data: 1097072640
I0630 14:51:25.309620 47538 layer_factory.hpp:77] Creating layer conv2a-Concat2_conv2a-Concat2_0_split
I0630 14:51:25.309628 47538 net.cpp:91] Creating Layer conv2a-Concat2_conv2a-Concat2_0_split
I0630 14:51:25.309633 47538 net.cpp:425] conv2a-Concat2_conv2a-Concat2_0_split <- conv2a-Concat2
I0630 14:51:25.309643 47538 net.cpp:399] conv2a-Concat2_conv2a-Concat2_0_split -> conv2a-Concat2_conv2a-Concat2_0_split_0
I0630 14:51:25.309653 47538 net.cpp:399] conv2a-Concat2_conv2a-Concat2_0_split -> conv2a-Concat2_conv2a-Concat2_0_split_1
I0630 14:51:25.309698 47538 net.cpp:141] Setting up conv2a-Concat2_conv2a-Concat2_0_split
I0630 14:51:25.309706 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.309711 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.309717 47538 net.cpp:156] Memory required for data: 1109655552
I0630 14:51:25.309721 47538 layer_factory.hpp:77] Creating layer conv2a-BatchNorm3
I0630 14:51:25.309732 47538 net.cpp:91] Creating Layer conv2a-BatchNorm3
I0630 14:51:25.309743 47538 net.cpp:425] conv2a-BatchNorm3 <- conv2a-Concat2_conv2a-Concat2_0_split_0
I0630 14:51:25.309764 47538 net.cpp:399] conv2a-BatchNorm3 -> conv2a-BatchNorm3
I0630 14:51:25.310015 47538 net.cpp:141] Setting up conv2a-BatchNorm3
I0630 14:51:25.310024 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.310029 47538 net.cpp:156] Memory required for data: 1115947008
I0630 14:51:25.310039 47538 layer_factory.hpp:77] Creating layer conv2a-Scale3
I0630 14:51:25.310047 47538 net.cpp:91] Creating Layer conv2a-Scale3
I0630 14:51:25.310052 47538 net.cpp:425] conv2a-Scale3 <- conv2a-BatchNorm3
I0630 14:51:25.310062 47538 net.cpp:386] conv2a-Scale3 -> conv2a-BatchNorm3 (in-place)
I0630 14:51:25.310115 47538 layer_factory.hpp:77] Creating layer conv2a-Scale3
I0630 14:51:25.310256 47538 net.cpp:141] Setting up conv2a-Scale3
I0630 14:51:25.310264 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.310269 47538 net.cpp:156] Memory required for data: 1122238464
I0630 14:51:25.310278 47538 layer_factory.hpp:77] Creating layer conv2a-ReLU3
I0630 14:51:25.310286 47538 net.cpp:91] Creating Layer conv2a-ReLU3
I0630 14:51:25.310290 47538 net.cpp:425] conv2a-ReLU3 <- conv2a-BatchNorm3
I0630 14:51:25.310299 47538 net.cpp:386] conv2a-ReLU3 -> conv2a-BatchNorm3 (in-place)
I0630 14:51:25.310534 47538 net.cpp:141] Setting up conv2a-ReLU3
I0630 14:51:25.310544 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.310549 47538 net.cpp:156] Memory required for data: 1128529920
I0630 14:51:25.310555 47538 layer_factory.hpp:77] Creating layer conv2a-Convolution4
I0630 14:51:25.310571 47538 net.cpp:91] Creating Layer conv2a-Convolution4
I0630 14:51:25.310577 47538 net.cpp:425] conv2a-Convolution4 <- conv2a-BatchNorm3
I0630 14:51:25.310590 47538 net.cpp:399] conv2a-Convolution4 -> conv2a-Convolution4
I0630 14:51:25.315160 47538 net.cpp:141] Setting up conv2a-Convolution4
I0630 14:51:25.315177 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.315182 47538 net.cpp:156] Memory required for data: 1130102784
I0630 14:51:25.315203 47538 layer_factory.hpp:77] Creating layer conv2a-Dropout3
I0630 14:51:25.315217 47538 net.cpp:91] Creating Layer conv2a-Dropout3
I0630 14:51:25.315223 47538 net.cpp:425] conv2a-Dropout3 <- conv2a-Convolution4
I0630 14:51:25.315232 47538 net.cpp:399] conv2a-Dropout3 -> conv2a-Dropout3
I0630 14:51:25.315296 47538 net.cpp:141] Setting up conv2a-Dropout3
I0630 14:51:25.315304 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.315310 47538 net.cpp:156] Memory required for data: 1131675648
I0630 14:51:25.315315 47538 layer_factory.hpp:77] Creating layer conv2a-Concat3
I0630 14:51:25.315325 47538 net.cpp:91] Creating Layer conv2a-Concat3
I0630 14:51:25.315330 47538 net.cpp:425] conv2a-Concat3 <- conv2a-Concat2_conv2a-Concat2_0_split_1
I0630 14:51:25.315337 47538 net.cpp:425] conv2a-Concat3 <- conv2a-Dropout3
I0630 14:51:25.315344 47538 net.cpp:399] conv2a-Concat3 -> conv2a
I0630 14:51:25.315376 47538 net.cpp:141] Setting up conv2a-Concat3
I0630 14:51:25.315383 47538 net.cpp:148] Top shape: 3 160 16 16 16 (1966080)
I0630 14:51:25.315388 47538 net.cpp:156] Memory required for data: 1139539968
I0630 14:51:25.315393 47538 layer_factory.hpp:77] Creating layer bn4
I0630 14:51:25.315415 47538 net.cpp:91] Creating Layer bn4
I0630 14:51:25.315420 47538 net.cpp:425] bn4 <- conv2a
I0630 14:51:25.315429 47538 net.cpp:399] bn4 -> conv2a_bn
I0630 14:51:25.315688 47538 net.cpp:141] Setting up bn4
I0630 14:51:25.315696 47538 net.cpp:148] Top shape: 3 160 16 16 16 (1966080)
I0630 14:51:25.315701 47538 net.cpp:156] Memory required for data: 1147404288
I0630 14:51:25.315711 47538 layer_factory.hpp:77] Creating layer scale_conv4
I0630 14:51:25.315721 47538 net.cpp:91] Creating Layer scale_conv4
I0630 14:51:25.315727 47538 net.cpp:425] scale_conv4 <- conv2a_bn
I0630 14:51:25.315733 47538 net.cpp:386] scale_conv4 -> conv2a_bn (in-place)
I0630 14:51:25.315786 47538 layer_factory.hpp:77] Creating layer scale_conv4
I0630 14:51:25.315939 47538 net.cpp:141] Setting up scale_conv4
I0630 14:51:25.315953 47538 net.cpp:148] Top shape: 3 160 16 16 16 (1966080)
I0630 14:51:25.315970 47538 net.cpp:156] Memory required for data: 1155268608
I0630 14:51:25.315979 47538 layer_factory.hpp:77] Creating layer relu2a
I0630 14:51:25.315986 47538 net.cpp:91] Creating Layer relu2a
I0630 14:51:25.315991 47538 net.cpp:425] relu2a <- conv2a_bn
I0630 14:51:25.316001 47538 net.cpp:386] relu2a -> conv2a_bn (in-place)
I0630 14:51:25.318686 47538 net.cpp:141] Setting up relu2a
I0630 14:51:25.318703 47538 net.cpp:148] Top shape: 3 160 16 16 16 (1966080)
I0630 14:51:25.318708 47538 net.cpp:156] Memory required for data: 1163132928
I0630 14:51:25.318714 47538 layer_factory.hpp:77] Creating layer conv2b
I0630 14:51:25.318732 47538 net.cpp:91] Creating Layer conv2b
I0630 14:51:25.318738 47538 net.cpp:425] conv2b <- conv2a_bn
I0630 14:51:25.318753 47538 net.cpp:399] conv2b -> conv2b
I0630 14:51:25.331730 47538 net.cpp:141] Setting up conv2b
I0630 14:51:25.331749 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.331755 47538 net.cpp:156] Memory required for data: 1169424384
I0630 14:51:25.331768 47538 layer_factory.hpp:77] Creating layer conv2b_conv2b_0_split
I0630 14:51:25.331779 47538 net.cpp:91] Creating Layer conv2b_conv2b_0_split
I0630 14:51:25.331784 47538 net.cpp:425] conv2b_conv2b_0_split <- conv2b
I0630 14:51:25.331796 47538 net.cpp:399] conv2b_conv2b_0_split -> conv2b_conv2b_0_split_0
I0630 14:51:25.331807 47538 net.cpp:399] conv2b_conv2b_0_split -> conv2b_conv2b_0_split_1
I0630 14:51:25.331866 47538 net.cpp:141] Setting up conv2b_conv2b_0_split
I0630 14:51:25.331874 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.331881 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.331884 47538 net.cpp:156] Memory required for data: 1182007296
I0630 14:51:25.331889 47538 layer_factory.hpp:77] Creating layer bn5
I0630 14:51:25.331912 47538 net.cpp:91] Creating Layer bn5
I0630 14:51:25.331918 47538 net.cpp:425] bn5 <- conv2b_conv2b_0_split_0
I0630 14:51:25.331925 47538 net.cpp:399] bn5 -> conv2b_bn
I0630 14:51:25.332175 47538 net.cpp:141] Setting up bn5
I0630 14:51:25.332185 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.332190 47538 net.cpp:156] Memory required for data: 1188298752
I0630 14:51:25.332199 47538 layer_factory.hpp:77] Creating layer scale_conv5_fine
I0630 14:51:25.332207 47538 net.cpp:91] Creating Layer scale_conv5_fine
I0630 14:51:25.332213 47538 net.cpp:425] scale_conv5_fine <- conv2b_bn
I0630 14:51:25.332221 47538 net.cpp:386] scale_conv5_fine -> conv2b_bn (in-place)
I0630 14:51:25.332271 47538 layer_factory.hpp:77] Creating layer scale_conv5_fine
I0630 14:51:25.332412 47538 net.cpp:141] Setting up scale_conv5_fine
I0630 14:51:25.332422 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.332425 47538 net.cpp:156] Memory required for data: 1194590208
I0630 14:51:25.332433 47538 layer_factory.hpp:77] Creating layer relu2b
I0630 14:51:25.332445 47538 net.cpp:91] Creating Layer relu2b
I0630 14:51:25.332451 47538 net.cpp:425] relu2b <- conv2b_bn
I0630 14:51:25.332458 47538 net.cpp:386] relu2b -> conv2b_bn (in-place)
I0630 14:51:25.332692 47538 net.cpp:141] Setting up relu2b
I0630 14:51:25.332702 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.332708 47538 net.cpp:156] Memory required for data: 1200881664
I0630 14:51:25.332713 47538 layer_factory.hpp:77] Creating layer pool2
I0630 14:51:25.332724 47538 net.cpp:91] Creating Layer pool2
I0630 14:51:25.332729 47538 net.cpp:425] pool2 <- conv2b_bn
I0630 14:51:25.332737 47538 net.cpp:399] pool2 -> pool2
I0630 14:51:25.333009 47538 net.cpp:141] Setting up pool2
I0630 14:51:25.333022 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:25.333027 47538 net.cpp:156] Memory required for data: 1201668096
I0630 14:51:25.333034 47538 layer_factory.hpp:77] Creating layer conv3a
I0630 14:51:25.333046 47538 net.cpp:91] Creating Layer conv3a
I0630 14:51:25.333052 47538 net.cpp:425] conv3a <- pool2
I0630 14:51:25.333060 47538 net.cpp:399] conv3a -> conv3a
I0630 14:51:25.347493 47538 net.cpp:141] Setting up conv3a
I0630 14:51:25.347528 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:25.347534 47538 net.cpp:156] Memory required for data: 1202454528
I0630 14:51:25.347544 47538 layer_factory.hpp:77] Creating layer conv3a_conv3a_0_split
I0630 14:51:25.347558 47538 net.cpp:91] Creating Layer conv3a_conv3a_0_split
I0630 14:51:25.347564 47538 net.cpp:425] conv3a_conv3a_0_split <- conv3a
I0630 14:51:25.347573 47538 net.cpp:399] conv3a_conv3a_0_split -> conv3a_conv3a_0_split_0
I0630 14:51:25.347586 47538 net.cpp:399] conv3a_conv3a_0_split -> conv3a_conv3a_0_split_1
I0630 14:51:25.347647 47538 net.cpp:141] Setting up conv3a_conv3a_0_split
I0630 14:51:25.347656 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:25.347662 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:25.347666 47538 net.cpp:156] Memory required for data: 1204027392
I0630 14:51:25.347671 47538 layer_factory.hpp:77] Creating layer bn6
I0630 14:51:25.347687 47538 net.cpp:91] Creating Layer bn6
I0630 14:51:25.347692 47538 net.cpp:425] bn6 <- conv3a_conv3a_0_split_0
I0630 14:51:25.347703 47538 net.cpp:399] bn6 -> conv3a_bn
I0630 14:51:25.347954 47538 net.cpp:141] Setting up bn6
I0630 14:51:25.347962 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:25.347967 47538 net.cpp:156] Memory required for data: 1204813824
I0630 14:51:25.347977 47538 layer_factory.hpp:77] Creating layer scale_conv6
I0630 14:51:25.347986 47538 net.cpp:91] Creating Layer scale_conv6
I0630 14:51:25.347991 47538 net.cpp:425] scale_conv6 <- conv3a_bn
I0630 14:51:25.347998 47538 net.cpp:386] scale_conv6 -> conv3a_bn (in-place)
I0630 14:51:25.348062 47538 layer_factory.hpp:77] Creating layer scale_conv6
I0630 14:51:25.348193 47538 net.cpp:141] Setting up scale_conv6
I0630 14:51:25.348202 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:25.348207 47538 net.cpp:156] Memory required for data: 1205600256
I0630 14:51:25.348215 47538 layer_factory.hpp:77] Creating layer relu3a
I0630 14:51:25.348225 47538 net.cpp:91] Creating Layer relu3a
I0630 14:51:25.348232 47538 net.cpp:425] relu3a <- conv3a_bn
I0630 14:51:25.348237 47538 net.cpp:386] relu3a -> conv3a_bn (in-place)
I0630 14:51:25.348492 47538 net.cpp:141] Setting up relu3a
I0630 14:51:25.348507 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:25.348512 47538 net.cpp:156] Memory required for data: 1206386688
I0630 14:51:25.348518 47538 layer_factory.hpp:77] Creating layer pool3
I0630 14:51:25.348527 47538 net.cpp:91] Creating Layer pool3
I0630 14:51:25.348533 47538 net.cpp:425] pool3 <- conv3a_bn
I0630 14:51:25.348543 47538 net.cpp:399] pool3 -> pool3
I0630 14:51:25.350827 47538 net.cpp:141] Setting up pool3
I0630 14:51:25.350847 47538 net.cpp:148] Top shape: 3 128 4 4 4 (24576)
I0630 14:51:25.350852 47538 net.cpp:156] Memory required for data: 1206484992
I0630 14:51:25.350858 47538 layer_factory.hpp:77] Creating layer deconv4
I0630 14:51:25.350870 47538 net.cpp:91] Creating Layer deconv4
I0630 14:51:25.350877 47538 net.cpp:425] deconv4 <- pool3
I0630 14:51:25.350888 47538 net.cpp:399] deconv4 -> deconv4
I0630 14:51:25.361203 47538 net.cpp:141] Setting up deconv4
I0630 14:51:25.361222 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:25.361227 47538 net.cpp:156] Memory required for data: 1207271424
I0630 14:51:25.361238 47538 layer_factory.hpp:77] Creating layer concat8
I0630 14:51:25.361250 47538 net.cpp:91] Creating Layer concat8
I0630 14:51:25.361256 47538 net.cpp:425] concat8 <- conv3a_conv3a_0_split_1
I0630 14:51:25.361263 47538 net.cpp:425] concat8 <- deconv4
I0630 14:51:25.361271 47538 net.cpp:399] concat8 -> concat8
I0630 14:51:25.361310 47538 net.cpp:141] Setting up concat8
I0630 14:51:25.361317 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:25.361321 47538 net.cpp:156] Memory required for data: 1208844288
I0630 14:51:25.361327 47538 layer_factory.hpp:77] Creating layer conv4-Convolution1
I0630 14:51:25.361346 47538 net.cpp:91] Creating Layer conv4-Convolution1
I0630 14:51:25.361356 47538 net.cpp:425] conv4-Convolution1 <- concat8
I0630 14:51:25.361383 47538 net.cpp:399] conv4-Convolution1 -> conv4-Convolution1
I0630 14:51:25.385004 47538 net.cpp:141] Setting up conv4-Convolution1
I0630 14:51:25.385032 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:25.385037 47538 net.cpp:156] Memory required for data: 1210417152
I0630 14:51:25.385048 47538 layer_factory.hpp:77] Creating layer conv4-Convolution1_conv4-Convolution1_0_split
I0630 14:51:25.385061 47538 net.cpp:91] Creating Layer conv4-Convolution1_conv4-Convolution1_0_split
I0630 14:51:25.385066 47538 net.cpp:425] conv4-Convolution1_conv4-Convolution1_0_split <- conv4-Convolution1
I0630 14:51:25.385082 47538 net.cpp:399] conv4-Convolution1_conv4-Convolution1_0_split -> conv4-Convolution1_conv4-Convolution1_0_split_0
I0630 14:51:25.385093 47538 net.cpp:399] conv4-Convolution1_conv4-Convolution1_0_split -> conv4-Convolution1_conv4-Convolution1_0_split_1
I0630 14:51:25.385150 47538 net.cpp:141] Setting up conv4-Convolution1_conv4-Convolution1_0_split
I0630 14:51:25.385159 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:25.385165 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:25.385169 47538 net.cpp:156] Memory required for data: 1213562880
I0630 14:51:25.385175 47538 layer_factory.hpp:77] Creating layer conv4-BatchNorm1
I0630 14:51:25.385187 47538 net.cpp:91] Creating Layer conv4-BatchNorm1
I0630 14:51:25.385192 47538 net.cpp:425] conv4-BatchNorm1 <- conv4-Convolution1_conv4-Convolution1_0_split_0
I0630 14:51:25.385200 47538 net.cpp:399] conv4-BatchNorm1 -> conv4-BatchNorm1
I0630 14:51:25.385452 47538 net.cpp:141] Setting up conv4-BatchNorm1
I0630 14:51:25.385459 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:25.385464 47538 net.cpp:156] Memory required for data: 1215135744
I0630 14:51:25.385474 47538 layer_factory.hpp:77] Creating layer conv4-Scale1
I0630 14:51:25.385486 47538 net.cpp:91] Creating Layer conv4-Scale1
I0630 14:51:25.385493 47538 net.cpp:425] conv4-Scale1 <- conv4-BatchNorm1
I0630 14:51:25.385499 47538 net.cpp:386] conv4-Scale1 -> conv4-BatchNorm1 (in-place)
I0630 14:51:25.385556 47538 layer_factory.hpp:77] Creating layer conv4-Scale1
I0630 14:51:25.385689 47538 net.cpp:141] Setting up conv4-Scale1
I0630 14:51:25.385696 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:25.385701 47538 net.cpp:156] Memory required for data: 1216708608
I0630 14:51:25.385712 47538 layer_factory.hpp:77] Creating layer conv4-ReLU1
I0630 14:51:25.385720 47538 net.cpp:91] Creating Layer conv4-ReLU1
I0630 14:51:25.385725 47538 net.cpp:425] conv4-ReLU1 <- conv4-BatchNorm1
I0630 14:51:25.385735 47538 net.cpp:386] conv4-ReLU1 -> conv4-BatchNorm1 (in-place)
I0630 14:51:25.390702 47538 net.cpp:141] Setting up conv4-ReLU1
I0630 14:51:25.390722 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:25.390727 47538 net.cpp:156] Memory required for data: 1218281472
I0630 14:51:25.390733 47538 layer_factory.hpp:77] Creating layer conv4-Convolution2
I0630 14:51:25.390755 47538 net.cpp:91] Creating Layer conv4-Convolution2
I0630 14:51:25.390763 47538 net.cpp:425] conv4-Convolution2 <- conv4-BatchNorm1
I0630 14:51:25.390772 47538 net.cpp:399] conv4-Convolution2 -> conv4-Convolution2
I0630 14:51:25.394419 47538 net.cpp:141] Setting up conv4-Convolution2
I0630 14:51:25.394436 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:25.394443 47538 net.cpp:156] Memory required for data: 1218478080
I0630 14:51:25.394451 47538 layer_factory.hpp:77] Creating layer conv4-Dropout1
I0630 14:51:25.394464 47538 net.cpp:91] Creating Layer conv4-Dropout1
I0630 14:51:25.394470 47538 net.cpp:425] conv4-Dropout1 <- conv4-Convolution2
I0630 14:51:25.394479 47538 net.cpp:399] conv4-Dropout1 -> conv4-Dropout1
I0630 14:51:25.394536 47538 net.cpp:141] Setting up conv4-Dropout1
I0630 14:51:25.394544 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:25.394548 47538 net.cpp:156] Memory required for data: 1218674688
I0630 14:51:25.394554 47538 layer_factory.hpp:77] Creating layer conv4-Concat1
I0630 14:51:25.394572 47538 net.cpp:91] Creating Layer conv4-Concat1
I0630 14:51:25.394593 47538 net.cpp:425] conv4-Concat1 <- conv4-Convolution1_conv4-Convolution1_0_split_1
I0630 14:51:25.394599 47538 net.cpp:425] conv4-Concat1 <- conv4-Dropout1
I0630 14:51:25.394610 47538 net.cpp:399] conv4-Concat1 -> conv4-Concat1
I0630 14:51:25.394644 47538 net.cpp:141] Setting up conv4-Concat1
I0630 14:51:25.394654 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:25.394659 47538 net.cpp:156] Memory required for data: 1220444160
I0630 14:51:25.394665 47538 layer_factory.hpp:77] Creating layer conv4-Concat1_conv4-Concat1_0_split
I0630 14:51:25.394672 47538 net.cpp:91] Creating Layer conv4-Concat1_conv4-Concat1_0_split
I0630 14:51:25.394677 47538 net.cpp:425] conv4-Concat1_conv4-Concat1_0_split <- conv4-Concat1
I0630 14:51:25.394685 47538 net.cpp:399] conv4-Concat1_conv4-Concat1_0_split -> conv4-Concat1_conv4-Concat1_0_split_0
I0630 14:51:25.394714 47538 net.cpp:399] conv4-Concat1_conv4-Concat1_0_split -> conv4-Concat1_conv4-Concat1_0_split_1
I0630 14:51:25.394764 47538 net.cpp:141] Setting up conv4-Concat1_conv4-Concat1_0_split
I0630 14:51:25.394773 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:25.394778 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:25.394783 47538 net.cpp:156] Memory required for data: 1223983104
I0630 14:51:25.394788 47538 layer_factory.hpp:77] Creating layer conv4-BatchNorm2
I0630 14:51:25.394798 47538 net.cpp:91] Creating Layer conv4-BatchNorm2
I0630 14:51:25.394802 47538 net.cpp:425] conv4-BatchNorm2 <- conv4-Concat1_conv4-Concat1_0_split_0
I0630 14:51:25.394814 47538 net.cpp:399] conv4-BatchNorm2 -> conv4-BatchNorm2
I0630 14:51:25.395105 47538 net.cpp:141] Setting up conv4-BatchNorm2
I0630 14:51:25.395115 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:25.395119 47538 net.cpp:156] Memory required for data: 1225752576
I0630 14:51:25.395130 47538 layer_factory.hpp:77] Creating layer conv4-Scale2
I0630 14:51:25.395138 47538 net.cpp:91] Creating Layer conv4-Scale2
I0630 14:51:25.395144 47538 net.cpp:425] conv4-Scale2 <- conv4-BatchNorm2
I0630 14:51:25.395153 47538 net.cpp:386] conv4-Scale2 -> conv4-BatchNorm2 (in-place)
I0630 14:51:25.395202 47538 layer_factory.hpp:77] Creating layer conv4-Scale2
I0630 14:51:25.395370 47538 net.cpp:141] Setting up conv4-Scale2
I0630 14:51:25.395378 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:25.395382 47538 net.cpp:156] Memory required for data: 1227522048
I0630 14:51:25.395395 47538 layer_factory.hpp:77] Creating layer conv4-ReLU2
I0630 14:51:25.395401 47538 net.cpp:91] Creating Layer conv4-ReLU2
I0630 14:51:25.395406 47538 net.cpp:425] conv4-ReLU2 <- conv4-BatchNorm2
I0630 14:51:25.395416 47538 net.cpp:386] conv4-ReLU2 -> conv4-BatchNorm2 (in-place)
I0630 14:51:25.395661 47538 net.cpp:141] Setting up conv4-ReLU2
I0630 14:51:25.395673 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:25.395678 47538 net.cpp:156] Memory required for data: 1229291520
I0630 14:51:25.395682 47538 layer_factory.hpp:77] Creating layer conv4-Convolution3
I0630 14:51:25.395699 47538 net.cpp:91] Creating Layer conv4-Convolution3
I0630 14:51:25.395704 47538 net.cpp:425] conv4-Convolution3 <- conv4-BatchNorm2
I0630 14:51:25.395715 47538 net.cpp:399] conv4-Convolution3 -> conv4-Convolution3
I0630 14:51:25.414634 47538 net.cpp:141] Setting up conv4-Convolution3
I0630 14:51:25.414654 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:25.414659 47538 net.cpp:156] Memory required for data: 1229488128
I0630 14:51:25.414670 47538 layer_factory.hpp:77] Creating layer conv4-Dropout2
I0630 14:51:25.414683 47538 net.cpp:91] Creating Layer conv4-Dropout2
I0630 14:51:25.414690 47538 net.cpp:425] conv4-Dropout2 <- conv4-Convolution3
I0630 14:51:25.414700 47538 net.cpp:399] conv4-Dropout2 -> conv4-Dropout2
I0630 14:51:25.414762 47538 net.cpp:141] Setting up conv4-Dropout2
I0630 14:51:25.414770 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:25.414775 47538 net.cpp:156] Memory required for data: 1229684736
I0630 14:51:25.414785 47538 layer_factory.hpp:77] Creating layer conv4-Concat2
I0630 14:51:25.414808 47538 net.cpp:91] Creating Layer conv4-Concat2
I0630 14:51:25.414813 47538 net.cpp:425] conv4-Concat2 <- conv4-Concat1_conv4-Concat1_0_split_1
I0630 14:51:25.414821 47538 net.cpp:425] conv4-Concat2 <- conv4-Dropout2
I0630 14:51:25.414834 47538 net.cpp:399] conv4-Concat2 -> conv4-Concat2
I0630 14:51:25.414868 47538 net.cpp:141] Setting up conv4-Concat2
I0630 14:51:25.414876 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:25.414881 47538 net.cpp:156] Memory required for data: 1231650816
I0630 14:51:25.414889 47538 layer_factory.hpp:77] Creating layer conv4-Concat2_conv4-Concat2_0_split
I0630 14:51:25.414901 47538 net.cpp:91] Creating Layer conv4-Concat2_conv4-Concat2_0_split
I0630 14:51:25.414906 47538 net.cpp:425] conv4-Concat2_conv4-Concat2_0_split <- conv4-Concat2
I0630 14:51:25.414917 47538 net.cpp:399] conv4-Concat2_conv4-Concat2_0_split -> conv4-Concat2_conv4-Concat2_0_split_0
I0630 14:51:25.414927 47538 net.cpp:399] conv4-Concat2_conv4-Concat2_0_split -> conv4-Concat2_conv4-Concat2_0_split_1
I0630 14:51:25.414999 47538 net.cpp:141] Setting up conv4-Concat2_conv4-Concat2_0_split
I0630 14:51:25.415022 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:25.415030 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:25.415035 47538 net.cpp:156] Memory required for data: 1235582976
I0630 14:51:25.415038 47538 layer_factory.hpp:77] Creating layer conv4-BatchNorm3
I0630 14:51:25.415048 47538 net.cpp:91] Creating Layer conv4-BatchNorm3
I0630 14:51:25.415055 47538 net.cpp:425] conv4-BatchNorm3 <- conv4-Concat2_conv4-Concat2_0_split_0
I0630 14:51:25.415066 47538 net.cpp:399] conv4-BatchNorm3 -> conv4-BatchNorm3
I0630 14:51:25.415354 47538 net.cpp:141] Setting up conv4-BatchNorm3
I0630 14:51:25.415362 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:25.415369 47538 net.cpp:156] Memory required for data: 1237549056
I0630 14:51:25.415378 47538 layer_factory.hpp:77] Creating layer conv4-Scale3
I0630 14:51:25.415386 47538 net.cpp:91] Creating Layer conv4-Scale3
I0630 14:51:25.415398 47538 net.cpp:425] conv4-Scale3 <- conv4-BatchNorm3
I0630 14:51:25.415406 47538 net.cpp:386] conv4-Scale3 -> conv4-BatchNorm3 (in-place)
I0630 14:51:25.415467 47538 layer_factory.hpp:77] Creating layer conv4-Scale3
I0630 14:51:25.415625 47538 net.cpp:141] Setting up conv4-Scale3
I0630 14:51:25.415634 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:25.415639 47538 net.cpp:156] Memory required for data: 1239515136
I0630 14:51:25.415650 47538 layer_factory.hpp:77] Creating layer conv4-ReLU3
I0630 14:51:25.415657 47538 net.cpp:91] Creating Layer conv4-ReLU3
I0630 14:51:25.415663 47538 net.cpp:425] conv4-ReLU3 <- conv4-BatchNorm3
I0630 14:51:25.415673 47538 net.cpp:386] conv4-ReLU3 -> conv4-BatchNorm3 (in-place)
I0630 14:51:25.415926 47538 net.cpp:141] Setting up conv4-ReLU3
I0630 14:51:25.415937 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:25.415942 47538 net.cpp:156] Memory required for data: 1241481216
I0630 14:51:25.415948 47538 layer_factory.hpp:77] Creating layer conv4-Convolution4
I0630 14:51:25.415966 47538 net.cpp:91] Creating Layer conv4-Convolution4
I0630 14:51:25.415972 47538 net.cpp:425] conv4-Convolution4 <- conv4-BatchNorm3
I0630 14:51:25.415984 47538 net.cpp:399] conv4-Convolution4 -> conv4-Convolution4
I0630 14:51:25.423909 47538 net.cpp:141] Setting up conv4-Convolution4
I0630 14:51:25.423928 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:25.423933 47538 net.cpp:156] Memory required for data: 1241677824
I0630 14:51:25.423943 47538 layer_factory.hpp:77] Creating layer conv4-Dropout3
I0630 14:51:25.423954 47538 net.cpp:91] Creating Layer conv4-Dropout3
I0630 14:51:25.423959 47538 net.cpp:425] conv4-Dropout3 <- conv4-Convolution4
I0630 14:51:25.423971 47538 net.cpp:399] conv4-Dropout3 -> conv4-Dropout3
I0630 14:51:25.424031 47538 net.cpp:141] Setting up conv4-Dropout3
I0630 14:51:25.424039 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:25.424048 47538 net.cpp:156] Memory required for data: 1241874432
I0630 14:51:25.424070 47538 layer_factory.hpp:77] Creating layer conv4-Concat3
I0630 14:51:25.424078 47538 net.cpp:91] Creating Layer conv4-Concat3
I0630 14:51:25.424085 47538 net.cpp:425] conv4-Concat3 <- conv4-Concat2_conv4-Concat2_0_split_1
I0630 14:51:25.424091 47538 net.cpp:425] conv4-Concat3 <- conv4-Dropout3
I0630 14:51:25.424103 47538 net.cpp:399] conv4-Concat3 -> conv4
I0630 14:51:25.424135 47538 net.cpp:141] Setting up conv4-Concat3
I0630 14:51:25.424144 47538 net.cpp:148] Top shape: 3 352 8 8 8 (540672)
I0630 14:51:25.424149 47538 net.cpp:156] Memory required for data: 1244037120
I0630 14:51:25.424154 47538 layer_factory.hpp:77] Creating layer conv4_bn
I0630 14:51:25.424165 47538 net.cpp:91] Creating Layer conv4_bn
I0630 14:51:25.424170 47538 net.cpp:425] conv4_bn <- conv4
I0630 14:51:25.424180 47538 net.cpp:399] conv4_bn -> conv4_bn
I0630 14:51:25.424445 47538 net.cpp:141] Setting up conv4_bn
I0630 14:51:25.424454 47538 net.cpp:148] Top shape: 3 352 8 8 8 (540672)
I0630 14:51:25.424459 47538 net.cpp:156] Memory required for data: 1246199808
I0630 14:51:25.424469 47538 layer_factory.hpp:77] Creating layer scale_conv4_fine
I0630 14:51:25.424477 47538 net.cpp:91] Creating Layer scale_conv4_fine
I0630 14:51:25.424482 47538 net.cpp:425] scale_conv4_fine <- conv4_bn
I0630 14:51:25.424494 47538 net.cpp:386] scale_conv4_fine -> conv4_bn (in-place)
I0630 14:51:25.424542 47538 layer_factory.hpp:77] Creating layer scale_conv4_fine
I0630 14:51:25.424697 47538 net.cpp:141] Setting up scale_conv4_fine
I0630 14:51:25.424706 47538 net.cpp:148] Top shape: 3 352 8 8 8 (540672)
I0630 14:51:25.424711 47538 net.cpp:156] Memory required for data: 1248362496
I0630 14:51:25.424719 47538 layer_factory.hpp:77] Creating layer relu4a
I0630 14:51:25.424726 47538 net.cpp:91] Creating Layer relu4a
I0630 14:51:25.424731 47538 net.cpp:425] relu4a <- conv4_bn
I0630 14:51:25.424738 47538 net.cpp:386] relu4a -> conv4_bn (in-place)
I0630 14:51:25.424990 47538 net.cpp:141] Setting up relu4a
I0630 14:51:25.425001 47538 net.cpp:148] Top shape: 3 352 8 8 8 (540672)
I0630 14:51:25.425006 47538 net.cpp:156] Memory required for data: 1250525184
I0630 14:51:25.425024 47538 layer_factory.hpp:77] Creating layer deconv5
I0630 14:51:25.425036 47538 net.cpp:91] Creating Layer deconv5
I0630 14:51:25.425041 47538 net.cpp:425] deconv5 <- conv4_bn
I0630 14:51:25.425050 47538 net.cpp:399] deconv5 -> deconv5
I0630 14:51:25.451166 47538 net.cpp:141] Setting up deconv5
I0630 14:51:25.451208 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:25.451213 47538 net.cpp:156] Memory required for data: 1256816640
I0630 14:51:25.451227 47538 layer_factory.hpp:77] Creating layer concat16
I0630 14:51:25.451244 47538 net.cpp:91] Creating Layer concat16
I0630 14:51:25.451252 47538 net.cpp:425] concat16 <- conv2b_conv2b_0_split_1
I0630 14:51:25.451262 47538 net.cpp:425] concat16 <- deconv5
I0630 14:51:25.451272 47538 net.cpp:399] concat16 -> concat16
I0630 14:51:25.451324 47538 net.cpp:141] Setting up concat16
I0630 14:51:25.451333 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.451337 47538 net.cpp:156] Memory required for data: 1269399552
I0630 14:51:25.451342 47538 layer_factory.hpp:77] Creating layer conv5-Convolution1
I0630 14:51:25.451371 47538 net.cpp:91] Creating Layer conv5-Convolution1
I0630 14:51:25.451376 47538 net.cpp:425] conv5-Convolution1 <- concat16
I0630 14:51:25.451388 47538 net.cpp:399] conv5-Convolution1 -> conv5-Convolution1
I0630 14:51:25.473501 47538 net.cpp:141] Setting up conv5-Convolution1
I0630 14:51:25.473524 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.473531 47538 net.cpp:156] Memory required for data: 1281982464
I0630 14:51:25.473548 47538 layer_factory.hpp:77] Creating layer conv5-Convolution1_conv5-Convolution1_0_split
I0630 14:51:25.473567 47538 net.cpp:91] Creating Layer conv5-Convolution1_conv5-Convolution1_0_split
I0630 14:51:25.473584 47538 net.cpp:425] conv5-Convolution1_conv5-Convolution1_0_split <- conv5-Convolution1
I0630 14:51:25.473611 47538 net.cpp:399] conv5-Convolution1_conv5-Convolution1_0_split -> conv5-Convolution1_conv5-Convolution1_0_split_0
I0630 14:51:25.473664 47538 net.cpp:399] conv5-Convolution1_conv5-Convolution1_0_split -> conv5-Convolution1_conv5-Convolution1_0_split_1
I0630 14:51:25.473735 47538 net.cpp:141] Setting up conv5-Convolution1_conv5-Convolution1_0_split
I0630 14:51:25.473745 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.473752 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.473757 47538 net.cpp:156] Memory required for data: 1307148288
I0630 14:51:25.473762 47538 layer_factory.hpp:77] Creating layer conv5-BatchNorm1
I0630 14:51:25.473774 47538 net.cpp:91] Creating Layer conv5-BatchNorm1
I0630 14:51:25.473780 47538 net.cpp:425] conv5-BatchNorm1 <- conv5-Convolution1_conv5-Convolution1_0_split_0
I0630 14:51:25.473788 47538 net.cpp:399] conv5-BatchNorm1 -> conv5-BatchNorm1
I0630 14:51:25.474098 47538 net.cpp:141] Setting up conv5-BatchNorm1
I0630 14:51:25.474118 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.474123 47538 net.cpp:156] Memory required for data: 1319731200
I0630 14:51:25.474134 47538 layer_factory.hpp:77] Creating layer conv5-Scale1
I0630 14:51:25.474144 47538 net.cpp:91] Creating Layer conv5-Scale1
I0630 14:51:25.474150 47538 net.cpp:425] conv5-Scale1 <- conv5-BatchNorm1
I0630 14:51:25.474160 47538 net.cpp:386] conv5-Scale1 -> conv5-BatchNorm1 (in-place)
I0630 14:51:25.474220 47538 layer_factory.hpp:77] Creating layer conv5-Scale1
I0630 14:51:25.474370 47538 net.cpp:141] Setting up conv5-Scale1
I0630 14:51:25.474380 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.474383 47538 net.cpp:156] Memory required for data: 1332314112
I0630 14:51:25.474392 47538 layer_factory.hpp:77] Creating layer conv5-ReLU1
I0630 14:51:25.474406 47538 net.cpp:91] Creating Layer conv5-ReLU1
I0630 14:51:25.474412 47538 net.cpp:425] conv5-ReLU1 <- conv5-BatchNorm1
I0630 14:51:25.474418 47538 net.cpp:386] conv5-ReLU1 -> conv5-BatchNorm1 (in-place)
I0630 14:51:25.474673 47538 net.cpp:141] Setting up conv5-ReLU1
I0630 14:51:25.474684 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.474689 47538 net.cpp:156] Memory required for data: 1344897024
I0630 14:51:25.474696 47538 layer_factory.hpp:77] Creating layer conv5-Convolution2
I0630 14:51:25.474714 47538 net.cpp:91] Creating Layer conv5-Convolution2
I0630 14:51:25.474720 47538 net.cpp:425] conv5-Convolution2 <- conv5-BatchNorm1
I0630 14:51:25.474730 47538 net.cpp:399] conv5-Convolution2 -> conv5-Convolution2
I0630 14:51:25.478472 47538 net.cpp:141] Setting up conv5-Convolution2
I0630 14:51:25.478489 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.478494 47538 net.cpp:156] Memory required for data: 1346469888
I0630 14:51:25.478505 47538 layer_factory.hpp:77] Creating layer conv5-Dropout1
I0630 14:51:25.478515 47538 net.cpp:91] Creating Layer conv5-Dropout1
I0630 14:51:25.478521 47538 net.cpp:425] conv5-Dropout1 <- conv5-Convolution2
I0630 14:51:25.478529 47538 net.cpp:399] conv5-Dropout1 -> conv5-Dropout1
I0630 14:51:25.478593 47538 net.cpp:141] Setting up conv5-Dropout1
I0630 14:51:25.478601 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.478606 47538 net.cpp:156] Memory required for data: 1348042752
I0630 14:51:25.478611 47538 layer_factory.hpp:77] Creating layer conv5-Concat1
I0630 14:51:25.478619 47538 net.cpp:91] Creating Layer conv5-Concat1
I0630 14:51:25.478624 47538 net.cpp:425] conv5-Concat1 <- conv5-Convolution1_conv5-Convolution1_0_split_1
I0630 14:51:25.478631 47538 net.cpp:425] conv5-Concat1 <- conv5-Dropout1
I0630 14:51:25.478641 47538 net.cpp:399] conv5-Concat1 -> conv5-Concat1
I0630 14:51:25.478675 47538 net.cpp:141] Setting up conv5-Concat1
I0630 14:51:25.478683 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.478688 47538 net.cpp:156] Memory required for data: 1362198528
I0630 14:51:25.478694 47538 layer_factory.hpp:77] Creating layer conv5-Concat1_conv5-Concat1_0_split
I0630 14:51:25.478708 47538 net.cpp:91] Creating Layer conv5-Concat1_conv5-Concat1_0_split
I0630 14:51:25.478726 47538 net.cpp:425] conv5-Concat1_conv5-Concat1_0_split <- conv5-Concat1
I0630 14:51:25.478736 47538 net.cpp:399] conv5-Concat1_conv5-Concat1_0_split -> conv5-Concat1_conv5-Concat1_0_split_0
I0630 14:51:25.478746 47538 net.cpp:399] conv5-Concat1_conv5-Concat1_0_split -> conv5-Concat1_conv5-Concat1_0_split_1
I0630 14:51:25.478798 47538 net.cpp:141] Setting up conv5-Concat1_conv5-Concat1_0_split
I0630 14:51:25.478806 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.478811 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.478816 47538 net.cpp:156] Memory required for data: 1390510080
I0630 14:51:25.478821 47538 layer_factory.hpp:77] Creating layer conv5-BatchNorm2
I0630 14:51:25.478833 47538 net.cpp:91] Creating Layer conv5-BatchNorm2
I0630 14:51:25.478839 47538 net.cpp:425] conv5-BatchNorm2 <- conv5-Concat1_conv5-Concat1_0_split_0
I0630 14:51:25.478848 47538 net.cpp:399] conv5-BatchNorm2 -> conv5-BatchNorm2
I0630 14:51:25.479133 47538 net.cpp:141] Setting up conv5-BatchNorm2
I0630 14:51:25.479142 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.479146 47538 net.cpp:156] Memory required for data: 1404665856
I0630 14:51:25.479157 47538 layer_factory.hpp:77] Creating layer conv5-Scale2
I0630 14:51:25.479166 47538 net.cpp:91] Creating Layer conv5-Scale2
I0630 14:51:25.479171 47538 net.cpp:425] conv5-Scale2 <- conv5-BatchNorm2
I0630 14:51:25.479185 47538 net.cpp:386] conv5-Scale2 -> conv5-BatchNorm2 (in-place)
I0630 14:51:25.479243 47538 layer_factory.hpp:77] Creating layer conv5-Scale2
I0630 14:51:25.479408 47538 net.cpp:141] Setting up conv5-Scale2
I0630 14:51:25.479418 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.479424 47538 net.cpp:156] Memory required for data: 1418821632
I0630 14:51:25.479447 47538 layer_factory.hpp:77] Creating layer conv5-ReLU2
I0630 14:51:25.479460 47538 net.cpp:91] Creating Layer conv5-ReLU2
I0630 14:51:25.479465 47538 net.cpp:425] conv5-ReLU2 <- conv5-BatchNorm2
I0630 14:51:25.479470 47538 net.cpp:386] conv5-ReLU2 -> conv5-BatchNorm2 (in-place)
I0630 14:51:25.490896 47538 net.cpp:141] Setting up conv5-ReLU2
I0630 14:51:25.490918 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.490923 47538 net.cpp:156] Memory required for data: 1432977408
I0630 14:51:25.490929 47538 layer_factory.hpp:77] Creating layer conv5-Convolution3
I0630 14:51:25.490945 47538 net.cpp:91] Creating Layer conv5-Convolution3
I0630 14:51:25.490953 47538 net.cpp:425] conv5-Convolution3 <- conv5-BatchNorm2
I0630 14:51:25.490965 47538 net.cpp:399] conv5-Convolution3 -> conv5-Convolution3
I0630 14:51:25.493974 47538 net.cpp:141] Setting up conv5-Convolution3
I0630 14:51:25.493990 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.493996 47538 net.cpp:156] Memory required for data: 1434550272
I0630 14:51:25.494005 47538 layer_factory.hpp:77] Creating layer conv5-Dropout2
I0630 14:51:25.494017 47538 net.cpp:91] Creating Layer conv5-Dropout2
I0630 14:51:25.494024 47538 net.cpp:425] conv5-Dropout2 <- conv5-Convolution3
I0630 14:51:25.494035 47538 net.cpp:399] conv5-Dropout2 -> conv5-Dropout2
I0630 14:51:25.494092 47538 net.cpp:141] Setting up conv5-Dropout2
I0630 14:51:25.494102 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.494105 47538 net.cpp:156] Memory required for data: 1436123136
I0630 14:51:25.494112 47538 layer_factory.hpp:77] Creating layer conv5-Concat2
I0630 14:51:25.494122 47538 net.cpp:91] Creating Layer conv5-Concat2
I0630 14:51:25.494127 47538 net.cpp:425] conv5-Concat2 <- conv5-Concat1_conv5-Concat1_0_split_1
I0630 14:51:25.494132 47538 net.cpp:425] conv5-Concat2 <- conv5-Dropout2
I0630 14:51:25.494140 47538 net.cpp:399] conv5-Concat2 -> conv5-Concat2
I0630 14:51:25.494174 47538 net.cpp:141] Setting up conv5-Concat2
I0630 14:51:25.494181 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.494185 47538 net.cpp:156] Memory required for data: 1451851776
I0630 14:51:25.494199 47538 layer_factory.hpp:77] Creating layer conv5-Concat2_conv5-Concat2_0_split
I0630 14:51:25.494220 47538 net.cpp:91] Creating Layer conv5-Concat2_conv5-Concat2_0_split
I0630 14:51:25.494225 47538 net.cpp:425] conv5-Concat2_conv5-Concat2_0_split <- conv5-Concat2
I0630 14:51:25.494235 47538 net.cpp:399] conv5-Concat2_conv5-Concat2_0_split -> conv5-Concat2_conv5-Concat2_0_split_0
I0630 14:51:25.494246 47538 net.cpp:399] conv5-Concat2_conv5-Concat2_0_split -> conv5-Concat2_conv5-Concat2_0_split_1
I0630 14:51:25.494299 47538 net.cpp:141] Setting up conv5-Concat2_conv5-Concat2_0_split
I0630 14:51:25.494307 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.494313 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.494318 47538 net.cpp:156] Memory required for data: 1483309056
I0630 14:51:25.494323 47538 layer_factory.hpp:77] Creating layer conv5-BatchNorm3
I0630 14:51:25.494334 47538 net.cpp:91] Creating Layer conv5-BatchNorm3
I0630 14:51:25.494339 47538 net.cpp:425] conv5-BatchNorm3 <- conv5-Concat2_conv5-Concat2_0_split_0
I0630 14:51:25.494349 47538 net.cpp:399] conv5-BatchNorm3 -> conv5-BatchNorm3
I0630 14:51:25.494627 47538 net.cpp:141] Setting up conv5-BatchNorm3
I0630 14:51:25.494637 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.494640 47538 net.cpp:156] Memory required for data: 1499037696
I0630 14:51:25.494652 47538 layer_factory.hpp:77] Creating layer conv5-Scale3
I0630 14:51:25.494662 47538 net.cpp:91] Creating Layer conv5-Scale3
I0630 14:51:25.494668 47538 net.cpp:425] conv5-Scale3 <- conv5-BatchNorm3
I0630 14:51:25.494673 47538 net.cpp:386] conv5-Scale3 -> conv5-BatchNorm3 (in-place)
I0630 14:51:25.494733 47538 layer_factory.hpp:77] Creating layer conv5-Scale3
I0630 14:51:25.494894 47538 net.cpp:141] Setting up conv5-Scale3
I0630 14:51:25.494904 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.494907 47538 net.cpp:156] Memory required for data: 1514766336
I0630 14:51:25.494916 47538 layer_factory.hpp:77] Creating layer conv5-ReLU3
I0630 14:51:25.494928 47538 net.cpp:91] Creating Layer conv5-ReLU3
I0630 14:51:25.494933 47538 net.cpp:425] conv5-ReLU3 <- conv5-BatchNorm3
I0630 14:51:25.494940 47538 net.cpp:386] conv5-ReLU3 -> conv5-BatchNorm3 (in-place)
I0630 14:51:25.497694 47538 net.cpp:141] Setting up conv5-ReLU3
I0630 14:51:25.497710 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.497715 47538 net.cpp:156] Memory required for data: 1530494976
I0630 14:51:25.497720 47538 layer_factory.hpp:77] Creating layer conv5-Convolution4
I0630 14:51:25.497737 47538 net.cpp:91] Creating Layer conv5-Convolution4
I0630 14:51:25.497743 47538 net.cpp:425] conv5-Convolution4 <- conv5-BatchNorm3
I0630 14:51:25.497756 47538 net.cpp:399] conv5-Convolution4 -> conv5-Convolution4
I0630 14:51:25.504222 47538 net.cpp:141] Setting up conv5-Convolution4
I0630 14:51:25.504243 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.504248 47538 net.cpp:156] Memory required for data: 1532067840
I0630 14:51:25.504258 47538 layer_factory.hpp:77] Creating layer conv5-Dropout3
I0630 14:51:25.504267 47538 net.cpp:91] Creating Layer conv5-Dropout3
I0630 14:51:25.504274 47538 net.cpp:425] conv5-Dropout3 <- conv5-Convolution4
I0630 14:51:25.504282 47538 net.cpp:399] conv5-Dropout3 -> conv5-Dropout3
I0630 14:51:25.504344 47538 net.cpp:141] Setting up conv5-Dropout3
I0630 14:51:25.504353 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.504357 47538 net.cpp:156] Memory required for data: 1533640704
I0630 14:51:25.504362 47538 layer_factory.hpp:77] Creating layer conv5-Concat3
I0630 14:51:25.504370 47538 net.cpp:91] Creating Layer conv5-Concat3
I0630 14:51:25.504375 47538 net.cpp:425] conv5-Concat3 <- conv5-Concat2_conv5-Concat2_0_split_1
I0630 14:51:25.504382 47538 net.cpp:425] conv5-Concat3 <- conv5-Dropout3
I0630 14:51:25.504392 47538 net.cpp:399] conv5-Concat3 -> conv5
I0630 14:51:25.504426 47538 net.cpp:141] Setting up conv5-Concat3
I0630 14:51:25.504433 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:25.504443 47538 net.cpp:156] Memory required for data: 1550942208
I0630 14:51:25.504464 47538 layer_factory.hpp:77] Creating layer conv5_bn
I0630 14:51:25.504473 47538 net.cpp:91] Creating Layer conv5_bn
I0630 14:51:25.504478 47538 net.cpp:425] conv5_bn <- conv5
I0630 14:51:25.504489 47538 net.cpp:399] conv5_bn -> conv5_bn
I0630 14:51:25.504774 47538 net.cpp:141] Setting up conv5_bn
I0630 14:51:25.504783 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:25.504787 47538 net.cpp:156] Memory required for data: 1568243712
I0630 14:51:25.504798 47538 layer_factory.hpp:77] Creating layer scale_conv5
I0630 14:51:25.504806 47538 net.cpp:91] Creating Layer scale_conv5
I0630 14:51:25.504812 47538 net.cpp:425] scale_conv5 <- conv5_bn
I0630 14:51:25.504817 47538 net.cpp:386] scale_conv5 -> conv5_bn (in-place)
I0630 14:51:25.504879 47538 layer_factory.hpp:77] Creating layer scale_conv5
I0630 14:51:25.505048 47538 net.cpp:141] Setting up scale_conv5
I0630 14:51:25.505056 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:25.505061 47538 net.cpp:156] Memory required for data: 1585545216
I0630 14:51:25.505070 47538 layer_factory.hpp:77] Creating layer relu5a
I0630 14:51:25.505076 47538 net.cpp:91] Creating Layer relu5a
I0630 14:51:25.505081 47538 net.cpp:425] relu5a <- conv5_bn
I0630 14:51:25.505090 47538 net.cpp:386] relu5a -> conv5_bn (in-place)
I0630 14:51:25.505331 47538 net.cpp:141] Setting up relu5a
I0630 14:51:25.505342 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:25.505347 47538 net.cpp:156] Memory required for data: 1602846720
I0630 14:51:25.505352 47538 layer_factory.hpp:77] Creating layer conv5_2-Convolution1
I0630 14:51:25.505383 47538 net.cpp:91] Creating Layer conv5_2-Convolution1
I0630 14:51:25.505388 47538 net.cpp:425] conv5_2-Convolution1 <- conv5_bn
I0630 14:51:25.505398 47538 net.cpp:399] conv5_2-Convolution1 -> conv5_2-Convolution1
I0630 14:51:25.532616 47538 net.cpp:141] Setting up conv5_2-Convolution1
I0630 14:51:25.532637 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.532642 47538 net.cpp:156] Memory required for data: 1615429632
I0630 14:51:25.532654 47538 layer_factory.hpp:77] Creating layer conv5_2-Convolution1_conv5_2-Convolution1_0_split
I0630 14:51:25.532663 47538 net.cpp:91] Creating Layer conv5_2-Convolution1_conv5_2-Convolution1_0_split
I0630 14:51:25.532670 47538 net.cpp:425] conv5_2-Convolution1_conv5_2-Convolution1_0_split <- conv5_2-Convolution1
I0630 14:51:25.532681 47538 net.cpp:399] conv5_2-Convolution1_conv5_2-Convolution1_0_split -> conv5_2-Convolution1_conv5_2-Convolution1_0_split_0
I0630 14:51:25.532693 47538 net.cpp:399] conv5_2-Convolution1_conv5_2-Convolution1_0_split -> conv5_2-Convolution1_conv5_2-Convolution1_0_split_1
I0630 14:51:25.532761 47538 net.cpp:141] Setting up conv5_2-Convolution1_conv5_2-Convolution1_0_split
I0630 14:51:25.532771 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.532778 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.532781 47538 net.cpp:156] Memory required for data: 1640595456
I0630 14:51:25.532786 47538 layer_factory.hpp:77] Creating layer conv5_2-BatchNorm1
I0630 14:51:25.532799 47538 net.cpp:91] Creating Layer conv5_2-BatchNorm1
I0630 14:51:25.532804 47538 net.cpp:425] conv5_2-BatchNorm1 <- conv5_2-Convolution1_conv5_2-Convolution1_0_split_0
I0630 14:51:25.532812 47538 net.cpp:399] conv5_2-BatchNorm1 -> conv5_2-BatchNorm1
I0630 14:51:25.533088 47538 net.cpp:141] Setting up conv5_2-BatchNorm1
I0630 14:51:25.533098 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.533103 47538 net.cpp:156] Memory required for data: 1653178368
I0630 14:51:25.533113 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale1
I0630 14:51:25.533120 47538 net.cpp:91] Creating Layer conv5_2-Scale1
I0630 14:51:25.533126 47538 net.cpp:425] conv5_2-Scale1 <- conv5_2-BatchNorm1
I0630 14:51:25.533136 47538 net.cpp:386] conv5_2-Scale1 -> conv5_2-BatchNorm1 (in-place)
I0630 14:51:25.533192 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale1
I0630 14:51:25.533354 47538 net.cpp:141] Setting up conv5_2-Scale1
I0630 14:51:25.533376 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.533381 47538 net.cpp:156] Memory required for data: 1665761280
I0630 14:51:25.533393 47538 layer_factory.hpp:77] Creating layer conv5_2-ReLU1
I0630 14:51:25.533403 47538 net.cpp:91] Creating Layer conv5_2-ReLU1
I0630 14:51:25.533409 47538 net.cpp:425] conv5_2-ReLU1 <- conv5_2-BatchNorm1
I0630 14:51:25.533416 47538 net.cpp:386] conv5_2-ReLU1 -> conv5_2-BatchNorm1 (in-place)
I0630 14:51:25.533677 47538 net.cpp:141] Setting up conv5_2-ReLU1
I0630 14:51:25.533689 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:25.533694 47538 net.cpp:156] Memory required for data: 1678344192
I0630 14:51:25.533699 47538 layer_factory.hpp:77] Creating layer conv5_2-Convolution2
I0630 14:51:25.533715 47538 net.cpp:91] Creating Layer conv5_2-Convolution2
I0630 14:51:25.533720 47538 net.cpp:425] conv5_2-Convolution2 <- conv5_2-BatchNorm1
I0630 14:51:25.533733 47538 net.cpp:399] conv5_2-Convolution2 -> conv5_2-Convolution2
I0630 14:51:25.537261 47538 net.cpp:141] Setting up conv5_2-Convolution2
I0630 14:51:25.537278 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.537283 47538 net.cpp:156] Memory required for data: 1679917056
I0630 14:51:25.537293 47538 layer_factory.hpp:77] Creating layer conv5_2-Dropout1
I0630 14:51:25.537302 47538 net.cpp:91] Creating Layer conv5_2-Dropout1
I0630 14:51:25.537312 47538 net.cpp:425] conv5_2-Dropout1 <- conv5_2-Convolution2
I0630 14:51:25.537320 47538 net.cpp:399] conv5_2-Dropout1 -> conv5_2-Dropout1
I0630 14:51:25.537381 47538 net.cpp:141] Setting up conv5_2-Dropout1
I0630 14:51:25.537390 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.537395 47538 net.cpp:156] Memory required for data: 1681489920
I0630 14:51:25.537400 47538 layer_factory.hpp:77] Creating layer conv5_2-Concat1
I0630 14:51:25.537412 47538 net.cpp:91] Creating Layer conv5_2-Concat1
I0630 14:51:25.537417 47538 net.cpp:425] conv5_2-Concat1 <- conv5_2-Convolution1_conv5_2-Convolution1_0_split_1
I0630 14:51:25.537423 47538 net.cpp:425] conv5_2-Concat1 <- conv5_2-Dropout1
I0630 14:51:25.537436 47538 net.cpp:399] conv5_2-Concat1 -> conv5_2-Concat1
I0630 14:51:25.537467 47538 net.cpp:141] Setting up conv5_2-Concat1
I0630 14:51:25.537478 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.537482 47538 net.cpp:156] Memory required for data: 1695645696
I0630 14:51:25.537487 47538 layer_factory.hpp:77] Creating layer conv5_2-Concat1_conv5_2-Concat1_0_split
I0630 14:51:25.537498 47538 net.cpp:91] Creating Layer conv5_2-Concat1_conv5_2-Concat1_0_split
I0630 14:51:25.537503 47538 net.cpp:425] conv5_2-Concat1_conv5_2-Concat1_0_split <- conv5_2-Concat1
I0630 14:51:25.537510 47538 net.cpp:399] conv5_2-Concat1_conv5_2-Concat1_0_split -> conv5_2-Concat1_conv5_2-Concat1_0_split_0
I0630 14:51:25.537523 47538 net.cpp:399] conv5_2-Concat1_conv5_2-Concat1_0_split -> conv5_2-Concat1_conv5_2-Concat1_0_split_1
I0630 14:51:25.537570 47538 net.cpp:141] Setting up conv5_2-Concat1_conv5_2-Concat1_0_split
I0630 14:51:25.537578 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.537585 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.537588 47538 net.cpp:156] Memory required for data: 1723957248
I0630 14:51:25.537593 47538 layer_factory.hpp:77] Creating layer conv5_2-BatchNorm2
I0630 14:51:25.537606 47538 net.cpp:91] Creating Layer conv5_2-BatchNorm2
I0630 14:51:25.537611 47538 net.cpp:425] conv5_2-BatchNorm2 <- conv5_2-Concat1_conv5_2-Concat1_0_split_0
I0630 14:51:25.537621 47538 net.cpp:399] conv5_2-BatchNorm2 -> conv5_2-BatchNorm2
I0630 14:51:25.537900 47538 net.cpp:141] Setting up conv5_2-BatchNorm2
I0630 14:51:25.537909 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.537914 47538 net.cpp:156] Memory required for data: 1738113024
I0630 14:51:25.537923 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale2
I0630 14:51:25.537935 47538 net.cpp:91] Creating Layer conv5_2-Scale2
I0630 14:51:25.537945 47538 net.cpp:425] conv5_2-Scale2 <- conv5_2-BatchNorm2
I0630 14:51:25.537967 47538 net.cpp:386] conv5_2-Scale2 -> conv5_2-BatchNorm2 (in-place)
I0630 14:51:25.538033 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale2
I0630 14:51:25.538204 47538 net.cpp:141] Setting up conv5_2-Scale2
I0630 14:51:25.538213 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.538218 47538 net.cpp:156] Memory required for data: 1752268800
I0630 14:51:25.538226 47538 layer_factory.hpp:77] Creating layer conv5_2-ReLU2
I0630 14:51:25.538233 47538 net.cpp:91] Creating Layer conv5_2-ReLU2
I0630 14:51:25.538239 47538 net.cpp:425] conv5_2-ReLU2 <- conv5_2-BatchNorm2
I0630 14:51:25.538249 47538 net.cpp:386] conv5_2-ReLU2 -> conv5_2-BatchNorm2 (in-place)
I0630 14:51:25.538486 47538 net.cpp:141] Setting up conv5_2-ReLU2
I0630 14:51:25.538497 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:25.538501 47538 net.cpp:156] Memory required for data: 1766424576
I0630 14:51:25.538506 47538 layer_factory.hpp:77] Creating layer conv5_2-Convolution3
I0630 14:51:25.538522 47538 net.cpp:91] Creating Layer conv5_2-Convolution3
I0630 14:51:25.538528 47538 net.cpp:425] conv5_2-Convolution3 <- conv5_2-BatchNorm2
I0630 14:51:25.538540 47538 net.cpp:399] conv5_2-Convolution3 -> conv5_2-Convolution3
I0630 14:51:25.546516 47538 net.cpp:141] Setting up conv5_2-Convolution3
I0630 14:51:25.546533 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.546540 47538 net.cpp:156] Memory required for data: 1767997440
I0630 14:51:25.546548 47538 layer_factory.hpp:77] Creating layer conv5_2-Dropout2
I0630 14:51:25.546561 47538 net.cpp:91] Creating Layer conv5_2-Dropout2
I0630 14:51:25.546566 47538 net.cpp:425] conv5_2-Dropout2 <- conv5_2-Convolution3
I0630 14:51:25.546576 47538 net.cpp:399] conv5_2-Dropout2 -> conv5_2-Dropout2
I0630 14:51:25.546639 47538 net.cpp:141] Setting up conv5_2-Dropout2
I0630 14:51:25.546648 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.546653 47538 net.cpp:156] Memory required for data: 1769570304
I0630 14:51:25.546661 47538 layer_factory.hpp:77] Creating layer conv5_2-Concat2
I0630 14:51:25.546669 47538 net.cpp:91] Creating Layer conv5_2-Concat2
I0630 14:51:25.546674 47538 net.cpp:425] conv5_2-Concat2 <- conv5_2-Concat1_conv5_2-Concat1_0_split_1
I0630 14:51:25.546680 47538 net.cpp:425] conv5_2-Concat2 <- conv5_2-Dropout2
I0630 14:51:25.546692 47538 net.cpp:399] conv5_2-Concat2 -> conv5_2-Concat2
I0630 14:51:25.546727 47538 net.cpp:141] Setting up conv5_2-Concat2
I0630 14:51:25.546736 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.546739 47538 net.cpp:156] Memory required for data: 1785298944
I0630 14:51:25.546744 47538 layer_factory.hpp:77] Creating layer conv5_2-Concat2_conv5_2-Concat2_0_split
I0630 14:51:25.546752 47538 net.cpp:91] Creating Layer conv5_2-Concat2_conv5_2-Concat2_0_split
I0630 14:51:25.546757 47538 net.cpp:425] conv5_2-Concat2_conv5_2-Concat2_0_split <- conv5_2-Concat2
I0630 14:51:25.546767 47538 net.cpp:399] conv5_2-Concat2_conv5_2-Concat2_0_split -> conv5_2-Concat2_conv5_2-Concat2_0_split_0
I0630 14:51:25.546777 47538 net.cpp:399] conv5_2-Concat2_conv5_2-Concat2_0_split -> conv5_2-Concat2_conv5_2-Concat2_0_split_1
I0630 14:51:25.546826 47538 net.cpp:141] Setting up conv5_2-Concat2_conv5_2-Concat2_0_split
I0630 14:51:25.546833 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.546839 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.546844 47538 net.cpp:156] Memory required for data: 1816756224
I0630 14:51:25.546849 47538 layer_factory.hpp:77] Creating layer conv5_2-BatchNorm3
I0630 14:51:25.546864 47538 net.cpp:91] Creating Layer conv5_2-BatchNorm3
I0630 14:51:25.546869 47538 net.cpp:425] conv5_2-BatchNorm3 <- conv5_2-Concat2_conv5_2-Concat2_0_split_0
I0630 14:51:25.546876 47538 net.cpp:399] conv5_2-BatchNorm3 -> conv5_2-BatchNorm3
I0630 14:51:25.547171 47538 net.cpp:141] Setting up conv5_2-BatchNorm3
I0630 14:51:25.547181 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.547189 47538 net.cpp:156] Memory required for data: 1832484864
I0630 14:51:25.547214 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale3
I0630 14:51:25.547224 47538 net.cpp:91] Creating Layer conv5_2-Scale3
I0630 14:51:25.547230 47538 net.cpp:425] conv5_2-Scale3 <- conv5_2-BatchNorm3
I0630 14:51:25.547238 47538 net.cpp:386] conv5_2-Scale3 -> conv5_2-BatchNorm3 (in-place)
I0630 14:51:25.547304 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale3
I0630 14:51:25.547475 47538 net.cpp:141] Setting up conv5_2-Scale3
I0630 14:51:25.547484 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.547488 47538 net.cpp:156] Memory required for data: 1848213504
I0630 14:51:25.547497 47538 layer_factory.hpp:77] Creating layer conv5_2-ReLU3
I0630 14:51:25.547504 47538 net.cpp:91] Creating Layer conv5_2-ReLU3
I0630 14:51:25.547509 47538 net.cpp:425] conv5_2-ReLU3 <- conv5_2-BatchNorm3
I0630 14:51:25.547518 47538 net.cpp:386] conv5_2-ReLU3 -> conv5_2-BatchNorm3 (in-place)
I0630 14:51:25.547760 47538 net.cpp:141] Setting up conv5_2-ReLU3
I0630 14:51:25.547771 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:25.547776 47538 net.cpp:156] Memory required for data: 1863942144
I0630 14:51:25.547780 47538 layer_factory.hpp:77] Creating layer conv5_2-Convolution4
I0630 14:51:25.547796 47538 net.cpp:91] Creating Layer conv5_2-Convolution4
I0630 14:51:25.547802 47538 net.cpp:425] conv5_2-Convolution4 <- conv5_2-BatchNorm3
I0630 14:51:25.547813 47538 net.cpp:399] conv5_2-Convolution4 -> conv5_2-Convolution4
I0630 14:51:25.554379 47538 net.cpp:141] Setting up conv5_2-Convolution4
I0630 14:51:25.554397 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.554402 47538 net.cpp:156] Memory required for data: 1865515008
I0630 14:51:25.554411 47538 layer_factory.hpp:77] Creating layer conv5_2-Dropout3
I0630 14:51:25.554425 47538 net.cpp:91] Creating Layer conv5_2-Dropout3
I0630 14:51:25.554431 47538 net.cpp:425] conv5_2-Dropout3 <- conv5_2-Convolution4
I0630 14:51:25.554440 47538 net.cpp:399] conv5_2-Dropout3 -> conv5_2-Dropout3
I0630 14:51:25.554503 47538 net.cpp:141] Setting up conv5_2-Dropout3
I0630 14:51:25.554512 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:25.554517 47538 net.cpp:156] Memory required for data: 1867087872
I0630 14:51:25.554524 47538 layer_factory.hpp:77] Creating layer conv5_2-Concat3
I0630 14:51:25.554533 47538 net.cpp:91] Creating Layer conv5_2-Concat3
I0630 14:51:25.554538 47538 net.cpp:425] conv5_2-Concat3 <- conv5_2-Concat2_conv5_2-Concat2_0_split_1
I0630 14:51:25.554545 47538 net.cpp:425] conv5_2-Concat3 <- conv5_2-Dropout3
I0630 14:51:25.554555 47538 net.cpp:399] conv5_2-Concat3 -> conv5_2
I0630 14:51:25.554590 47538 net.cpp:141] Setting up conv5_2-Concat3
I0630 14:51:25.554599 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:25.554603 47538 net.cpp:156] Memory required for data: 1884389376
I0630 14:51:25.554607 47538 layer_factory.hpp:77] Creating layer conv5_2_bn
I0630 14:51:25.554615 47538 net.cpp:91] Creating Layer conv5_2_bn
I0630 14:51:25.554621 47538 net.cpp:425] conv5_2_bn <- conv5_2
I0630 14:51:25.554632 47538 net.cpp:399] conv5_2_bn -> conv5_2_bn
I0630 14:51:25.554929 47538 net.cpp:141] Setting up conv5_2_bn
I0630 14:51:25.554937 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:25.554942 47538 net.cpp:156] Memory required for data: 1901690880
I0630 14:51:25.554952 47538 layer_factory.hpp:77] Creating layer scale_conv5_2
I0630 14:51:25.554960 47538 net.cpp:91] Creating Layer scale_conv5_2
I0630 14:51:25.554965 47538 net.cpp:425] scale_conv5_2 <- conv5_2_bn
I0630 14:51:25.554980 47538 net.cpp:386] scale_conv5_2 -> conv5_2_bn (in-place)
I0630 14:51:25.555045 47538 layer_factory.hpp:77] Creating layer scale_conv5_2
I0630 14:51:25.555215 47538 net.cpp:141] Setting up scale_conv5_2
I0630 14:51:25.555224 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:25.555229 47538 net.cpp:156] Memory required for data: 1918992384
I0630 14:51:25.555238 47538 layer_factory.hpp:77] Creating layer relu5a_2
I0630 14:51:25.555253 47538 net.cpp:91] Creating Layer relu5a_2
I0630 14:51:25.555270 47538 net.cpp:425] relu5a_2 <- conv5_2_bn
I0630 14:51:25.555280 47538 net.cpp:386] relu5a_2 -> conv5_2_bn (in-place)
I0630 14:51:25.556409 47538 net.cpp:141] Setting up relu5a_2
I0630 14:51:25.556427 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:25.556432 47538 net.cpp:156] Memory required for data: 1936293888
I0630 14:51:25.556437 47538 layer_factory.hpp:77] Creating layer deconv6
I0630 14:51:25.556452 47538 net.cpp:91] Creating Layer deconv6
I0630 14:51:25.556458 47538 net.cpp:425] deconv6 <- conv5_2_bn
I0630 14:51:25.556466 47538 net.cpp:399] deconv6 -> deconv6
I0630 14:51:25.570029 47538 net.cpp:141] Setting up deconv6
I0630 14:51:25.570046 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.570051 47538 net.cpp:156] Memory required for data: 1961459712
I0630 14:51:25.570061 47538 layer_factory.hpp:77] Creating layer concat32
I0630 14:51:25.570073 47538 net.cpp:91] Creating Layer concat32
I0630 14:51:25.570080 47538 net.cpp:425] concat32 <- conv1c_conv1c_0_split_1
I0630 14:51:25.570087 47538 net.cpp:425] concat32 <- deconv6
I0630 14:51:25.570094 47538 net.cpp:399] concat32 -> concat32
I0630 14:51:25.570137 47538 net.cpp:141] Setting up concat32
I0630 14:51:25.570144 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:25.570150 47538 net.cpp:156] Memory required for data: 2011791360
I0630 14:51:25.570154 47538 layer_factory.hpp:77] Creating layer conv6-Convolution1
I0630 14:51:25.570168 47538 net.cpp:91] Creating Layer conv6-Convolution1
I0630 14:51:25.570173 47538 net.cpp:425] conv6-Convolution1 <- concat32
I0630 14:51:25.570186 47538 net.cpp:399] conv6-Convolution1 -> conv6-Convolution1
I0630 14:51:25.585556 47538 net.cpp:141] Setting up conv6-Convolution1
I0630 14:51:25.585578 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:25.585583 47538 net.cpp:156] Memory required for data: 2062123008
I0630 14:51:25.585597 47538 layer_factory.hpp:77] Creating layer conv6-Convolution1_conv6-Convolution1_0_split
I0630 14:51:25.585606 47538 net.cpp:91] Creating Layer conv6-Convolution1_conv6-Convolution1_0_split
I0630 14:51:25.585613 47538 net.cpp:425] conv6-Convolution1_conv6-Convolution1_0_split <- conv6-Convolution1
I0630 14:51:25.585620 47538 net.cpp:399] conv6-Convolution1_conv6-Convolution1_0_split -> conv6-Convolution1_conv6-Convolution1_0_split_0
I0630 14:51:25.585634 47538 net.cpp:399] conv6-Convolution1_conv6-Convolution1_0_split -> conv6-Convolution1_conv6-Convolution1_0_split_1
I0630 14:51:25.585701 47538 net.cpp:141] Setting up conv6-Convolution1_conv6-Convolution1_0_split
I0630 14:51:25.585709 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:25.585716 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:25.585721 47538 net.cpp:156] Memory required for data: 2162786304
I0630 14:51:25.585726 47538 layer_factory.hpp:77] Creating layer conv6-BatchNorm1
I0630 14:51:25.585736 47538 net.cpp:91] Creating Layer conv6-BatchNorm1
I0630 14:51:25.585741 47538 net.cpp:425] conv6-BatchNorm1 <- conv6-Convolution1_conv6-Convolution1_0_split_0
I0630 14:51:25.585752 47538 net.cpp:399] conv6-BatchNorm1 -> conv6-BatchNorm1
I0630 14:51:25.586069 47538 net.cpp:141] Setting up conv6-BatchNorm1
I0630 14:51:25.586079 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:25.586083 47538 net.cpp:156] Memory required for data: 2213117952
I0630 14:51:25.586094 47538 layer_factory.hpp:77] Creating layer conv6-Scale1
I0630 14:51:25.586102 47538 net.cpp:91] Creating Layer conv6-Scale1
I0630 14:51:25.586107 47538 net.cpp:425] conv6-Scale1 <- conv6-BatchNorm1
I0630 14:51:25.586114 47538 net.cpp:386] conv6-Scale1 -> conv6-BatchNorm1 (in-place)
I0630 14:51:25.586174 47538 layer_factory.hpp:77] Creating layer conv6-Scale1
I0630 14:51:25.589768 47538 net.cpp:141] Setting up conv6-Scale1
I0630 14:51:25.589784 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:25.589789 47538 net.cpp:156] Memory required for data: 2263449600
I0630 14:51:25.589804 47538 layer_factory.hpp:77] Creating layer conv6-ReLU1
I0630 14:51:25.589826 47538 net.cpp:91] Creating Layer conv6-ReLU1
I0630 14:51:25.589833 47538 net.cpp:425] conv6-ReLU1 <- conv6-BatchNorm1
I0630 14:51:25.589843 47538 net.cpp:386] conv6-ReLU1 -> conv6-BatchNorm1 (in-place)
I0630 14:51:25.590889 47538 net.cpp:141] Setting up conv6-ReLU1
I0630 14:51:25.590905 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:25.590910 47538 net.cpp:156] Memory required for data: 2313781248
I0630 14:51:25.590919 47538 layer_factory.hpp:77] Creating layer conv6-Convolution2
I0630 14:51:25.590934 47538 net.cpp:91] Creating Layer conv6-Convolution2
I0630 14:51:25.590940 47538 net.cpp:425] conv6-Convolution2 <- conv6-BatchNorm1
I0630 14:51:25.590953 47538 net.cpp:399] conv6-Convolution2 -> conv6-Convolution2
I0630 14:51:25.596271 47538 net.cpp:141] Setting up conv6-Convolution2
I0630 14:51:25.596287 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.596292 47538 net.cpp:156] Memory required for data: 2320072704
I0630 14:51:25.596302 47538 layer_factory.hpp:77] Creating layer conv6-Dropout1
I0630 14:51:25.596312 47538 net.cpp:91] Creating Layer conv6-Dropout1
I0630 14:51:25.596318 47538 net.cpp:425] conv6-Dropout1 <- conv6-Convolution2
I0630 14:51:25.596328 47538 net.cpp:399] conv6-Dropout1 -> conv6-Dropout1
I0630 14:51:25.596396 47538 net.cpp:141] Setting up conv6-Dropout1
I0630 14:51:25.596405 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.596410 47538 net.cpp:156] Memory required for data: 2326364160
I0630 14:51:25.596415 47538 layer_factory.hpp:77] Creating layer conv6-Concat1
I0630 14:51:25.596424 47538 net.cpp:91] Creating Layer conv6-Concat1
I0630 14:51:25.596429 47538 net.cpp:425] conv6-Concat1 <- conv6-Convolution1_conv6-Convolution1_0_split_1
I0630 14:51:25.596436 47538 net.cpp:425] conv6-Concat1 <- conv6-Dropout1
I0630 14:51:25.596449 47538 net.cpp:399] conv6-Concat1 -> conv6-Concat1
I0630 14:51:25.596482 47538 net.cpp:141] Setting up conv6-Concat1
I0630 14:51:25.596489 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:25.596494 47538 net.cpp:156] Memory required for data: 2382987264
I0630 14:51:25.596503 47538 layer_factory.hpp:77] Creating layer conv6-Concat1_conv6-Concat1_0_split
I0630 14:51:25.596513 47538 net.cpp:91] Creating Layer conv6-Concat1_conv6-Concat1_0_split
I0630 14:51:25.596518 47538 net.cpp:425] conv6-Concat1_conv6-Concat1_0_split <- conv6-Concat1
I0630 14:51:25.596525 47538 net.cpp:399] conv6-Concat1_conv6-Concat1_0_split -> conv6-Concat1_conv6-Concat1_0_split_0
I0630 14:51:25.596537 47538 net.cpp:399] conv6-Concat1_conv6-Concat1_0_split -> conv6-Concat1_conv6-Concat1_0_split_1
I0630 14:51:25.596586 47538 net.cpp:141] Setting up conv6-Concat1_conv6-Concat1_0_split
I0630 14:51:25.596594 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:25.596601 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:25.596606 47538 net.cpp:156] Memory required for data: 2496233472
I0630 14:51:25.596609 47538 layer_factory.hpp:77] Creating layer conv6-BatchNorm2
I0630 14:51:25.596621 47538 net.cpp:91] Creating Layer conv6-BatchNorm2
I0630 14:51:25.596627 47538 net.cpp:425] conv6-BatchNorm2 <- conv6-Concat1_conv6-Concat1_0_split_0
I0630 14:51:25.596637 47538 net.cpp:399] conv6-BatchNorm2 -> conv6-BatchNorm2
I0630 14:51:25.596941 47538 net.cpp:141] Setting up conv6-BatchNorm2
I0630 14:51:25.596951 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:25.596956 47538 net.cpp:156] Memory required for data: 2552856576
I0630 14:51:25.596966 47538 layer_factory.hpp:77] Creating layer conv6-Scale2
I0630 14:51:25.596976 47538 net.cpp:91] Creating Layer conv6-Scale2
I0630 14:51:25.596982 47538 net.cpp:425] conv6-Scale2 <- conv6-BatchNorm2
I0630 14:51:25.596989 47538 net.cpp:386] conv6-Scale2 -> conv6-BatchNorm2 (in-place)
I0630 14:51:25.597045 47538 layer_factory.hpp:77] Creating layer conv6-Scale2
I0630 14:51:25.597252 47538 net.cpp:141] Setting up conv6-Scale2
I0630 14:51:25.597266 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:25.597285 47538 net.cpp:156] Memory required for data: 2609479680
I0630 14:51:25.597295 47538 layer_factory.hpp:77] Creating layer conv6-ReLU2
I0630 14:51:25.597306 47538 net.cpp:91] Creating Layer conv6-ReLU2
I0630 14:51:25.597311 47538 net.cpp:425] conv6-ReLU2 <- conv6-BatchNorm2
I0630 14:51:25.597321 47538 net.cpp:386] conv6-ReLU2 -> conv6-BatchNorm2 (in-place)
I0630 14:51:25.597568 47538 net.cpp:141] Setting up conv6-ReLU2
I0630 14:51:25.597579 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:25.597584 47538 net.cpp:156] Memory required for data: 2666102784
I0630 14:51:25.597590 47538 layer_factory.hpp:77] Creating layer conv6-Convolution3
I0630 14:51:25.597605 47538 net.cpp:91] Creating Layer conv6-Convolution3
I0630 14:51:25.597611 47538 net.cpp:425] conv6-Convolution3 <- conv6-BatchNorm2
I0630 14:51:25.597622 47538 net.cpp:399] conv6-Convolution3 -> conv6-Convolution3
I0630 14:51:25.600962 47538 net.cpp:141] Setting up conv6-Convolution3
I0630 14:51:25.600978 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.600983 47538 net.cpp:156] Memory required for data: 2672394240
I0630 14:51:25.600992 47538 layer_factory.hpp:77] Creating layer conv6-Dropout2
I0630 14:51:25.601002 47538 net.cpp:91] Creating Layer conv6-Dropout2
I0630 14:51:25.601008 47538 net.cpp:425] conv6-Dropout2 <- conv6-Convolution3
I0630 14:51:25.601016 47538 net.cpp:399] conv6-Dropout2 -> conv6-Dropout2
I0630 14:51:25.601084 47538 net.cpp:141] Setting up conv6-Dropout2
I0630 14:51:25.601094 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.601099 47538 net.cpp:156] Memory required for data: 2678685696
I0630 14:51:25.601104 47538 layer_factory.hpp:77] Creating layer conv6-Concat2
I0630 14:51:25.601114 47538 net.cpp:91] Creating Layer conv6-Concat2
I0630 14:51:25.601120 47538 net.cpp:425] conv6-Concat2 <- conv6-Concat1_conv6-Concat1_0_split_1
I0630 14:51:25.601126 47538 net.cpp:425] conv6-Concat2 <- conv6-Dropout2
I0630 14:51:25.601133 47538 net.cpp:399] conv6-Concat2 -> conv6-Concat2
I0630 14:51:25.601168 47538 net.cpp:141] Setting up conv6-Concat2
I0630 14:51:25.601177 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:25.601181 47538 net.cpp:156] Memory required for data: 2741600256
I0630 14:51:25.601189 47538 layer_factory.hpp:77] Creating layer conv6-Concat2_conv6-Concat2_0_split
I0630 14:51:25.601197 47538 net.cpp:91] Creating Layer conv6-Concat2_conv6-Concat2_0_split
I0630 14:51:25.601203 47538 net.cpp:425] conv6-Concat2_conv6-Concat2_0_split <- conv6-Concat2
I0630 14:51:25.601212 47538 net.cpp:399] conv6-Concat2_conv6-Concat2_0_split -> conv6-Concat2_conv6-Concat2_0_split_0
I0630 14:51:25.601222 47538 net.cpp:399] conv6-Concat2_conv6-Concat2_0_split -> conv6-Concat2_conv6-Concat2_0_split_1
I0630 14:51:25.601275 47538 net.cpp:141] Setting up conv6-Concat2_conv6-Concat2_0_split
I0630 14:51:25.601284 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:25.601289 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:25.601294 47538 net.cpp:156] Memory required for data: 2867429376
I0630 14:51:25.601298 47538 layer_factory.hpp:77] Creating layer conv6-BatchNorm3
I0630 14:51:25.601310 47538 net.cpp:91] Creating Layer conv6-BatchNorm3
I0630 14:51:25.601315 47538 net.cpp:425] conv6-BatchNorm3 <- conv6-Concat2_conv6-Concat2_0_split_0
I0630 14:51:25.601322 47538 net.cpp:399] conv6-BatchNorm3 -> conv6-BatchNorm3
I0630 14:51:25.601629 47538 net.cpp:141] Setting up conv6-BatchNorm3
I0630 14:51:25.601639 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:25.601642 47538 net.cpp:156] Memory required for data: 2930343936
I0630 14:51:25.601652 47538 layer_factory.hpp:77] Creating layer conv6-Scale3
I0630 14:51:25.601665 47538 net.cpp:91] Creating Layer conv6-Scale3
I0630 14:51:25.601671 47538 net.cpp:425] conv6-Scale3 <- conv6-BatchNorm3
I0630 14:51:25.601678 47538 net.cpp:386] conv6-Scale3 -> conv6-BatchNorm3 (in-place)
I0630 14:51:25.601737 47538 layer_factory.hpp:77] Creating layer conv6-Scale3
I0630 14:51:25.601953 47538 net.cpp:141] Setting up conv6-Scale3
I0630 14:51:25.601976 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:25.601981 47538 net.cpp:156] Memory required for data: 2993258496
I0630 14:51:25.601991 47538 layer_factory.hpp:77] Creating layer conv6-ReLU3
I0630 14:51:25.602001 47538 net.cpp:91] Creating Layer conv6-ReLU3
I0630 14:51:25.602007 47538 net.cpp:425] conv6-ReLU3 <- conv6-BatchNorm3
I0630 14:51:25.602015 47538 net.cpp:386] conv6-ReLU3 -> conv6-BatchNorm3 (in-place)
I0630 14:51:25.602268 47538 net.cpp:141] Setting up conv6-ReLU3
I0630 14:51:25.602279 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:25.602285 47538 net.cpp:156] Memory required for data: 3056173056
I0630 14:51:25.602290 47538 layer_factory.hpp:77] Creating layer conv6-Convolution4
I0630 14:51:25.602305 47538 net.cpp:91] Creating Layer conv6-Convolution4
I0630 14:51:25.602310 47538 net.cpp:425] conv6-Convolution4 <- conv6-BatchNorm3
I0630 14:51:25.602325 47538 net.cpp:399] conv6-Convolution4 -> conv6-Convolution4
I0630 14:51:25.609656 47538 net.cpp:141] Setting up conv6-Convolution4
I0630 14:51:25.609673 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.609678 47538 net.cpp:156] Memory required for data: 3062464512
I0630 14:51:25.609688 47538 layer_factory.hpp:77] Creating layer conv6-Dropout3
I0630 14:51:25.609700 47538 net.cpp:91] Creating Layer conv6-Dropout3
I0630 14:51:25.609706 47538 net.cpp:425] conv6-Dropout3 <- conv6-Convolution4
I0630 14:51:25.609714 47538 net.cpp:399] conv6-Dropout3 -> conv6-Dropout3
I0630 14:51:25.609787 47538 net.cpp:141] Setting up conv6-Dropout3
I0630 14:51:25.609795 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.609800 47538 net.cpp:156] Memory required for data: 3068755968
I0630 14:51:25.609807 47538 layer_factory.hpp:77] Creating layer conv6-Concat3
I0630 14:51:25.609817 47538 net.cpp:91] Creating Layer conv6-Concat3
I0630 14:51:25.609822 47538 net.cpp:425] conv6-Concat3 <- conv6-Concat2_conv6-Concat2_0_split_1
I0630 14:51:25.609828 47538 net.cpp:425] conv6-Concat3 <- conv6-Dropout3
I0630 14:51:25.609838 47538 net.cpp:399] conv6-Concat3 -> conv6
I0630 14:51:25.609872 47538 net.cpp:141] Setting up conv6-Concat3
I0630 14:51:25.609882 47538 net.cpp:148] Top shape: 3 176 32 32 32 (17301504)
I0630 14:51:25.609887 47538 net.cpp:156] Memory required for data: 3137961984
I0630 14:51:25.609891 47538 layer_factory.hpp:77] Creating layer conv6_bn
I0630 14:51:25.609900 47538 net.cpp:91] Creating Layer conv6_bn
I0630 14:51:25.609905 47538 net.cpp:425] conv6_bn <- conv6
I0630 14:51:25.609915 47538 net.cpp:399] conv6_bn -> conv6_bn
I0630 14:51:25.610231 47538 net.cpp:141] Setting up conv6_bn
I0630 14:51:25.610241 47538 net.cpp:148] Top shape: 3 176 32 32 32 (17301504)
I0630 14:51:25.610246 47538 net.cpp:156] Memory required for data: 3207168000
I0630 14:51:25.610256 47538 layer_factory.hpp:77] Creating layer scale_conv6_fine
I0630 14:51:25.610267 47538 net.cpp:91] Creating Layer scale_conv6_fine
I0630 14:51:25.610273 47538 net.cpp:425] scale_conv6_fine <- conv6_bn
I0630 14:51:25.610280 47538 net.cpp:386] scale_conv6_fine -> conv6_bn (in-place)
I0630 14:51:25.610337 47538 layer_factory.hpp:77] Creating layer scale_conv6_fine
I0630 14:51:25.612524 47538 net.cpp:141] Setting up scale_conv6_fine
I0630 14:51:25.612540 47538 net.cpp:148] Top shape: 3 176 32 32 32 (17301504)
I0630 14:51:25.612545 47538 net.cpp:156] Memory required for data: 3276374016
I0630 14:51:25.612555 47538 layer_factory.hpp:77] Creating layer relu6
I0630 14:51:25.612562 47538 net.cpp:91] Creating Layer relu6
I0630 14:51:25.612569 47538 net.cpp:425] relu6 <- conv6_bn
I0630 14:51:25.612579 47538 net.cpp:386] relu6 -> conv6_bn (in-place)
I0630 14:51:25.612843 47538 net.cpp:141] Setting up relu6
I0630 14:51:25.612854 47538 net.cpp:148] Top shape: 3 176 32 32 32 (17301504)
I0630 14:51:25.612860 47538 net.cpp:156] Memory required for data: 3345580032
I0630 14:51:25.612869 47538 layer_factory.hpp:77] Creating layer conv6_2-Convolution1
I0630 14:51:25.612887 47538 net.cpp:91] Creating Layer conv6_2-Convolution1
I0630 14:51:25.612906 47538 net.cpp:425] conv6_2-Convolution1 <- conv6_bn
I0630 14:51:25.612920 47538 net.cpp:399] conv6_2-Convolution1 -> conv6_2-Convolution1
I0630 14:51:25.626179 47538 net.cpp:141] Setting up conv6_2-Convolution1
I0630 14:51:25.626195 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.626200 47538 net.cpp:156] Memory required for data: 3370745856
I0630 14:51:25.626211 47538 layer_factory.hpp:77] Creating layer conv6_2-Convolution1_conv6_2-Convolution1_0_split
I0630 14:51:25.626224 47538 net.cpp:91] Creating Layer conv6_2-Convolution1_conv6_2-Convolution1_0_split
I0630 14:51:25.626230 47538 net.cpp:425] conv6_2-Convolution1_conv6_2-Convolution1_0_split <- conv6_2-Convolution1
I0630 14:51:25.626237 47538 net.cpp:399] conv6_2-Convolution1_conv6_2-Convolution1_0_split -> conv6_2-Convolution1_conv6_2-Convolution1_0_split_0
I0630 14:51:25.626251 47538 net.cpp:399] conv6_2-Convolution1_conv6_2-Convolution1_0_split -> conv6_2-Convolution1_conv6_2-Convolution1_0_split_1
I0630 14:51:25.626317 47538 net.cpp:141] Setting up conv6_2-Convolution1_conv6_2-Convolution1_0_split
I0630 14:51:25.626327 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.626332 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.626338 47538 net.cpp:156] Memory required for data: 3421077504
I0630 14:51:25.626343 47538 layer_factory.hpp:77] Creating layer conv6_2-BatchNorm1
I0630 14:51:25.626353 47538 net.cpp:91] Creating Layer conv6_2-BatchNorm1
I0630 14:51:25.626358 47538 net.cpp:425] conv6_2-BatchNorm1 <- conv6_2-Convolution1_conv6_2-Convolution1_0_split_0
I0630 14:51:25.626369 47538 net.cpp:399] conv6_2-BatchNorm1 -> conv6_2-BatchNorm1
I0630 14:51:25.626694 47538 net.cpp:141] Setting up conv6_2-BatchNorm1
I0630 14:51:25.626703 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.626708 47538 net.cpp:156] Memory required for data: 3446243328
I0630 14:51:25.626718 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale1
I0630 14:51:25.626729 47538 net.cpp:91] Creating Layer conv6_2-Scale1
I0630 14:51:25.626734 47538 net.cpp:425] conv6_2-Scale1 <- conv6_2-BatchNorm1
I0630 14:51:25.626741 47538 net.cpp:386] conv6_2-Scale1 -> conv6_2-BatchNorm1 (in-place)
I0630 14:51:25.626802 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale1
I0630 14:51:25.627023 47538 net.cpp:141] Setting up conv6_2-Scale1
I0630 14:51:25.627033 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.627038 47538 net.cpp:156] Memory required for data: 3471409152
I0630 14:51:25.627046 47538 layer_factory.hpp:77] Creating layer conv6_2-ReLU1
I0630 14:51:25.627056 47538 net.cpp:91] Creating Layer conv6_2-ReLU1
I0630 14:51:25.627063 47538 net.cpp:425] conv6_2-ReLU1 <- conv6_2-BatchNorm1
I0630 14:51:25.627068 47538 net.cpp:386] conv6_2-ReLU1 -> conv6_2-BatchNorm1 (in-place)
I0630 14:51:25.627323 47538 net.cpp:141] Setting up conv6_2-ReLU1
I0630 14:51:25.627337 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:25.627342 47538 net.cpp:156] Memory required for data: 3496574976
I0630 14:51:25.627347 47538 layer_factory.hpp:77] Creating layer conv6_2-Convolution2
I0630 14:51:25.627363 47538 net.cpp:91] Creating Layer conv6_2-Convolution2
I0630 14:51:25.627369 47538 net.cpp:425] conv6_2-Convolution2 <- conv6_2-BatchNorm1
I0630 14:51:25.627380 47538 net.cpp:399] conv6_2-Convolution2 -> conv6_2-Convolution2
I0630 14:51:25.640314 47538 net.cpp:141] Setting up conv6_2-Convolution2
I0630 14:51:25.640331 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.640336 47538 net.cpp:156] Memory required for data: 3502866432
I0630 14:51:25.640349 47538 layer_factory.hpp:77] Creating layer conv6_2-Dropout1
I0630 14:51:25.640362 47538 net.cpp:91] Creating Layer conv6_2-Dropout1
I0630 14:51:25.640368 47538 net.cpp:425] conv6_2-Dropout1 <- conv6_2-Convolution2
I0630 14:51:25.640379 47538 net.cpp:399] conv6_2-Dropout1 -> conv6_2-Dropout1
I0630 14:51:25.640447 47538 net.cpp:141] Setting up conv6_2-Dropout1
I0630 14:51:25.640462 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.640480 47538 net.cpp:156] Memory required for data: 3509157888
I0630 14:51:25.640488 47538 layer_factory.hpp:77] Creating layer conv6_2-Concat1
I0630 14:51:25.640496 47538 net.cpp:91] Creating Layer conv6_2-Concat1
I0630 14:51:25.640502 47538 net.cpp:425] conv6_2-Concat1 <- conv6_2-Convolution1_conv6_2-Convolution1_0_split_1
I0630 14:51:25.640509 47538 net.cpp:425] conv6_2-Concat1 <- conv6_2-Dropout1
I0630 14:51:25.640517 47538 net.cpp:399] conv6_2-Concat1 -> conv6_2-Concat1
I0630 14:51:25.640560 47538 net.cpp:141] Setting up conv6_2-Concat1
I0630 14:51:25.640568 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.640574 47538 net.cpp:156] Memory required for data: 3540615168
I0630 14:51:25.640578 47538 layer_factory.hpp:77] Creating layer conv6_2-Concat1_conv6_2-Concat1_0_split
I0630 14:51:25.640588 47538 net.cpp:91] Creating Layer conv6_2-Concat1_conv6_2-Concat1_0_split
I0630 14:51:25.640594 47538 net.cpp:425] conv6_2-Concat1_conv6_2-Concat1_0_split <- conv6_2-Concat1
I0630 14:51:25.640602 47538 net.cpp:399] conv6_2-Concat1_conv6_2-Concat1_0_split -> conv6_2-Concat1_conv6_2-Concat1_0_split_0
I0630 14:51:25.640611 47538 net.cpp:399] conv6_2-Concat1_conv6_2-Concat1_0_split -> conv6_2-Concat1_conv6_2-Concat1_0_split_1
I0630 14:51:25.640666 47538 net.cpp:141] Setting up conv6_2-Concat1_conv6_2-Concat1_0_split
I0630 14:51:25.640673 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.640679 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.640684 47538 net.cpp:156] Memory required for data: 3603529728
I0630 14:51:25.640688 47538 layer_factory.hpp:77] Creating layer conv6_2-BatchNorm2
I0630 14:51:25.640702 47538 net.cpp:91] Creating Layer conv6_2-BatchNorm2
I0630 14:51:25.640707 47538 net.cpp:425] conv6_2-BatchNorm2 <- conv6_2-Concat1_conv6_2-Concat1_0_split_0
I0630 14:51:25.640717 47538 net.cpp:399] conv6_2-BatchNorm2 -> conv6_2-BatchNorm2
I0630 14:51:25.641037 47538 net.cpp:141] Setting up conv6_2-BatchNorm2
I0630 14:51:25.641047 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.641052 47538 net.cpp:156] Memory required for data: 3634987008
I0630 14:51:25.641062 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale2
I0630 14:51:25.641069 47538 net.cpp:91] Creating Layer conv6_2-Scale2
I0630 14:51:25.641075 47538 net.cpp:425] conv6_2-Scale2 <- conv6_2-BatchNorm2
I0630 14:51:25.641085 47538 net.cpp:386] conv6_2-Scale2 -> conv6_2-BatchNorm2 (in-place)
I0630 14:51:25.641145 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale2
I0630 14:51:25.641356 47538 net.cpp:141] Setting up conv6_2-Scale2
I0630 14:51:25.641368 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.641373 47538 net.cpp:156] Memory required for data: 3666444288
I0630 14:51:25.641381 47538 layer_factory.hpp:77] Creating layer conv6_2-ReLU2
I0630 14:51:25.641388 47538 net.cpp:91] Creating Layer conv6_2-ReLU2
I0630 14:51:25.641393 47538 net.cpp:425] conv6_2-ReLU2 <- conv6_2-BatchNorm2
I0630 14:51:25.641402 47538 net.cpp:386] conv6_2-ReLU2 -> conv6_2-BatchNorm2 (in-place)
I0630 14:51:25.643286 47538 net.cpp:141] Setting up conv6_2-ReLU2
I0630 14:51:25.643304 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:25.643309 47538 net.cpp:156] Memory required for data: 3697901568
I0630 14:51:25.643316 47538 layer_factory.hpp:77] Creating layer conv6_2-Convolution3
I0630 14:51:25.643334 47538 net.cpp:91] Creating Layer conv6_2-Convolution3
I0630 14:51:25.643340 47538 net.cpp:425] conv6_2-Convolution3 <- conv6_2-BatchNorm2
I0630 14:51:25.643353 47538 net.cpp:399] conv6_2-Convolution3 -> conv6_2-Convolution3
I0630 14:51:25.645694 47538 net.cpp:141] Setting up conv6_2-Convolution3
I0630 14:51:25.645710 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.645715 47538 net.cpp:156] Memory required for data: 3704193024
I0630 14:51:25.645725 47538 layer_factory.hpp:77] Creating layer conv6_2-Dropout2
I0630 14:51:25.645740 47538 net.cpp:91] Creating Layer conv6_2-Dropout2
I0630 14:51:25.645752 47538 net.cpp:425] conv6_2-Dropout2 <- conv6_2-Convolution3
I0630 14:51:25.645776 47538 net.cpp:399] conv6_2-Dropout2 -> conv6_2-Dropout2
I0630 14:51:25.645848 47538 net.cpp:141] Setting up conv6_2-Dropout2
I0630 14:51:25.645859 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.645862 47538 net.cpp:156] Memory required for data: 3710484480
I0630 14:51:25.645867 47538 layer_factory.hpp:77] Creating layer conv6_2-Concat2
I0630 14:51:25.645877 47538 net.cpp:91] Creating Layer conv6_2-Concat2
I0630 14:51:25.645884 47538 net.cpp:425] conv6_2-Concat2 <- conv6_2-Concat1_conv6_2-Concat1_0_split_1
I0630 14:51:25.645890 47538 net.cpp:425] conv6_2-Concat2 <- conv6_2-Dropout2
I0630 14:51:25.645898 47538 net.cpp:399] conv6_2-Concat2 -> conv6_2-Concat2
I0630 14:51:25.645934 47538 net.cpp:141] Setting up conv6_2-Concat2
I0630 14:51:25.645943 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.645947 47538 net.cpp:156] Memory required for data: 3748233216
I0630 14:51:25.645952 47538 layer_factory.hpp:77] Creating layer conv6_2-Concat2_conv6_2-Concat2_0_split
I0630 14:51:25.645959 47538 net.cpp:91] Creating Layer conv6_2-Concat2_conv6_2-Concat2_0_split
I0630 14:51:25.645965 47538 net.cpp:425] conv6_2-Concat2_conv6_2-Concat2_0_split <- conv6_2-Concat2
I0630 14:51:25.645975 47538 net.cpp:399] conv6_2-Concat2_conv6_2-Concat2_0_split -> conv6_2-Concat2_conv6_2-Concat2_0_split_0
I0630 14:51:25.645984 47538 net.cpp:399] conv6_2-Concat2_conv6_2-Concat2_0_split -> conv6_2-Concat2_conv6_2-Concat2_0_split_1
I0630 14:51:25.646039 47538 net.cpp:141] Setting up conv6_2-Concat2_conv6_2-Concat2_0_split
I0630 14:51:25.646046 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.646052 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.646056 47538 net.cpp:156] Memory required for data: 3823730688
I0630 14:51:25.646061 47538 layer_factory.hpp:77] Creating layer conv6_2-BatchNorm3
I0630 14:51:25.646073 47538 net.cpp:91] Creating Layer conv6_2-BatchNorm3
I0630 14:51:25.646078 47538 net.cpp:425] conv6_2-BatchNorm3 <- conv6_2-Concat2_conv6_2-Concat2_0_split_0
I0630 14:51:25.646088 47538 net.cpp:399] conv6_2-BatchNorm3 -> conv6_2-BatchNorm3
I0630 14:51:25.646409 47538 net.cpp:141] Setting up conv6_2-BatchNorm3
I0630 14:51:25.646418 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.646422 47538 net.cpp:156] Memory required for data: 3861479424
I0630 14:51:25.646433 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale3
I0630 14:51:25.646440 47538 net.cpp:91] Creating Layer conv6_2-Scale3
I0630 14:51:25.646447 47538 net.cpp:425] conv6_2-Scale3 <- conv6_2-BatchNorm3
I0630 14:51:25.646453 47538 net.cpp:386] conv6_2-Scale3 -> conv6_2-BatchNorm3 (in-place)
I0630 14:51:25.646517 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale3
I0630 14:51:25.646734 47538 net.cpp:141] Setting up conv6_2-Scale3
I0630 14:51:25.646744 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.646749 47538 net.cpp:156] Memory required for data: 3899228160
I0630 14:51:25.646757 47538 layer_factory.hpp:77] Creating layer conv6_2-ReLU3
I0630 14:51:25.646767 47538 net.cpp:91] Creating Layer conv6_2-ReLU3
I0630 14:51:25.646773 47538 net.cpp:425] conv6_2-ReLU3 <- conv6_2-BatchNorm3
I0630 14:51:25.646780 47538 net.cpp:386] conv6_2-ReLU3 -> conv6_2-BatchNorm3 (in-place)
I0630 14:51:25.647994 47538 net.cpp:141] Setting up conv6_2-ReLU3
I0630 14:51:25.648010 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:25.648015 47538 net.cpp:156] Memory required for data: 3936976896
I0630 14:51:25.648020 47538 layer_factory.hpp:77] Creating layer conv6_2-Convolution4
I0630 14:51:25.648043 47538 net.cpp:91] Creating Layer conv6_2-Convolution4
I0630 14:51:25.648051 47538 net.cpp:425] conv6_2-Convolution4 <- conv6_2-BatchNorm3
I0630 14:51:25.648061 47538 net.cpp:399] conv6_2-Convolution4 -> conv6_2-Convolution4
I0630 14:51:25.653354 47538 net.cpp:141] Setting up conv6_2-Convolution4
I0630 14:51:25.653371 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.653380 47538 net.cpp:156] Memory required for data: 3943268352
I0630 14:51:25.653405 47538 layer_factory.hpp:77] Creating layer conv6_2-Dropout3
I0630 14:51:25.653417 47538 net.cpp:91] Creating Layer conv6_2-Dropout3
I0630 14:51:25.653424 47538 net.cpp:425] conv6_2-Dropout3 <- conv6_2-Convolution4
I0630 14:51:25.653434 47538 net.cpp:399] conv6_2-Dropout3 -> conv6_2-Dropout3
I0630 14:51:25.653504 47538 net.cpp:141] Setting up conv6_2-Dropout3
I0630 14:51:25.653513 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:25.653517 47538 net.cpp:156] Memory required for data: 3949559808
I0630 14:51:25.653522 47538 layer_factory.hpp:77] Creating layer conv6_2-Concat3
I0630 14:51:25.653533 47538 net.cpp:91] Creating Layer conv6_2-Concat3
I0630 14:51:25.653539 47538 net.cpp:425] conv6_2-Concat3 <- conv6_2-Concat2_conv6_2-Concat2_0_split_1
I0630 14:51:25.653545 47538 net.cpp:425] conv6_2-Concat3 <- conv6_2-Dropout3
I0630 14:51:25.653553 47538 net.cpp:399] conv6_2-Concat3 -> conv6_2
I0630 14:51:25.653591 47538 net.cpp:141] Setting up conv6_2-Concat3
I0630 14:51:25.653599 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:25.653604 47538 net.cpp:156] Memory required for data: 3993600000
I0630 14:51:25.653609 47538 layer_factory.hpp:77] Creating layer conv6_2_bn
I0630 14:51:25.653622 47538 net.cpp:91] Creating Layer conv6_2_bn
I0630 14:51:25.653627 47538 net.cpp:425] conv6_2_bn <- conv6_2
I0630 14:51:25.653635 47538 net.cpp:399] conv6_2_bn -> conv6_2_bn
I0630 14:51:25.653955 47538 net.cpp:141] Setting up conv6_2_bn
I0630 14:51:25.653966 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:25.653970 47538 net.cpp:156] Memory required for data: 4037640192
I0630 14:51:25.653983 47538 layer_factory.hpp:77] Creating layer scale_conv6_2
I0630 14:51:25.653995 47538 net.cpp:91] Creating Layer scale_conv6_2
I0630 14:51:25.654001 47538 net.cpp:425] scale_conv6_2 <- conv6_2_bn
I0630 14:51:25.654008 47538 net.cpp:386] scale_conv6_2 -> conv6_2_bn (in-place)
I0630 14:51:25.654072 47538 layer_factory.hpp:77] Creating layer scale_conv6_2
I0630 14:51:25.654287 47538 net.cpp:141] Setting up scale_conv6_2
I0630 14:51:25.654297 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:25.654301 47538 net.cpp:156] Memory required for data: 4081680384
I0630 14:51:25.654309 47538 layer_factory.hpp:77] Creating layer relu6_2
I0630 14:51:25.654316 47538 net.cpp:91] Creating Layer relu6_2
I0630 14:51:25.654322 47538 net.cpp:425] relu6_2 <- conv6_2_bn
I0630 14:51:25.654331 47538 net.cpp:386] relu6_2 -> conv6_2_bn (in-place)
I0630 14:51:25.654578 47538 net.cpp:141] Setting up relu6_2
I0630 14:51:25.654589 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:25.654595 47538 net.cpp:156] Memory required for data: 4125720576
I0630 14:51:25.654600 47538 layer_factory.hpp:77] Creating layer conv6_3-Convolution1
I0630 14:51:25.654614 47538 net.cpp:91] Creating Layer conv6_3-Convolution1
I0630 14:51:25.654620 47538 net.cpp:425] conv6_3-Convolution1 <- conv6_2_bn
I0630 14:51:25.654633 47538 net.cpp:399] conv6_3-Convolution1 -> conv6_3-Convolution1
I0630 14:51:25.662004 47538 net.cpp:141] Setting up conv6_3-Convolution1
I0630 14:51:25.662021 47538 net.cpp:148] Top shape: 3 4 32 32 32 (393216)
I0630 14:51:25.662026 47538 net.cpp:156] Memory required for data: 4127293440
I0630 14:51:25.662037 47538 layer_factory.hpp:77] Creating layer conv6_3-BatchNorm1
I0630 14:51:25.662053 47538 net.cpp:91] Creating Layer conv6_3-BatchNorm1
I0630 14:51:25.662060 47538 net.cpp:425] conv6_3-BatchNorm1 <- conv6_3-Convolution1
I0630 14:51:25.662071 47538 net.cpp:399] conv6_3-BatchNorm1 -> conv6_3-BatchNorm1
I0630 14:51:25.662416 47538 net.cpp:141] Setting up conv6_3-BatchNorm1
I0630 14:51:25.662425 47538 net.cpp:148] Top shape: 3 4 32 32 32 (393216)
I0630 14:51:25.662429 47538 net.cpp:156] Memory required for data: 4128866304
I0630 14:51:25.662439 47538 layer_factory.hpp:77] Creating layer conv6_3-Scale1
I0630 14:51:25.662448 47538 net.cpp:91] Creating Layer conv6_3-Scale1
I0630 14:51:25.662454 47538 net.cpp:425] conv6_3-Scale1 <- conv6_3-BatchNorm1
I0630 14:51:25.662468 47538 net.cpp:386] conv6_3-Scale1 -> conv6_3-BatchNorm1 (in-place)
I0630 14:51:25.662544 47538 layer_factory.hpp:77] Creating layer conv6_3-Scale1
I0630 14:51:25.662762 47538 net.cpp:141] Setting up conv6_3-Scale1
I0630 14:51:25.662775 47538 net.cpp:148] Top shape: 3 4 32 32 32 (393216)
I0630 14:51:25.662778 47538 net.cpp:156] Memory required for data: 4130439168
I0630 14:51:25.662787 47538 layer_factory.hpp:77] Creating layer conv6_3-ReLU1
I0630 14:51:25.662796 47538 net.cpp:91] Creating Layer conv6_3-ReLU1
I0630 14:51:25.662801 47538 net.cpp:425] conv6_3-ReLU1 <- conv6_3-BatchNorm1
I0630 14:51:25.662806 47538 net.cpp:386] conv6_3-ReLU1 -> conv6_3-BatchNorm1 (in-place)
I0630 14:51:25.663079 47538 net.cpp:141] Setting up conv6_3-ReLU1
I0630 14:51:25.663090 47538 net.cpp:148] Top shape: 3 4 32 32 32 (393216)
I0630 14:51:25.663095 47538 net.cpp:156] Memory required for data: 4132012032
I0630 14:51:25.663100 47538 layer_factory.hpp:77] Creating layer loss
I0630 14:51:25.663113 47538 net.cpp:91] Creating Layer loss
I0630 14:51:25.663120 47538 net.cpp:425] loss <- conv6_3-BatchNorm1
I0630 14:51:25.663126 47538 net.cpp:425] loss <- dataSeg
I0630 14:51:25.663132 47538 net.cpp:425] loss <- dataCp
I0630 14:51:25.663146 47538 net.cpp:399] loss -> loss
I0630 14:51:25.663168 47538 layer_factory.hpp:77] Creating layer loss
I0630 14:51:25.666157 47538 net.cpp:141] Setting up loss
I0630 14:51:25.666173 47538 net.cpp:148] Top shape: (1)
I0630 14:51:25.666178 47538 net.cpp:151]     with loss weight 1
I0630 14:51:25.666208 47538 net.cpp:156] Memory required for data: 4132012036
I0630 14:51:25.666213 47538 net.cpp:217] loss needs backward computation.
I0630 14:51:25.666224 47538 net.cpp:217] conv6_3-ReLU1 needs backward computation.
I0630 14:51:25.666229 47538 net.cpp:217] conv6_3-Scale1 needs backward computation.
I0630 14:51:25.666234 47538 net.cpp:217] conv6_3-BatchNorm1 needs backward computation.
I0630 14:51:25.666239 47538 net.cpp:217] conv6_3-Convolution1 needs backward computation.
I0630 14:51:25.666244 47538 net.cpp:217] relu6_2 needs backward computation.
I0630 14:51:25.666247 47538 net.cpp:217] scale_conv6_2 needs backward computation.
I0630 14:51:25.666254 47538 net.cpp:217] conv6_2_bn needs backward computation.
I0630 14:51:25.666257 47538 net.cpp:217] conv6_2-Concat3 needs backward computation.
I0630 14:51:25.666263 47538 net.cpp:217] conv6_2-Dropout3 needs backward computation.
I0630 14:51:25.666270 47538 net.cpp:217] conv6_2-Convolution4 needs backward computation.
I0630 14:51:25.666275 47538 net.cpp:217] conv6_2-ReLU3 needs backward computation.
I0630 14:51:25.666280 47538 net.cpp:217] conv6_2-Scale3 needs backward computation.
I0630 14:51:25.666283 47538 net.cpp:217] conv6_2-BatchNorm3 needs backward computation.
I0630 14:51:25.666288 47538 net.cpp:217] conv6_2-Concat2_conv6_2-Concat2_0_split needs backward computation.
I0630 14:51:25.666294 47538 net.cpp:217] conv6_2-Concat2 needs backward computation.
I0630 14:51:25.666302 47538 net.cpp:217] conv6_2-Dropout2 needs backward computation.
I0630 14:51:25.666307 47538 net.cpp:217] conv6_2-Convolution3 needs backward computation.
I0630 14:51:25.666312 47538 net.cpp:217] conv6_2-ReLU2 needs backward computation.
I0630 14:51:25.666317 47538 net.cpp:217] conv6_2-Scale2 needs backward computation.
I0630 14:51:25.666322 47538 net.cpp:217] conv6_2-BatchNorm2 needs backward computation.
I0630 14:51:25.666327 47538 net.cpp:217] conv6_2-Concat1_conv6_2-Concat1_0_split needs backward computation.
I0630 14:51:25.666332 47538 net.cpp:217] conv6_2-Concat1 needs backward computation.
I0630 14:51:25.666338 47538 net.cpp:217] conv6_2-Dropout1 needs backward computation.
I0630 14:51:25.666343 47538 net.cpp:217] conv6_2-Convolution2 needs backward computation.
I0630 14:51:25.666348 47538 net.cpp:217] conv6_2-ReLU1 needs backward computation.
I0630 14:51:25.666352 47538 net.cpp:217] conv6_2-Scale1 needs backward computation.
I0630 14:51:25.666358 47538 net.cpp:217] conv6_2-BatchNorm1 needs backward computation.
I0630 14:51:25.666363 47538 net.cpp:217] conv6_2-Convolution1_conv6_2-Convolution1_0_split needs backward computation.
I0630 14:51:25.666384 47538 net.cpp:217] conv6_2-Convolution1 needs backward computation.
I0630 14:51:25.666389 47538 net.cpp:217] relu6 needs backward computation.
I0630 14:51:25.666395 47538 net.cpp:217] scale_conv6_fine needs backward computation.
I0630 14:51:25.666399 47538 net.cpp:217] conv6_bn needs backward computation.
I0630 14:51:25.666404 47538 net.cpp:217] conv6-Concat3 needs backward computation.
I0630 14:51:25.666410 47538 net.cpp:217] conv6-Dropout3 needs backward computation.
I0630 14:51:25.666416 47538 net.cpp:217] conv6-Convolution4 needs backward computation.
I0630 14:51:25.666421 47538 net.cpp:217] conv6-ReLU3 needs backward computation.
I0630 14:51:25.666425 47538 net.cpp:217] conv6-Scale3 needs backward computation.
I0630 14:51:25.666430 47538 net.cpp:217] conv6-BatchNorm3 needs backward computation.
I0630 14:51:25.666435 47538 net.cpp:217] conv6-Concat2_conv6-Concat2_0_split needs backward computation.
I0630 14:51:25.666441 47538 net.cpp:217] conv6-Concat2 needs backward computation.
I0630 14:51:25.666447 47538 net.cpp:217] conv6-Dropout2 needs backward computation.
I0630 14:51:25.666455 47538 net.cpp:217] conv6-Convolution3 needs backward computation.
I0630 14:51:25.666461 47538 net.cpp:217] conv6-ReLU2 needs backward computation.
I0630 14:51:25.666465 47538 net.cpp:217] conv6-Scale2 needs backward computation.
I0630 14:51:25.666471 47538 net.cpp:217] conv6-BatchNorm2 needs backward computation.
I0630 14:51:25.666476 47538 net.cpp:217] conv6-Concat1_conv6-Concat1_0_split needs backward computation.
I0630 14:51:25.666481 47538 net.cpp:217] conv6-Concat1 needs backward computation.
I0630 14:51:25.666486 47538 net.cpp:217] conv6-Dropout1 needs backward computation.
I0630 14:51:25.666491 47538 net.cpp:217] conv6-Convolution2 needs backward computation.
I0630 14:51:25.666496 47538 net.cpp:217] conv6-ReLU1 needs backward computation.
I0630 14:51:25.666502 47538 net.cpp:217] conv6-Scale1 needs backward computation.
I0630 14:51:25.666507 47538 net.cpp:217] conv6-BatchNorm1 needs backward computation.
I0630 14:51:25.666512 47538 net.cpp:217] conv6-Convolution1_conv6-Convolution1_0_split needs backward computation.
I0630 14:51:25.666517 47538 net.cpp:217] conv6-Convolution1 needs backward computation.
I0630 14:51:25.666522 47538 net.cpp:217] concat32 needs backward computation.
I0630 14:51:25.666528 47538 net.cpp:217] deconv6 needs backward computation.
I0630 14:51:25.666533 47538 net.cpp:217] relu5a_2 needs backward computation.
I0630 14:51:25.666538 47538 net.cpp:217] scale_conv5_2 needs backward computation.
I0630 14:51:25.666543 47538 net.cpp:217] conv5_2_bn needs backward computation.
I0630 14:51:25.666548 47538 net.cpp:217] conv5_2-Concat3 needs backward computation.
I0630 14:51:25.666554 47538 net.cpp:217] conv5_2-Dropout3 needs backward computation.
I0630 14:51:25.666563 47538 net.cpp:217] conv5_2-Convolution4 needs backward computation.
I0630 14:51:25.666570 47538 net.cpp:217] conv5_2-ReLU3 needs backward computation.
I0630 14:51:25.666574 47538 net.cpp:217] conv5_2-Scale3 needs backward computation.
I0630 14:51:25.666579 47538 net.cpp:217] conv5_2-BatchNorm3 needs backward computation.
I0630 14:51:25.666584 47538 net.cpp:217] conv5_2-Concat2_conv5_2-Concat2_0_split needs backward computation.
I0630 14:51:25.666590 47538 net.cpp:217] conv5_2-Concat2 needs backward computation.
I0630 14:51:25.666597 47538 net.cpp:217] conv5_2-Dropout2 needs backward computation.
I0630 14:51:25.666604 47538 net.cpp:217] conv5_2-Convolution3 needs backward computation.
I0630 14:51:25.666608 47538 net.cpp:217] conv5_2-ReLU2 needs backward computation.
I0630 14:51:25.666612 47538 net.cpp:217] conv5_2-Scale2 needs backward computation.
I0630 14:51:25.666618 47538 net.cpp:217] conv5_2-BatchNorm2 needs backward computation.
I0630 14:51:25.666623 47538 net.cpp:217] conv5_2-Concat1_conv5_2-Concat1_0_split needs backward computation.
I0630 14:51:25.666628 47538 net.cpp:217] conv5_2-Concat1 needs backward computation.
I0630 14:51:25.666635 47538 net.cpp:217] conv5_2-Dropout1 needs backward computation.
I0630 14:51:25.666651 47538 net.cpp:217] conv5_2-Convolution2 needs backward computation.
I0630 14:51:25.666657 47538 net.cpp:217] conv5_2-ReLU1 needs backward computation.
I0630 14:51:25.666662 47538 net.cpp:217] conv5_2-Scale1 needs backward computation.
I0630 14:51:25.666666 47538 net.cpp:217] conv5_2-BatchNorm1 needs backward computation.
I0630 14:51:25.666672 47538 net.cpp:217] conv5_2-Convolution1_conv5_2-Convolution1_0_split needs backward computation.
I0630 14:51:25.666677 47538 net.cpp:217] conv5_2-Convolution1 needs backward computation.
I0630 14:51:25.666683 47538 net.cpp:217] relu5a needs backward computation.
I0630 14:51:25.666688 47538 net.cpp:217] scale_conv5 needs backward computation.
I0630 14:51:25.666694 47538 net.cpp:217] conv5_bn needs backward computation.
I0630 14:51:25.666699 47538 net.cpp:217] conv5-Concat3 needs backward computation.
I0630 14:51:25.666705 47538 net.cpp:217] conv5-Dropout3 needs backward computation.
I0630 14:51:25.666713 47538 net.cpp:217] conv5-Convolution4 needs backward computation.
I0630 14:51:25.666720 47538 net.cpp:217] conv5-ReLU3 needs backward computation.
I0630 14:51:25.666725 47538 net.cpp:217] conv5-Scale3 needs backward computation.
I0630 14:51:25.666729 47538 net.cpp:217] conv5-BatchNorm3 needs backward computation.
I0630 14:51:25.666735 47538 net.cpp:217] conv5-Concat2_conv5-Concat2_0_split needs backward computation.
I0630 14:51:25.666741 47538 net.cpp:217] conv5-Concat2 needs backward computation.
I0630 14:51:25.666748 47538 net.cpp:217] conv5-Dropout2 needs backward computation.
I0630 14:51:25.666752 47538 net.cpp:217] conv5-Convolution3 needs backward computation.
I0630 14:51:25.666757 47538 net.cpp:217] conv5-ReLU2 needs backward computation.
I0630 14:51:25.666764 47538 net.cpp:217] conv5-Scale2 needs backward computation.
I0630 14:51:25.666769 47538 net.cpp:217] conv5-BatchNorm2 needs backward computation.
I0630 14:51:25.666774 47538 net.cpp:217] conv5-Concat1_conv5-Concat1_0_split needs backward computation.
I0630 14:51:25.666779 47538 net.cpp:217] conv5-Concat1 needs backward computation.
I0630 14:51:25.666785 47538 net.cpp:217] conv5-Dropout1 needs backward computation.
I0630 14:51:25.666790 47538 net.cpp:217] conv5-Convolution2 needs backward computation.
I0630 14:51:25.666796 47538 net.cpp:217] conv5-ReLU1 needs backward computation.
I0630 14:51:25.666800 47538 net.cpp:217] conv5-Scale1 needs backward computation.
I0630 14:51:25.666806 47538 net.cpp:217] conv5-BatchNorm1 needs backward computation.
I0630 14:51:25.666811 47538 net.cpp:217] conv5-Convolution1_conv5-Convolution1_0_split needs backward computation.
I0630 14:51:25.666816 47538 net.cpp:217] conv5-Convolution1 needs backward computation.
I0630 14:51:25.666822 47538 net.cpp:217] concat16 needs backward computation.
I0630 14:51:25.666831 47538 net.cpp:217] deconv5 needs backward computation.
I0630 14:51:25.666836 47538 net.cpp:217] relu4a needs backward computation.
I0630 14:51:25.666841 47538 net.cpp:217] scale_conv4_fine needs backward computation.
I0630 14:51:25.666847 47538 net.cpp:217] conv4_bn needs backward computation.
I0630 14:51:25.666853 47538 net.cpp:217] conv4-Concat3 needs backward computation.
I0630 14:51:25.666859 47538 net.cpp:217] conv4-Dropout3 needs backward computation.
I0630 14:51:25.666865 47538 net.cpp:217] conv4-Convolution4 needs backward computation.
I0630 14:51:25.666870 47538 net.cpp:217] conv4-ReLU3 needs backward computation.
I0630 14:51:25.666877 47538 net.cpp:217] conv4-Scale3 needs backward computation.
I0630 14:51:25.666882 47538 net.cpp:217] conv4-BatchNorm3 needs backward computation.
I0630 14:51:25.666887 47538 net.cpp:217] conv4-Concat2_conv4-Concat2_0_split needs backward computation.
I0630 14:51:25.666893 47538 net.cpp:217] conv4-Concat2 needs backward computation.
I0630 14:51:25.666898 47538 net.cpp:217] conv4-Dropout2 needs backward computation.
I0630 14:51:25.666904 47538 net.cpp:217] conv4-Convolution3 needs backward computation.
I0630 14:51:25.666909 47538 net.cpp:217] conv4-ReLU2 needs backward computation.
I0630 14:51:25.666918 47538 net.cpp:217] conv4-Scale2 needs backward computation.
I0630 14:51:25.666930 47538 net.cpp:217] conv4-BatchNorm2 needs backward computation.
I0630 14:51:25.666936 47538 net.cpp:217] conv4-Concat1_conv4-Concat1_0_split needs backward computation.
I0630 14:51:25.666941 47538 net.cpp:217] conv4-Concat1 needs backward computation.
I0630 14:51:25.666947 47538 net.cpp:217] conv4-Dropout1 needs backward computation.
I0630 14:51:25.666954 47538 net.cpp:217] conv4-Convolution2 needs backward computation.
I0630 14:51:25.666960 47538 net.cpp:217] conv4-ReLU1 needs backward computation.
I0630 14:51:25.666963 47538 net.cpp:217] conv4-Scale1 needs backward computation.
I0630 14:51:25.666968 47538 net.cpp:217] conv4-BatchNorm1 needs backward computation.
I0630 14:51:25.666982 47538 net.cpp:217] conv4-Convolution1_conv4-Convolution1_0_split needs backward computation.
I0630 14:51:25.666991 47538 net.cpp:217] conv4-Convolution1 needs backward computation.
I0630 14:51:25.666996 47538 net.cpp:217] concat8 needs backward computation.
I0630 14:51:25.667002 47538 net.cpp:217] deconv4 needs backward computation.
I0630 14:51:25.667008 47538 net.cpp:217] pool3 needs backward computation.
I0630 14:51:25.667013 47538 net.cpp:217] relu3a needs backward computation.
I0630 14:51:25.667018 47538 net.cpp:217] scale_conv6 needs backward computation.
I0630 14:51:25.667023 47538 net.cpp:217] bn6 needs backward computation.
I0630 14:51:25.667029 47538 net.cpp:217] conv3a_conv3a_0_split needs backward computation.
I0630 14:51:25.667035 47538 net.cpp:217] conv3a needs backward computation.
I0630 14:51:25.667040 47538 net.cpp:217] pool2 needs backward computation.
I0630 14:51:25.667045 47538 net.cpp:217] relu2b needs backward computation.
I0630 14:51:25.667052 47538 net.cpp:217] scale_conv5_fine needs backward computation.
I0630 14:51:25.667057 47538 net.cpp:217] bn5 needs backward computation.
I0630 14:51:25.667062 47538 net.cpp:217] conv2b_conv2b_0_split needs backward computation.
I0630 14:51:25.667066 47538 net.cpp:217] conv2b needs backward computation.
I0630 14:51:25.667073 47538 net.cpp:217] relu2a needs backward computation.
I0630 14:51:25.667078 47538 net.cpp:217] scale_conv4 needs backward computation.
I0630 14:51:25.667083 47538 net.cpp:217] bn4 needs backward computation.
I0630 14:51:25.667088 47538 net.cpp:217] conv2a-Concat3 needs backward computation.
I0630 14:51:25.667095 47538 net.cpp:217] conv2a-Dropout3 needs backward computation.
I0630 14:51:25.667100 47538 net.cpp:217] conv2a-Convolution4 needs backward computation.
I0630 14:51:25.667106 47538 net.cpp:217] conv2a-ReLU3 needs backward computation.
I0630 14:51:25.667111 47538 net.cpp:217] conv2a-Scale3 needs backward computation.
I0630 14:51:25.667116 47538 net.cpp:217] conv2a-BatchNorm3 needs backward computation.
I0630 14:51:25.667122 47538 net.cpp:217] conv2a-Concat2_conv2a-Concat2_0_split needs backward computation.
I0630 14:51:25.667127 47538 net.cpp:217] conv2a-Concat2 needs backward computation.
I0630 14:51:25.667136 47538 net.cpp:217] conv2a-Dropout2 needs backward computation.
I0630 14:51:25.667143 47538 net.cpp:217] conv2a-Convolution3 needs backward computation.
I0630 14:51:25.667148 47538 net.cpp:217] conv2a-ReLU2 needs backward computation.
I0630 14:51:25.667153 47538 net.cpp:217] conv2a-Scale2 needs backward computation.
I0630 14:51:25.667158 47538 net.cpp:217] conv2a-BatchNorm2 needs backward computation.
I0630 14:51:25.667165 47538 net.cpp:217] conv2a-Concat1_conv2a-Concat1_0_split needs backward computation.
I0630 14:51:25.667171 47538 net.cpp:217] conv2a-Concat1 needs backward computation.
I0630 14:51:25.667176 47538 net.cpp:217] conv2a-Dropout1 needs backward computation.
I0630 14:51:25.667181 47538 net.cpp:217] conv2a-Convolution2 needs backward computation.
I0630 14:51:25.667188 47538 net.cpp:217] conv2a-ReLU1 needs backward computation.
I0630 14:51:25.667193 47538 net.cpp:217] conv2a-Scale1 needs backward computation.
I0630 14:51:25.667197 47538 net.cpp:217] conv2a-BatchNorm1 needs backward computation.
I0630 14:51:25.667207 47538 net.cpp:217] conv2a-Convolution1_conv2a-Convolution1_0_split needs backward computation.
I0630 14:51:25.667220 47538 net.cpp:217] conv2a-Convolution1 needs backward computation.
I0630 14:51:25.667225 47538 net.cpp:217] pool1 needs backward computation.
I0630 14:51:25.667230 47538 net.cpp:217] relu1c needs backward computation.
I0630 14:51:25.667235 47538 net.cpp:217] scale_conv3 needs backward computation.
I0630 14:51:25.667241 47538 net.cpp:217] bn3 needs backward computation.
I0630 14:51:25.667246 47538 net.cpp:217] conv1c_conv1c_0_split needs backward computation.
I0630 14:51:25.667251 47538 net.cpp:217] conv1c needs backward computation.
I0630 14:51:25.667256 47538 net.cpp:217] relu1b needs backward computation.
I0630 14:51:25.667263 47538 net.cpp:217] scale_conv2 needs backward computation.
I0630 14:51:25.667266 47538 net.cpp:217] bn2 needs backward computation.
I0630 14:51:25.667273 47538 net.cpp:217] Concat3 needs backward computation.
I0630 14:51:25.667277 47538 net.cpp:217] Dropout3 needs backward computation.
I0630 14:51:25.667284 47538 net.cpp:217] Convolution4 needs backward computation.
I0630 14:51:25.667289 47538 net.cpp:217] ReLU3 needs backward computation.
I0630 14:51:25.667294 47538 net.cpp:217] Scale3 needs backward computation.
I0630 14:51:25.667299 47538 net.cpp:217] BatchNorm3 needs backward computation.
I0630 14:51:25.667309 47538 net.cpp:217] Concat2_Concat2_0_split needs backward computation.
I0630 14:51:25.667315 47538 net.cpp:217] Concat2 needs backward computation.
I0630 14:51:25.667320 47538 net.cpp:217] Dropout2 needs backward computation.
I0630 14:51:25.667325 47538 net.cpp:217] Convolution3 needs backward computation.
I0630 14:51:25.667331 47538 net.cpp:217] ReLU2 needs backward computation.
I0630 14:51:25.667336 47538 net.cpp:217] Scale2 needs backward computation.
I0630 14:51:25.667341 47538 net.cpp:217] BatchNorm2 needs backward computation.
I0630 14:51:25.667346 47538 net.cpp:217] Concat1_Concat1_0_split needs backward computation.
I0630 14:51:25.667352 47538 net.cpp:217] Concat1 needs backward computation.
I0630 14:51:25.667358 47538 net.cpp:217] Dropout1 needs backward computation.
I0630 14:51:25.667364 47538 net.cpp:217] Convolution2 needs backward computation.
I0630 14:51:25.667369 47538 net.cpp:217] ReLU1 needs backward computation.
I0630 14:51:25.667376 47538 net.cpp:217] Scale1 needs backward computation.
I0630 14:51:25.667379 47538 net.cpp:217] BatchNorm1 needs backward computation.
I0630 14:51:25.667385 47538 net.cpp:217] Convolution1_Convolution1_0_split needs backward computation.
I0630 14:51:25.667390 47538 net.cpp:217] Convolution1 needs backward computation.
I0630 14:51:25.667397 47538 net.cpp:217] relu1a needs backward computation.
I0630 14:51:25.667402 47538 net.cpp:217] scale_conv1 needs backward computation.
I0630 14:51:25.667407 47538 net.cpp:217] bn1 needs backward computation.
I0630 14:51:25.667412 47538 net.cpp:217] conv1a needs backward computation.
I0630 14:51:25.667418 47538 net.cpp:219] concat does not need backward computation.
I0630 14:51:25.667428 47538 net.cpp:219] data does not need backward computation.
I0630 14:51:25.667433 47538 net.cpp:261] This network produces output loss
I0630 14:51:25.667620 47538 net.cpp:274] Network initialization done.
I0630 14:51:25.671535 47538 solver.cpp:181] Creating test net (#0) specified by net file: infant_train.prototxt
I0630 14:51:25.671974 47538 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0630 14:51:25.672145 47538 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss
I0630 14:51:25.674446 47538 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "dataT1"
  top: "dataT2"
  top: "dataSeg"
  top: "dataCp"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "testInfant3D_list-BCP18-cp.txt"
    batch_size: 3
    shuffle: true
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "dataT1"
  bottom: "dataT2"
  top: "data"
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1a_bn"
  top: "conv1a_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a_bn"
  top: "conv1a_bn"
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "conv1a_bn"
  top: "Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "BatchNorm1"
  top: "Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "Dropout1"
  type: "Dropout"
  bottom: "Convolution2"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Convolution1"
  bottom: "Dropout1"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Concat1"
  top: "BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "BatchNorm2"
  top: "Convolution3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "Dropout2"
  type: "Dropout"
  bottom: "Convolution3"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Concat1"
  bottom: "Dropout2"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Concat2"
  top: "BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "BatchNorm3"
  top: "BatchNorm3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "BatchNorm3"
  top: "BatchNorm3"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "BatchNorm3"
  top: "Convolution4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "Dropout3"
  type: "Dropout"
  bottom: "Convolution4"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "Concat2"
  bottom: "Dropout3"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "Concat3"
  top: "conv1b_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv2"
  type: "Scale"
  bottom: "conv1b_bn"
  top: "conv1b_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1b"
  type: "ReLU"
  bottom: "conv1b_bn"
  top: "conv1b_bn"
}
layer {
  name: "conv1c"
  type: "Convolution"
  bottom: "conv1b_bn"
  top: "conv1c"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv1c"
  top: "conv1c_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv3"
  type: "Scale"
  bottom: "conv1c_bn"
  top: "conv1c_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1c"
  type: "ReLU"
  bottom: "conv1c_bn"
  top: "conv1c_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1c_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: CUDNN
  }
}
layer {
  name: "conv2a-Convolution1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2a-Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2a-BatchNorm1"
  type: "BatchNorm"
  bottom: "conv2a-Convolution1"
  top: "conv2a-BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2a-Scale1"
  type: "Scale"
  bottom: "conv2a-BatchNorm1"
  top: "conv2a-BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2a-ReLU1"
  type: "ReLU"
  bottom: "conv2a-BatchNorm1"
  top: "conv2a-BatchNorm1"
}
layer {
  name: "conv2a-Convolution2"
  type: "Convolution"
  bottom: "conv2a-BatchNorm1"
  top: "conv2a-Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2a-Dropout1"
  type: "Dropout"
  bottom: "conv2a-Convolution2"
  top: "conv2a-Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2a-Concat1"
  type: "Concat"
  bottom: "conv2a-Convolution1"
  bottom: "conv2a-Dropout1"
  top: "conv2a-Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2a-BatchNorm2"
  type: "BatchNorm"
  bottom: "conv2a-Concat1"
  top: "conv2a-BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2a-Scale2"
  type: "Scale"
  bottom: "conv2a-BatchNorm2"
  top: "conv2a-BatchNorm2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2a-ReLU2"
  type: "ReLU"
  bottom: "conv2a-BatchNorm2"
  top: "conv2a-BatchNorm2"
}
layer {
  name: "conv2a-Convolution3"
  type: "Convolution"
  bottom: "conv2a-BatchNorm2"
  top: "conv2a-Convolution3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2a-Dropout2"
  type: "Dropout"
  bottom: "conv2a-Convolution3"
  top: "conv2a-Dropout2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2a-Concat2"
  type: "Concat"
  bottom: "conv2a-Concat1"
  bottom: "conv2a-Dropout2"
  top: "conv2a-Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2a-BatchNorm3"
  type: "BatchNorm"
  bottom: "conv2a-Concat2"
  top: "conv2a-BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2a-Scale3"
  type: "Scale"
  bottom: "conv2a-BatchNorm3"
  top: "conv2a-BatchNorm3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2a-ReLU3"
  type: "ReLU"
  bottom: "conv2a-BatchNorm3"
  top: "conv2a-BatchNorm3"
}
layer {
  name: "conv2a-Convolution4"
  type: "Convolution"
  bottom: "conv2a-BatchNorm3"
  top: "conv2a-Convolution4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2a-Dropout3"
  type: "Dropout"
  bottom: "conv2a-Convolution4"
  top: "conv2a-Dropout3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2a-Concat3"
  type: "Concat"
  bottom: "conv2a-Concat2"
  bottom: "conv2a-Dropout3"
  top: "conv2a"
  concat_param {
    axis: 1
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv2a"
  top: "conv2a_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv4"
  type: "Scale"
  bottom: "conv2a_bn"
  top: "conv2a_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a_bn"
  top: "conv2a_bn"
}
layer {
  name: "conv2b"
  type: "Convolution"
  bottom: "conv2a_bn"
  top: "conv2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv2b"
  top: "conv2b_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv5_fine"
  type: "Scale"
  bottom: "conv2b_bn"
  top: "conv2b_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2b"
  type: "ReLU"
  bottom: "conv2b_bn"
  top: "conv2b_bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2b_bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: CUDNN
  }
}
layer {
  name: "conv3a"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "conv3a"
  top: "conv3a_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv6"
  type: "Scale"
  bottom: "conv3a_bn"
  top: "conv3a_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a_bn"
  top: "conv3a_bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3a_bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: CUDNN
  }
}
layer {
  name: "deconv4"
  type: "Deconvolution"
  bottom: "pool3"
  top: "deconv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "xavier"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat8"
  type: "Concat"
  bottom: "conv3a"
  bottom: "deconv4"
  top: "concat8"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "conv4-Convolution1"
  type: "Convolution"
  bottom: "concat8"
  top: "conv4-Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv4-BatchNorm1"
  type: "BatchNorm"
  bottom: "conv4-Convolution1"
  top: "conv4-BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4-Scale1"
  type: "Scale"
  bottom: "conv4-BatchNorm1"
  top: "conv4-BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4-ReLU1"
  type: "ReLU"
  bottom: "conv4-BatchNorm1"
  top: "conv4-BatchNorm1"
}
layer {
  name: "conv4-Convolution2"
  type: "Convolution"
  bottom: "conv4-BatchNorm1"
  top: "conv4-Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv4-Dropout1"
  type: "Dropout"
  bottom: "conv4-Convolution2"
  top: "conv4-Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4-Concat1"
  type: "Concat"
  bottom: "conv4-Convolution1"
  bottom: "conv4-Dropout1"
  top: "conv4-Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv4-BatchNorm2"
  type: "BatchNorm"
  bottom: "conv4-Concat1"
  top: "conv4-BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4-Scale2"
  type: "Scale"
  bottom: "conv4-BatchNorm2"
  top: "conv4-BatchNorm2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4-ReLU2"
  type: "ReLU"
  bottom: "conv4-BatchNorm2"
  top: "conv4-BatchNorm2"
}
layer {
  name: "conv4-Convolution3"
  type: "Convolution"
  bottom: "conv4-BatchNorm2"
  top: "conv4-Convolution3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv4-Dropout2"
  type: "Dropout"
  bottom: "conv4-Convolution3"
  top: "conv4-Dropout2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4-Concat2"
  type: "Concat"
  bottom: "conv4-Concat1"
  bottom: "conv4-Dropout2"
  top: "conv4-Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv4-BatchNorm3"
  type: "BatchNorm"
  bottom: "conv4-Concat2"
  top: "conv4-BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4-Scale3"
  type: "Scale"
  bottom: "conv4-BatchNorm3"
  top: "conv4-BatchNorm3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4-ReLU3"
  type: "ReLU"
  bottom: "conv4-BatchNorm3"
  top: "conv4-BatchNorm3"
}
layer {
  name: "conv4-Convolution4"
  type: "Convolution"
  bottom: "conv4-BatchNorm3"
  top: "conv4-Convolution4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv4-Dropout3"
  type: "Dropout"
  bottom: "conv4-Convolution4"
  top: "conv4-Dropout3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4-Concat3"
  type: "Concat"
  bottom: "conv4-Concat2"
  bottom: "conv4-Dropout3"
  top: "conv4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv4_bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv4_fine"
  type: "Scale"
  bottom: "conv4_bn"
  top: "conv4_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4_bn"
  top: "conv4_bn"
}
layer {
  name: "deconv5"
  type: "Deconvolution"
  bottom: "conv4_bn"
  top: "deconv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "xavier"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat16"
  type: "Concat"
  bottom: "conv2b"
  bottom: "deconv5"
  top: "concat16"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "conv5-Convolution1"
  type: "Convolution"
  bottom: "concat16"
  top: "conv5-Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5-BatchNorm1"
  type: "BatchNorm"
  bottom: "conv5-Convolution1"
  top: "conv5-BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5-Scale1"
  type: "Scale"
  bottom: "conv5-BatchNorm1"
  top: "conv5-BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5-ReLU1"
  type: "ReLU"
  bottom: "conv5-BatchNorm1"
  top: "conv5-BatchNorm1"
}
layer {
  name: "conv5-Convolution2"
  type: "Convolution"
  bottom: "conv5-BatchNorm1"
  top: "conv5-Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5-Dropout1"
  type: "Dropout"
  bottom: "conv5-Convolution2"
  top: "conv5-Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5-Concat1"
  type: "Concat"
  bottom: "conv5-Convolution1"
  bottom: "conv5-Dropout1"
  top: "conv5-Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5-BatchNorm2"
  type: "BatchNorm"
  bottom: "conv5-Concat1"
  top: "conv5-BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5-Scale2"
  type: "Scale"
  bottom: "conv5-BatchNorm2"
  top: "conv5-BatchNorm2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5-ReLU2"
  type: "ReLU"
  bottom: "conv5-BatchNorm2"
  top: "conv5-BatchNorm2"
}
layer {
  name: "conv5-Convolution3"
  type: "Convolution"
  bottom: "conv5-BatchNorm2"
  top: "conv5-Convolution3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5-Dropout2"
  type: "Dropout"
  bottom: "conv5-Convolution3"
  top: "conv5-Dropout2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5-Concat2"
  type: "Concat"
  bottom: "conv5-Concat1"
  bottom: "conv5-Dropout2"
  top: "conv5-Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5-BatchNorm3"
  type: "BatchNorm"
  bottom: "conv5-Concat2"
  top: "conv5-BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5-Scale3"
  type: "Scale"
  bottom: "conv5-BatchNorm3"
  top: "conv5-BatchNorm3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5-ReLU3"
  type: "ReLU"
  bottom: "conv5-BatchNorm3"
  top: "conv5-BatchNorm3"
}
layer {
  name: "conv5-Convolution4"
  type: "Convolution"
  bottom: "conv5-BatchNorm3"
  top: "conv5-Convolution4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5-Dropout3"
  type: "Dropout"
  bottom: "conv5-Convolution4"
  top: "conv5-Dropout3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5-Concat3"
  type: "Concat"
  bottom: "conv5-Concat2"
  bottom: "conv5-Dropout3"
  top: "conv5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5_bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv5"
  type: "Scale"
  bottom: "conv5_bn"
  top: "conv5_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5_bn"
  top: "conv5_bn"
}
layer {
  name: "conv5_2-Convolution1"
  type: "Convolution"
  bottom: "conv5_bn"
  top: "conv5_2-Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5_2-BatchNorm1"
  type: "BatchNorm"
  bottom: "conv5_2-Convolution1"
  top: "conv5_2-BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2-Scale1"
  type: "Scale"
  bottom: "conv5_2-BatchNorm1"
  top: "conv5_2-BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2-ReLU1"
  type: "ReLU"
  bottom: "conv5_2-BatchNorm1"
  top: "conv5_2-BatchNorm1"
}
layer {
  name: "conv5_2-Convolution2"
  type: "Convolution"
  bottom: "conv5_2-BatchNorm1"
  top: "conv5_2-Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5_2-Dropout1"
  type: "Dropout"
  bottom: "conv5_2-Convolution2"
  top: "conv5_2-Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5_2-Concat1"
  type: "Concat"
  bottom: "conv5_2-Convolution1"
  bottom: "conv5_2-Dropout1"
  top: "conv5_2-Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5_2-BatchNorm2"
  type: "BatchNorm"
  bottom: "conv5_2-Concat1"
  top: "conv5_2-BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2-Scale2"
  type: "Scale"
  bottom: "conv5_2-BatchNorm2"
  top: "conv5_2-BatchNorm2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2-ReLU2"
  type: "ReLU"
  bottom: "conv5_2-BatchNorm2"
  top: "conv5_2-BatchNorm2"
}
layer {
  name: "conv5_2-Convolution3"
  type: "Convolution"
  bottom: "conv5_2-BatchNorm2"
  top: "conv5_2-Convolution3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5_2-Dropout2"
  type: "Dropout"
  bottom: "conv5_2-Convolution3"
  top: "conv5_2-Dropout2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5_2-Concat2"
  type: "Concat"
  bottom: "conv5_2-Concat1"
  bottom: "conv5_2-Dropout2"
  top: "conv5_2-Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5_2-BatchNorm3"
  type: "BatchNorm"
  bottom: "conv5_2-Concat2"
  top: "conv5_2-BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2-Scale3"
  type: "Scale"
  bottom: "conv5_2-BatchNorm3"
  top: "conv5_2-BatchNorm3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2-ReLU3"
  type: "ReLU"
  bottom: "conv5_2-BatchNorm3"
  top: "conv5_2-BatchNorm3"
}
layer {
  name: "conv5_2-Convolution4"
  type: "Convolution"
  bottom: "conv5_2-BatchNorm3"
  top: "conv5_2-Convolution4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv5_2-Dropout3"
  type: "Dropout"
  bottom: "conv5_2-Convolution4"
  top: "conv5_2-Dropout3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv5_2-Concat3"
  type: "Concat"
  bottom: "conv5_2-Concat2"
  bottom: "conv5_2-Dropout3"
  top: "conv5_2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5_2_bn"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv5_2"
  type: "Scale"
  bottom: "conv5_2_bn"
  top: "conv5_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5a_2"
  type: "ReLU"
  bottom: "conv5_2_bn"
  top: "conv5_2_bn"
}
layer {
  name: "deconv6"
  type: "Deconvolution"
  bottom: "conv5_2_bn"
  top: "deconv6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "xavier"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat32"
  type: "Concat"
  bottom: "conv1c"
  bottom: "deconv6"
  top: "concat32"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "conv6-Convolution1"
  type: "Convolution"
  bottom: "concat32"
  top: "conv6-Convolution1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv6-BatchNorm1"
  type: "BatchNorm"
  bottom: "conv6-Convolution1"
  top: "conv6-BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv6-Scale1"
  type: "Scale"
  bottom: "conv6-BatchNorm1"
  top: "conv6-BatchNorm1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6-ReLU1"
  type: "ReLU"
  bottom: "conv6-BatchNorm1"
  top: "conv6-BatchNorm1"
}
layer {
  name: "conv6-Convolution2"
  type: "Convolution"
  bottom: "conv6-BatchNorm1"
  top: "conv6-Convolution2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv6-Dropout1"
  type: "Dropout"
  bottom: "conv6-Convolution2"
  top: "conv6-Dropout1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv6-Concat1"
  type: "Concat"
  bottom: "conv6-Convolution1"
  bottom: "conv6-Dropout1"
  top: "conv6-Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv6-BatchNorm2"
  type: "BatchNorm"
  bottom: "conv6-Concat1"
  top: "conv6-BatchNorm2"
  param {
    lr_mult: 0
 
I0630 14:51:25.676201 47538 layer_factory.hpp:77] Creating layer data
I0630 14:51:25.676235 47538 net.cpp:91] Creating Layer data
I0630 14:51:25.676249 47538 net.cpp:399] data -> dataT1
I0630 14:51:25.676272 47538 net.cpp:399] data -> dataT2
I0630 14:51:25.676290 47538 net.cpp:399] data -> dataSeg
I0630 14:51:25.676311 47538 net.cpp:399] data -> dataCp
I0630 14:51:25.676326 47538 hdf5_data_layer.cpp:81] Loading list of HDF5 filenames from: testInfant3D_list-BCP18-cp.txt
I0630 14:51:25.694368 47538 hdf5_data_layer.cpp:95] Number of HDF5 files: 1
I0630 14:51:30.808804 47538 net.cpp:141] Setting up data
I0630 14:51:30.808912 47538 net.cpp:148] Top shape: 3 1 32 32 32 (98304)
I0630 14:51:30.808933 47538 net.cpp:148] Top shape: 3 1 32 32 32 (98304)
I0630 14:51:30.808948 47538 net.cpp:148] Top shape: 3 1 32 32 32 (98304)
I0630 14:51:30.808964 47538 net.cpp:148] Top shape: 3 1 32 32 32 (98304)
I0630 14:51:30.808979 47538 net.cpp:156] Memory required for data: 1572864
I0630 14:51:30.809015 47538 layer_factory.hpp:77] Creating layer dataSeg_data_2_split
I0630 14:51:30.809092 47538 net.cpp:91] Creating Layer dataSeg_data_2_split
I0630 14:51:30.809115 47538 net.cpp:425] dataSeg_data_2_split <- dataSeg
I0630 14:51:30.809150 47538 net.cpp:399] dataSeg_data_2_split -> dataSeg_data_2_split_0
I0630 14:51:30.809185 47538 net.cpp:399] dataSeg_data_2_split -> dataSeg_data_2_split_1
I0630 14:51:30.809320 47538 net.cpp:141] Setting up dataSeg_data_2_split
I0630 14:51:30.809342 47538 net.cpp:148] Top shape: 3 1 32 32 32 (98304)
I0630 14:51:30.809360 47538 net.cpp:148] Top shape: 3 1 32 32 32 (98304)
I0630 14:51:30.809372 47538 net.cpp:156] Memory required for data: 2359296
I0630 14:51:30.809388 47538 layer_factory.hpp:77] Creating layer concat
I0630 14:51:30.809424 47538 net.cpp:91] Creating Layer concat
I0630 14:51:30.809442 47538 net.cpp:425] concat <- dataT1
I0630 14:51:30.809458 47538 net.cpp:425] concat <- dataT2
I0630 14:51:30.809474 47538 net.cpp:399] concat -> data
I0630 14:51:30.809556 47538 net.cpp:141] Setting up concat
I0630 14:51:30.809579 47538 net.cpp:148] Top shape: 3 2 32 32 32 (196608)
I0630 14:51:30.809592 47538 net.cpp:156] Memory required for data: 3145728
I0630 14:51:30.809604 47538 layer_factory.hpp:77] Creating layer conv1a
I0630 14:51:30.809710 47538 net.cpp:91] Creating Layer conv1a
I0630 14:51:30.809726 47538 net.cpp:425] conv1a <- data
I0630 14:51:30.809748 47538 net.cpp:399] conv1a -> conv1a
I0630 14:51:30.819782 47538 net.cpp:141] Setting up conv1a
I0630 14:51:30.819808 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.819818 47538 net.cpp:156] Memory required for data: 28311552
I0630 14:51:30.819849 47538 layer_factory.hpp:77] Creating layer bn1
I0630 14:51:30.819876 47538 net.cpp:91] Creating Layer bn1
I0630 14:51:30.819885 47538 net.cpp:425] bn1 <- conv1a
I0630 14:51:30.819900 47538 net.cpp:399] bn1 -> conv1a_bn
I0630 14:51:30.820441 47538 net.cpp:141] Setting up bn1
I0630 14:51:30.820456 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.820463 47538 net.cpp:156] Memory required for data: 53477376
I0630 14:51:30.820489 47538 layer_factory.hpp:77] Creating layer scale_conv1
I0630 14:51:30.820505 47538 net.cpp:91] Creating Layer scale_conv1
I0630 14:51:30.820524 47538 net.cpp:425] scale_conv1 <- conv1a_bn
I0630 14:51:30.820574 47538 net.cpp:386] scale_conv1 -> conv1a_bn (in-place)
I0630 14:51:30.820669 47538 layer_factory.hpp:77] Creating layer scale_conv1
I0630 14:51:30.821010 47538 net.cpp:141] Setting up scale_conv1
I0630 14:51:30.821025 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.821033 47538 net.cpp:156] Memory required for data: 78643200
I0630 14:51:30.821048 47538 layer_factory.hpp:77] Creating layer relu1a
I0630 14:51:30.821072 47538 net.cpp:91] Creating Layer relu1a
I0630 14:51:30.821080 47538 net.cpp:425] relu1a <- conv1a_bn
I0630 14:51:30.821094 47538 net.cpp:386] relu1a -> conv1a_bn (in-place)
I0630 14:51:30.821477 47538 net.cpp:141] Setting up relu1a
I0630 14:51:30.821494 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.821501 47538 net.cpp:156] Memory required for data: 103809024
I0630 14:51:30.821509 47538 layer_factory.hpp:77] Creating layer Convolution1
I0630 14:51:30.821537 47538 net.cpp:91] Creating Layer Convolution1
I0630 14:51:30.821544 47538 net.cpp:425] Convolution1 <- conv1a_bn
I0630 14:51:30.821557 47538 net.cpp:399] Convolution1 -> Convolution1
I0630 14:51:30.827951 47538 net.cpp:141] Setting up Convolution1
I0630 14:51:30.827984 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.827992 47538 net.cpp:156] Memory required for data: 128974848
I0630 14:51:30.828012 47538 layer_factory.hpp:77] Creating layer Convolution1_Convolution1_0_split
I0630 14:51:30.828039 47538 net.cpp:91] Creating Layer Convolution1_Convolution1_0_split
I0630 14:51:30.828049 47538 net.cpp:425] Convolution1_Convolution1_0_split <- Convolution1
I0630 14:51:30.828063 47538 net.cpp:399] Convolution1_Convolution1_0_split -> Convolution1_Convolution1_0_split_0
I0630 14:51:30.828080 47538 net.cpp:399] Convolution1_Convolution1_0_split -> Convolution1_Convolution1_0_split_1
I0630 14:51:30.828181 47538 net.cpp:141] Setting up Convolution1_Convolution1_0_split
I0630 14:51:30.828195 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.828204 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.828210 47538 net.cpp:156] Memory required for data: 179306496
I0630 14:51:30.828222 47538 layer_factory.hpp:77] Creating layer BatchNorm1
I0630 14:51:30.828243 47538 net.cpp:91] Creating Layer BatchNorm1
I0630 14:51:30.828250 47538 net.cpp:425] BatchNorm1 <- Convolution1_Convolution1_0_split_0
I0630 14:51:30.828263 47538 net.cpp:399] BatchNorm1 -> BatchNorm1
I0630 14:51:30.828771 47538 net.cpp:141] Setting up BatchNorm1
I0630 14:51:30.828788 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.828794 47538 net.cpp:156] Memory required for data: 204472320
I0630 14:51:30.828810 47538 layer_factory.hpp:77] Creating layer Scale1
I0630 14:51:30.828824 47538 net.cpp:91] Creating Layer Scale1
I0630 14:51:30.828832 47538 net.cpp:425] Scale1 <- BatchNorm1
I0630 14:51:30.828842 47538 net.cpp:386] Scale1 -> BatchNorm1 (in-place)
I0630 14:51:30.828930 47538 layer_factory.hpp:77] Creating layer Scale1
I0630 14:51:30.831841 47538 net.cpp:141] Setting up Scale1
I0630 14:51:30.831867 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.831876 47538 net.cpp:156] Memory required for data: 229638144
I0630 14:51:30.831890 47538 layer_factory.hpp:77] Creating layer ReLU1
I0630 14:51:30.831903 47538 net.cpp:91] Creating Layer ReLU1
I0630 14:51:30.831913 47538 net.cpp:425] ReLU1 <- BatchNorm1
I0630 14:51:30.831925 47538 net.cpp:386] ReLU1 -> BatchNorm1 (in-place)
I0630 14:51:30.833566 47538 net.cpp:141] Setting up ReLU1
I0630 14:51:30.833588 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.833597 47538 net.cpp:156] Memory required for data: 254803968
I0630 14:51:30.833606 47538 layer_factory.hpp:77] Creating layer Convolution2
I0630 14:51:30.833638 47538 net.cpp:91] Creating Layer Convolution2
I0630 14:51:30.833647 47538 net.cpp:425] Convolution2 <- BatchNorm1
I0630 14:51:30.833663 47538 net.cpp:399] Convolution2 -> Convolution2
I0630 14:51:30.846333 47538 net.cpp:141] Setting up Convolution2
I0630 14:51:30.846386 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:30.846395 47538 net.cpp:156] Memory required for data: 261095424
I0630 14:51:30.846410 47538 layer_factory.hpp:77] Creating layer Dropout1
I0630 14:51:30.846427 47538 net.cpp:91] Creating Layer Dropout1
I0630 14:51:30.846436 47538 net.cpp:425] Dropout1 <- Convolution2
I0630 14:51:30.846447 47538 net.cpp:399] Dropout1 -> Dropout1
I0630 14:51:30.846558 47538 net.cpp:141] Setting up Dropout1
I0630 14:51:30.846570 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:30.846577 47538 net.cpp:156] Memory required for data: 267386880
I0630 14:51:30.846583 47538 layer_factory.hpp:77] Creating layer Concat1
I0630 14:51:30.846601 47538 net.cpp:91] Creating Layer Concat1
I0630 14:51:30.846607 47538 net.cpp:425] Concat1 <- Convolution1_Convolution1_0_split_1
I0630 14:51:30.846616 47538 net.cpp:425] Concat1 <- Dropout1
I0630 14:51:30.846630 47538 net.cpp:399] Concat1 -> Concat1
I0630 14:51:30.846688 47538 net.cpp:141] Setting up Concat1
I0630 14:51:30.846698 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:30.846704 47538 net.cpp:156] Memory required for data: 298844160
I0630 14:51:30.846711 47538 layer_factory.hpp:77] Creating layer Concat1_Concat1_0_split
I0630 14:51:30.846724 47538 net.cpp:91] Creating Layer Concat1_Concat1_0_split
I0630 14:51:30.846730 47538 net.cpp:425] Concat1_Concat1_0_split <- Concat1
I0630 14:51:30.846747 47538 net.cpp:399] Concat1_Concat1_0_split -> Concat1_Concat1_0_split_0
I0630 14:51:30.846763 47538 net.cpp:399] Concat1_Concat1_0_split -> Concat1_Concat1_0_split_1
I0630 14:51:30.846844 47538 net.cpp:141] Setting up Concat1_Concat1_0_split
I0630 14:51:30.846856 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:30.846865 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:30.846873 47538 net.cpp:156] Memory required for data: 361758720
I0630 14:51:30.846880 47538 layer_factory.hpp:77] Creating layer BatchNorm2
I0630 14:51:30.846905 47538 net.cpp:91] Creating Layer BatchNorm2
I0630 14:51:30.846912 47538 net.cpp:425] BatchNorm2 <- Concat1_Concat1_0_split_0
I0630 14:51:30.846923 47538 net.cpp:399] BatchNorm2 -> BatchNorm2
I0630 14:51:30.847503 47538 net.cpp:141] Setting up BatchNorm2
I0630 14:51:30.847517 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:30.847522 47538 net.cpp:156] Memory required for data: 393216000
I0630 14:51:30.847541 47538 layer_factory.hpp:77] Creating layer Scale2
I0630 14:51:30.847558 47538 net.cpp:91] Creating Layer Scale2
I0630 14:51:30.847565 47538 net.cpp:425] Scale2 <- BatchNorm2
I0630 14:51:30.847575 47538 net.cpp:386] Scale2 -> BatchNorm2 (in-place)
I0630 14:51:30.847661 47538 layer_factory.hpp:77] Creating layer Scale2
I0630 14:51:30.847960 47538 net.cpp:141] Setting up Scale2
I0630 14:51:30.847973 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:30.847980 47538 net.cpp:156] Memory required for data: 424673280
I0630 14:51:30.847990 47538 layer_factory.hpp:77] Creating layer ReLU2
I0630 14:51:30.848001 47538 net.cpp:91] Creating Layer ReLU2
I0630 14:51:30.848006 47538 net.cpp:425] ReLU2 <- BatchNorm2
I0630 14:51:30.848018 47538 net.cpp:386] ReLU2 -> BatchNorm2 (in-place)
I0630 14:51:30.848359 47538 net.cpp:141] Setting up ReLU2
I0630 14:51:30.848376 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:30.848382 47538 net.cpp:156] Memory required for data: 456130560
I0630 14:51:30.848388 47538 layer_factory.hpp:77] Creating layer Convolution3
I0630 14:51:30.848412 47538 net.cpp:91] Creating Layer Convolution3
I0630 14:51:30.848420 47538 net.cpp:425] Convolution3 <- BatchNorm2
I0630 14:51:30.848435 47538 net.cpp:399] Convolution3 -> Convolution3
I0630 14:51:30.852581 47538 net.cpp:141] Setting up Convolution3
I0630 14:51:30.852602 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:30.852609 47538 net.cpp:156] Memory required for data: 462422016
I0630 14:51:30.852625 47538 layer_factory.hpp:77] Creating layer Dropout2
I0630 14:51:30.852645 47538 net.cpp:91] Creating Layer Dropout2
I0630 14:51:30.852675 47538 net.cpp:425] Dropout2 <- Convolution3
I0630 14:51:30.852691 47538 net.cpp:399] Dropout2 -> Dropout2
I0630 14:51:30.852782 47538 net.cpp:141] Setting up Dropout2
I0630 14:51:30.852797 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:30.852802 47538 net.cpp:156] Memory required for data: 468713472
I0630 14:51:30.852810 47538 layer_factory.hpp:77] Creating layer Concat2
I0630 14:51:30.852820 47538 net.cpp:91] Creating Layer Concat2
I0630 14:51:30.852828 47538 net.cpp:425] Concat2 <- Concat1_Concat1_0_split_1
I0630 14:51:30.852836 47538 net.cpp:425] Concat2 <- Dropout2
I0630 14:51:30.852847 47538 net.cpp:399] Concat2 -> Concat2
I0630 14:51:30.852895 47538 net.cpp:141] Setting up Concat2
I0630 14:51:30.852908 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:30.852914 47538 net.cpp:156] Memory required for data: 506462208
I0630 14:51:30.852922 47538 layer_factory.hpp:77] Creating layer Concat2_Concat2_0_split
I0630 14:51:30.852934 47538 net.cpp:91] Creating Layer Concat2_Concat2_0_split
I0630 14:51:30.852941 47538 net.cpp:425] Concat2_Concat2_0_split <- Concat2
I0630 14:51:30.852950 47538 net.cpp:399] Concat2_Concat2_0_split -> Concat2_Concat2_0_split_0
I0630 14:51:30.852967 47538 net.cpp:399] Concat2_Concat2_0_split -> Concat2_Concat2_0_split_1
I0630 14:51:30.853039 47538 net.cpp:141] Setting up Concat2_Concat2_0_split
I0630 14:51:30.853049 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:30.853057 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:30.853065 47538 net.cpp:156] Memory required for data: 581959680
I0630 14:51:30.853070 47538 layer_factory.hpp:77] Creating layer BatchNorm3
I0630 14:51:30.853088 47538 net.cpp:91] Creating Layer BatchNorm3
I0630 14:51:30.853096 47538 net.cpp:425] BatchNorm3 <- Concat2_Concat2_0_split_0
I0630 14:51:30.853111 47538 net.cpp:399] BatchNorm3 -> BatchNorm3
I0630 14:51:30.853638 47538 net.cpp:141] Setting up BatchNorm3
I0630 14:51:30.853649 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:30.853657 47538 net.cpp:156] Memory required for data: 619708416
I0630 14:51:30.853672 47538 layer_factory.hpp:77] Creating layer Scale3
I0630 14:51:30.853682 47538 net.cpp:91] Creating Layer Scale3
I0630 14:51:30.853688 47538 net.cpp:425] Scale3 <- BatchNorm3
I0630 14:51:30.853700 47538 net.cpp:386] Scale3 -> BatchNorm3 (in-place)
I0630 14:51:30.853782 47538 layer_factory.hpp:77] Creating layer Scale3
I0630 14:51:30.854094 47538 net.cpp:141] Setting up Scale3
I0630 14:51:30.854108 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:30.854115 47538 net.cpp:156] Memory required for data: 657457152
I0630 14:51:30.854126 47538 layer_factory.hpp:77] Creating layer ReLU3
I0630 14:51:30.854136 47538 net.cpp:91] Creating Layer ReLU3
I0630 14:51:30.854143 47538 net.cpp:425] ReLU3 <- BatchNorm3
I0630 14:51:30.854152 47538 net.cpp:386] ReLU3 -> BatchNorm3 (in-place)
I0630 14:51:30.854508 47538 net.cpp:141] Setting up ReLU3
I0630 14:51:30.854522 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:30.854528 47538 net.cpp:156] Memory required for data: 695205888
I0630 14:51:30.854535 47538 layer_factory.hpp:77] Creating layer Convolution4
I0630 14:51:30.854562 47538 net.cpp:91] Creating Layer Convolution4
I0630 14:51:30.854570 47538 net.cpp:425] Convolution4 <- BatchNorm3
I0630 14:51:30.854583 47538 net.cpp:399] Convolution4 -> Convolution4
I0630 14:51:30.866732 47538 net.cpp:141] Setting up Convolution4
I0630 14:51:30.866760 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:30.866766 47538 net.cpp:156] Memory required for data: 701497344
I0630 14:51:30.866780 47538 layer_factory.hpp:77] Creating layer Dropout3
I0630 14:51:30.866796 47538 net.cpp:91] Creating Layer Dropout3
I0630 14:51:30.866806 47538 net.cpp:425] Dropout3 <- Convolution4
I0630 14:51:30.866819 47538 net.cpp:399] Dropout3 -> Dropout3
I0630 14:51:30.866914 47538 net.cpp:141] Setting up Dropout3
I0630 14:51:30.866923 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:30.866937 47538 net.cpp:156] Memory required for data: 707788800
I0630 14:51:30.866968 47538 layer_factory.hpp:77] Creating layer Concat3
I0630 14:51:30.866991 47538 net.cpp:91] Creating Layer Concat3
I0630 14:51:30.866999 47538 net.cpp:425] Concat3 <- Concat2_Concat2_0_split_1
I0630 14:51:30.867008 47538 net.cpp:425] Concat3 <- Dropout3
I0630 14:51:30.867022 47538 net.cpp:399] Concat3 -> Concat3
I0630 14:51:30.867071 47538 net.cpp:141] Setting up Concat3
I0630 14:51:30.867081 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:30.867089 47538 net.cpp:156] Memory required for data: 751828992
I0630 14:51:30.867094 47538 layer_factory.hpp:77] Creating layer bn2
I0630 14:51:30.867107 47538 net.cpp:91] Creating Layer bn2
I0630 14:51:30.867115 47538 net.cpp:425] bn2 <- Concat3
I0630 14:51:30.867128 47538 net.cpp:399] bn2 -> conv1b_bn
I0630 14:51:30.867573 47538 net.cpp:141] Setting up bn2
I0630 14:51:30.867584 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:30.867590 47538 net.cpp:156] Memory required for data: 795869184
I0630 14:51:30.867612 47538 layer_factory.hpp:77] Creating layer scale_conv2
I0630 14:51:30.867626 47538 net.cpp:91] Creating Layer scale_conv2
I0630 14:51:30.867632 47538 net.cpp:425] scale_conv2 <- conv1b_bn
I0630 14:51:30.867641 47538 net.cpp:386] scale_conv2 -> conv1b_bn (in-place)
I0630 14:51:30.867724 47538 layer_factory.hpp:77] Creating layer scale_conv2
I0630 14:51:30.870297 47538 net.cpp:141] Setting up scale_conv2
I0630 14:51:30.870317 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:30.870323 47538 net.cpp:156] Memory required for data: 839909376
I0630 14:51:30.870340 47538 layer_factory.hpp:77] Creating layer relu1b
I0630 14:51:30.870352 47538 net.cpp:91] Creating Layer relu1b
I0630 14:51:30.870358 47538 net.cpp:425] relu1b <- conv1b_bn
I0630 14:51:30.870370 47538 net.cpp:386] relu1b -> conv1b_bn (in-place)
I0630 14:51:30.870709 47538 net.cpp:141] Setting up relu1b
I0630 14:51:30.870723 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:30.870729 47538 net.cpp:156] Memory required for data: 883949568
I0630 14:51:30.870735 47538 layer_factory.hpp:77] Creating layer conv1c
I0630 14:51:30.870769 47538 net.cpp:91] Creating Layer conv1c
I0630 14:51:30.870776 47538 net.cpp:425] conv1c <- conv1b_bn
I0630 14:51:30.870787 47538 net.cpp:399] conv1c -> conv1c
I0630 14:51:30.879209 47538 net.cpp:141] Setting up conv1c
I0630 14:51:30.879232 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.879240 47538 net.cpp:156] Memory required for data: 909115392
I0630 14:51:30.879251 47538 layer_factory.hpp:77] Creating layer conv1c_conv1c_0_split
I0630 14:51:30.879264 47538 net.cpp:91] Creating Layer conv1c_conv1c_0_split
I0630 14:51:30.879272 47538 net.cpp:425] conv1c_conv1c_0_split <- conv1c
I0630 14:51:30.879285 47538 net.cpp:399] conv1c_conv1c_0_split -> conv1c_conv1c_0_split_0
I0630 14:51:30.879300 47538 net.cpp:399] conv1c_conv1c_0_split -> conv1c_conv1c_0_split_1
I0630 14:51:30.879391 47538 net.cpp:141] Setting up conv1c_conv1c_0_split
I0630 14:51:30.879403 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.879411 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.879416 47538 net.cpp:156] Memory required for data: 959447040
I0630 14:51:30.879422 47538 layer_factory.hpp:77] Creating layer bn3
I0630 14:51:30.879442 47538 net.cpp:91] Creating Layer bn3
I0630 14:51:30.879449 47538 net.cpp:425] bn3 <- conv1c_conv1c_0_split_0
I0630 14:51:30.879462 47538 net.cpp:399] bn3 -> conv1c_bn
I0630 14:51:30.879902 47538 net.cpp:141] Setting up bn3
I0630 14:51:30.879918 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.879925 47538 net.cpp:156] Memory required for data: 984612864
I0630 14:51:30.879937 47538 layer_factory.hpp:77] Creating layer scale_conv3
I0630 14:51:30.879947 47538 net.cpp:91] Creating Layer scale_conv3
I0630 14:51:30.879956 47538 net.cpp:425] scale_conv3 <- conv1c_bn
I0630 14:51:30.879966 47538 net.cpp:386] scale_conv3 -> conv1c_bn (in-place)
I0630 14:51:30.880051 47538 layer_factory.hpp:77] Creating layer scale_conv3
I0630 14:51:30.880359 47538 net.cpp:141] Setting up scale_conv3
I0630 14:51:30.880373 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.880378 47538 net.cpp:156] Memory required for data: 1009778688
I0630 14:51:30.880389 47538 layer_factory.hpp:77] Creating layer relu1c
I0630 14:51:30.880401 47538 net.cpp:91] Creating Layer relu1c
I0630 14:51:30.880409 47538 net.cpp:425] relu1c <- conv1c_bn
I0630 14:51:30.880419 47538 net.cpp:386] relu1c -> conv1c_bn (in-place)
I0630 14:51:30.880748 47538 net.cpp:141] Setting up relu1c
I0630 14:51:30.880765 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:30.880772 47538 net.cpp:156] Memory required for data: 1034944512
I0630 14:51:30.880779 47538 layer_factory.hpp:77] Creating layer pool1
I0630 14:51:30.880790 47538 net.cpp:91] Creating Layer pool1
I0630 14:51:30.880797 47538 net.cpp:425] pool1 <- conv1c_bn
I0630 14:51:30.880811 47538 net.cpp:399] pool1 -> pool1
I0630 14:51:30.887488 47538 net.cpp:141] Setting up pool1
I0630 14:51:30.887509 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:30.887516 47538 net.cpp:156] Memory required for data: 1038090240
I0630 14:51:30.887527 47538 layer_factory.hpp:77] Creating layer conv2a-Convolution1
I0630 14:51:30.887549 47538 net.cpp:91] Creating Layer conv2a-Convolution1
I0630 14:51:30.887557 47538 net.cpp:425] conv2a-Convolution1 <- pool1
I0630 14:51:30.887571 47538 net.cpp:399] conv2a-Convolution1 -> conv2a-Convolution1
I0630 14:51:30.889993 47538 net.cpp:141] Setting up conv2a-Convolution1
I0630 14:51:30.890009 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:30.890015 47538 net.cpp:156] Memory required for data: 1041235968
I0630 14:51:30.890027 47538 layer_factory.hpp:77] Creating layer conv2a-Convolution1_conv2a-Convolution1_0_split
I0630 14:51:30.890039 47538 net.cpp:91] Creating Layer conv2a-Convolution1_conv2a-Convolution1_0_split
I0630 14:51:30.890046 47538 net.cpp:425] conv2a-Convolution1_conv2a-Convolution1_0_split <- conv2a-Convolution1
I0630 14:51:30.890058 47538 net.cpp:399] conv2a-Convolution1_conv2a-Convolution1_0_split -> conv2a-Convolution1_conv2a-Convolution1_0_split_0
I0630 14:51:30.890071 47538 net.cpp:399] conv2a-Convolution1_conv2a-Convolution1_0_split -> conv2a-Convolution1_conv2a-Convolution1_0_split_1
I0630 14:51:30.890151 47538 net.cpp:141] Setting up conv2a-Convolution1_conv2a-Convolution1_0_split
I0630 14:51:30.890161 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:30.890167 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:30.890172 47538 net.cpp:156] Memory required for data: 1047527424
I0630 14:51:30.890179 47538 layer_factory.hpp:77] Creating layer conv2a-BatchNorm1
I0630 14:51:30.890192 47538 net.cpp:91] Creating Layer conv2a-BatchNorm1
I0630 14:51:30.890198 47538 net.cpp:425] conv2a-BatchNorm1 <- conv2a-Convolution1_conv2a-Convolution1_0_split_0
I0630 14:51:30.890208 47538 net.cpp:399] conv2a-BatchNorm1 -> conv2a-BatchNorm1
I0630 14:51:30.890596 47538 net.cpp:141] Setting up conv2a-BatchNorm1
I0630 14:51:30.890606 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:30.890612 47538 net.cpp:156] Memory required for data: 1050673152
I0630 14:51:30.890624 47538 layer_factory.hpp:77] Creating layer conv2a-Scale1
I0630 14:51:30.890640 47538 net.cpp:91] Creating Layer conv2a-Scale1
I0630 14:51:30.890646 47538 net.cpp:425] conv2a-Scale1 <- conv2a-BatchNorm1
I0630 14:51:30.890655 47538 net.cpp:386] conv2a-Scale1 -> conv2a-BatchNorm1 (in-place)
I0630 14:51:30.890730 47538 layer_factory.hpp:77] Creating layer conv2a-Scale1
I0630 14:51:30.890952 47538 net.cpp:141] Setting up conv2a-Scale1
I0630 14:51:30.890964 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:30.890969 47538 net.cpp:156] Memory required for data: 1053818880
I0630 14:51:30.890986 47538 layer_factory.hpp:77] Creating layer conv2a-ReLU1
I0630 14:51:30.890996 47538 net.cpp:91] Creating Layer conv2a-ReLU1
I0630 14:51:30.891002 47538 net.cpp:425] conv2a-ReLU1 <- conv2a-BatchNorm1
I0630 14:51:30.891019 47538 net.cpp:386] conv2a-ReLU1 -> conv2a-BatchNorm1 (in-place)
I0630 14:51:30.892454 47538 net.cpp:141] Setting up conv2a-ReLU1
I0630 14:51:30.892473 47538 net.cpp:148] Top shape: 3 64 16 16 16 (786432)
I0630 14:51:30.892479 47538 net.cpp:156] Memory required for data: 1056964608
I0630 14:51:30.892485 47538 layer_factory.hpp:77] Creating layer conv2a-Convolution2
I0630 14:51:30.892504 47538 net.cpp:91] Creating Layer conv2a-Convolution2
I0630 14:51:30.892513 47538 net.cpp:425] conv2a-Convolution2 <- conv2a-BatchNorm1
I0630 14:51:30.892527 47538 net.cpp:399] conv2a-Convolution2 -> conv2a-Convolution2
I0630 14:51:30.896389 47538 net.cpp:141] Setting up conv2a-Convolution2
I0630 14:51:30.896411 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:30.896418 47538 net.cpp:156] Memory required for data: 1058537472
I0630 14:51:30.896430 47538 layer_factory.hpp:77] Creating layer conv2a-Dropout1
I0630 14:51:30.896442 47538 net.cpp:91] Creating Layer conv2a-Dropout1
I0630 14:51:30.896463 47538 net.cpp:425] conv2a-Dropout1 <- conv2a-Convolution2
I0630 14:51:30.896474 47538 net.cpp:399] conv2a-Dropout1 -> conv2a-Dropout1
I0630 14:51:30.896556 47538 net.cpp:141] Setting up conv2a-Dropout1
I0630 14:51:30.896567 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:30.896572 47538 net.cpp:156] Memory required for data: 1060110336
I0630 14:51:30.896582 47538 layer_factory.hpp:77] Creating layer conv2a-Concat1
I0630 14:51:30.896592 47538 net.cpp:91] Creating Layer conv2a-Concat1
I0630 14:51:30.896598 47538 net.cpp:425] conv2a-Concat1 <- conv2a-Convolution1_conv2a-Convolution1_0_split_1
I0630 14:51:30.896606 47538 net.cpp:425] conv2a-Concat1 <- conv2a-Dropout1
I0630 14:51:30.896620 47538 net.cpp:399] conv2a-Concat1 -> conv2a-Concat1
I0630 14:51:30.896662 47538 net.cpp:141] Setting up conv2a-Concat1
I0630 14:51:30.896674 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:30.896679 47538 net.cpp:156] Memory required for data: 1064828928
I0630 14:51:30.896687 47538 layer_factory.hpp:77] Creating layer conv2a-Concat1_conv2a-Concat1_0_split
I0630 14:51:30.896697 47538 net.cpp:91] Creating Layer conv2a-Concat1_conv2a-Concat1_0_split
I0630 14:51:30.896704 47538 net.cpp:425] conv2a-Concat1_conv2a-Concat1_0_split <- conv2a-Concat1
I0630 14:51:30.896713 47538 net.cpp:399] conv2a-Concat1_conv2a-Concat1_0_split -> conv2a-Concat1_conv2a-Concat1_0_split_0
I0630 14:51:30.896728 47538 net.cpp:399] conv2a-Concat1_conv2a-Concat1_0_split -> conv2a-Concat1_conv2a-Concat1_0_split_1
I0630 14:51:30.896793 47538 net.cpp:141] Setting up conv2a-Concat1_conv2a-Concat1_0_split
I0630 14:51:30.896802 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:30.896809 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:30.896816 47538 net.cpp:156] Memory required for data: 1074266112
I0630 14:51:30.896821 47538 layer_factory.hpp:77] Creating layer conv2a-BatchNorm2
I0630 14:51:30.896836 47538 net.cpp:91] Creating Layer conv2a-BatchNorm2
I0630 14:51:30.896842 47538 net.cpp:425] conv2a-BatchNorm2 <- conv2a-Concat1_conv2a-Concat1_0_split_0
I0630 14:51:30.896854 47538 net.cpp:399] conv2a-BatchNorm2 -> conv2a-BatchNorm2
I0630 14:51:30.897234 47538 net.cpp:141] Setting up conv2a-BatchNorm2
I0630 14:51:30.897244 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:30.897250 47538 net.cpp:156] Memory required for data: 1078984704
I0630 14:51:30.897264 47538 layer_factory.hpp:77] Creating layer conv2a-Scale2
I0630 14:51:30.897275 47538 net.cpp:91] Creating Layer conv2a-Scale2
I0630 14:51:30.897281 47538 net.cpp:425] conv2a-Scale2 <- conv2a-BatchNorm2
I0630 14:51:30.897294 47538 net.cpp:386] conv2a-Scale2 -> conv2a-BatchNorm2 (in-place)
I0630 14:51:30.897372 47538 layer_factory.hpp:77] Creating layer conv2a-Scale2
I0630 14:51:30.897598 47538 net.cpp:141] Setting up conv2a-Scale2
I0630 14:51:30.897608 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:30.897614 47538 net.cpp:156] Memory required for data: 1083703296
I0630 14:51:30.897630 47538 layer_factory.hpp:77] Creating layer conv2a-ReLU2
I0630 14:51:30.897655 47538 net.cpp:91] Creating Layer conv2a-ReLU2
I0630 14:51:30.897662 47538 net.cpp:425] conv2a-ReLU2 <- conv2a-BatchNorm2
I0630 14:51:30.897673 47538 net.cpp:386] conv2a-ReLU2 -> conv2a-BatchNorm2 (in-place)
I0630 14:51:30.897984 47538 net.cpp:141] Setting up conv2a-ReLU2
I0630 14:51:30.897997 47538 net.cpp:148] Top shape: 3 96 16 16 16 (1179648)
I0630 14:51:30.898003 47538 net.cpp:156] Memory required for data: 1088421888
I0630 14:51:30.898010 47538 layer_factory.hpp:77] Creating layer conv2a-Convolution3
I0630 14:51:30.898031 47538 net.cpp:91] Creating Layer conv2a-Convolution3
I0630 14:51:30.898037 47538 net.cpp:425] conv2a-Convolution3 <- conv2a-BatchNorm2
I0630 14:51:30.898051 47538 net.cpp:399] conv2a-Convolution3 -> conv2a-Convolution3
I0630 14:51:30.902721 47538 net.cpp:141] Setting up conv2a-Convolution3
I0630 14:51:30.902745 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:30.902751 47538 net.cpp:156] Memory required for data: 1089994752
I0630 14:51:30.902762 47538 layer_factory.hpp:77] Creating layer conv2a-Dropout2
I0630 14:51:30.902774 47538 net.cpp:91] Creating Layer conv2a-Dropout2
I0630 14:51:30.902782 47538 net.cpp:425] conv2a-Dropout2 <- conv2a-Convolution3
I0630 14:51:30.902797 47538 net.cpp:399] conv2a-Dropout2 -> conv2a-Dropout2
I0630 14:51:30.902882 47538 net.cpp:141] Setting up conv2a-Dropout2
I0630 14:51:30.902892 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:30.902899 47538 net.cpp:156] Memory required for data: 1091567616
I0630 14:51:30.902909 47538 layer_factory.hpp:77] Creating layer conv2a-Concat2
I0630 14:51:30.902920 47538 net.cpp:91] Creating Layer conv2a-Concat2
I0630 14:51:30.902927 47538 net.cpp:425] conv2a-Concat2 <- conv2a-Concat1_conv2a-Concat1_0_split_1
I0630 14:51:30.902936 47538 net.cpp:425] conv2a-Concat2 <- conv2a-Dropout2
I0630 14:51:30.902945 47538 net.cpp:399] conv2a-Concat2 -> conv2a-Concat2
I0630 14:51:30.903013 47538 net.cpp:141] Setting up conv2a-Concat2
I0630 14:51:30.903023 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.903030 47538 net.cpp:156] Memory required for data: 1097859072
I0630 14:51:30.903035 47538 layer_factory.hpp:77] Creating layer conv2a-Concat2_conv2a-Concat2_0_split
I0630 14:51:30.903045 47538 net.cpp:91] Creating Layer conv2a-Concat2_conv2a-Concat2_0_split
I0630 14:51:30.903051 47538 net.cpp:425] conv2a-Concat2_conv2a-Concat2_0_split <- conv2a-Concat2
I0630 14:51:30.903064 47538 net.cpp:399] conv2a-Concat2_conv2a-Concat2_0_split -> conv2a-Concat2_conv2a-Concat2_0_split_0
I0630 14:51:30.903075 47538 net.cpp:399] conv2a-Concat2_conv2a-Concat2_0_split -> conv2a-Concat2_conv2a-Concat2_0_split_1
I0630 14:51:30.903143 47538 net.cpp:141] Setting up conv2a-Concat2_conv2a-Concat2_0_split
I0630 14:51:30.903152 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.903160 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.903165 47538 net.cpp:156] Memory required for data: 1110441984
I0630 14:51:30.903172 47538 layer_factory.hpp:77] Creating layer conv2a-BatchNorm3
I0630 14:51:30.903184 47538 net.cpp:91] Creating Layer conv2a-BatchNorm3
I0630 14:51:30.903192 47538 net.cpp:425] conv2a-BatchNorm3 <- conv2a-Concat2_conv2a-Concat2_0_split_0
I0630 14:51:30.903201 47538 net.cpp:399] conv2a-BatchNorm3 -> conv2a-BatchNorm3
I0630 14:51:30.903576 47538 net.cpp:141] Setting up conv2a-BatchNorm3
I0630 14:51:30.903586 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.903592 47538 net.cpp:156] Memory required for data: 1116733440
I0630 14:51:30.903605 47538 layer_factory.hpp:77] Creating layer conv2a-Scale3
I0630 14:51:30.903614 47538 net.cpp:91] Creating Layer conv2a-Scale3
I0630 14:51:30.903620 47538 net.cpp:425] conv2a-Scale3 <- conv2a-BatchNorm3
I0630 14:51:30.903632 47538 net.cpp:386] conv2a-Scale3 -> conv2a-BatchNorm3 (in-place)
I0630 14:51:30.903710 47538 layer_factory.hpp:77] Creating layer conv2a-Scale3
I0630 14:51:30.903915 47538 net.cpp:141] Setting up conv2a-Scale3
I0630 14:51:30.903931 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.903954 47538 net.cpp:156] Memory required for data: 1123024896
I0630 14:51:30.903966 47538 layer_factory.hpp:77] Creating layer conv2a-ReLU3
I0630 14:51:30.903980 47538 net.cpp:91] Creating Layer conv2a-ReLU3
I0630 14:51:30.903985 47538 net.cpp:425] conv2a-ReLU3 <- conv2a-BatchNorm3
I0630 14:51:30.903995 47538 net.cpp:386] conv2a-ReLU3 -> conv2a-BatchNorm3 (in-place)
I0630 14:51:30.904301 47538 net.cpp:141] Setting up conv2a-ReLU3
I0630 14:51:30.904314 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.904320 47538 net.cpp:156] Memory required for data: 1129316352
I0630 14:51:30.904326 47538 layer_factory.hpp:77] Creating layer conv2a-Convolution4
I0630 14:51:30.904348 47538 net.cpp:91] Creating Layer conv2a-Convolution4
I0630 14:51:30.904356 47538 net.cpp:425] conv2a-Convolution4 <- conv2a-BatchNorm3
I0630 14:51:30.904366 47538 net.cpp:399] conv2a-Convolution4 -> conv2a-Convolution4
I0630 14:51:30.908002 47538 net.cpp:141] Setting up conv2a-Convolution4
I0630 14:51:30.908020 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:30.908026 47538 net.cpp:156] Memory required for data: 1130889216
I0630 14:51:30.908051 47538 layer_factory.hpp:77] Creating layer conv2a-Dropout3
I0630 14:51:30.908066 47538 net.cpp:91] Creating Layer conv2a-Dropout3
I0630 14:51:30.908072 47538 net.cpp:425] conv2a-Dropout3 <- conv2a-Convolution4
I0630 14:51:30.908082 47538 net.cpp:399] conv2a-Dropout3 -> conv2a-Dropout3
I0630 14:51:30.908156 47538 net.cpp:141] Setting up conv2a-Dropout3
I0630 14:51:30.908166 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:30.908171 47538 net.cpp:156] Memory required for data: 1132462080
I0630 14:51:30.908177 47538 layer_factory.hpp:77] Creating layer conv2a-Concat3
I0630 14:51:30.908193 47538 net.cpp:91] Creating Layer conv2a-Concat3
I0630 14:51:30.908201 47538 net.cpp:425] conv2a-Concat3 <- conv2a-Concat2_conv2a-Concat2_0_split_1
I0630 14:51:30.908208 47538 net.cpp:425] conv2a-Concat3 <- conv2a-Dropout3
I0630 14:51:30.908216 47538 net.cpp:399] conv2a-Concat3 -> conv2a
I0630 14:51:30.908259 47538 net.cpp:141] Setting up conv2a-Concat3
I0630 14:51:30.908269 47538 net.cpp:148] Top shape: 3 160 16 16 16 (1966080)
I0630 14:51:30.908274 47538 net.cpp:156] Memory required for data: 1140326400
I0630 14:51:30.908279 47538 layer_factory.hpp:77] Creating layer bn4
I0630 14:51:30.908291 47538 net.cpp:91] Creating Layer bn4
I0630 14:51:30.908298 47538 net.cpp:425] bn4 <- conv2a
I0630 14:51:30.908308 47538 net.cpp:399] bn4 -> conv2a_bn
I0630 14:51:30.908672 47538 net.cpp:141] Setting up bn4
I0630 14:51:30.908682 47538 net.cpp:148] Top shape: 3 160 16 16 16 (1966080)
I0630 14:51:30.908689 47538 net.cpp:156] Memory required for data: 1148190720
I0630 14:51:30.908700 47538 layer_factory.hpp:77] Creating layer scale_conv4
I0630 14:51:30.908711 47538 net.cpp:91] Creating Layer scale_conv4
I0630 14:51:30.908717 47538 net.cpp:425] scale_conv4 <- conv2a_bn
I0630 14:51:30.908725 47538 net.cpp:386] scale_conv4 -> conv2a_bn (in-place)
I0630 14:51:30.908797 47538 layer_factory.hpp:77] Creating layer scale_conv4
I0630 14:51:30.909001 47538 net.cpp:141] Setting up scale_conv4
I0630 14:51:30.909011 47538 net.cpp:148] Top shape: 3 160 16 16 16 (1966080)
I0630 14:51:30.909018 47538 net.cpp:156] Memory required for data: 1156055040
I0630 14:51:30.909027 47538 layer_factory.hpp:77] Creating layer relu2a
I0630 14:51:30.909037 47538 net.cpp:91] Creating Layer relu2a
I0630 14:51:30.909044 47538 net.cpp:425] relu2a <- conv2a_bn
I0630 14:51:30.909051 47538 net.cpp:386] relu2a -> conv2a_bn (in-place)
I0630 14:51:30.909339 47538 net.cpp:141] Setting up relu2a
I0630 14:51:30.909351 47538 net.cpp:148] Top shape: 3 160 16 16 16 (1966080)
I0630 14:51:30.909358 47538 net.cpp:156] Memory required for data: 1163919360
I0630 14:51:30.909365 47538 layer_factory.hpp:77] Creating layer conv2b
I0630 14:51:30.909382 47538 net.cpp:91] Creating Layer conv2b
I0630 14:51:30.909389 47538 net.cpp:425] conv2b <- conv2a_bn
I0630 14:51:30.909406 47538 net.cpp:399] conv2b -> conv2b
I0630 14:51:30.918325 47538 net.cpp:141] Setting up conv2b
I0630 14:51:30.918359 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.918365 47538 net.cpp:156] Memory required for data: 1170210816
I0630 14:51:30.918376 47538 layer_factory.hpp:77] Creating layer conv2b_conv2b_0_split
I0630 14:51:30.918398 47538 net.cpp:91] Creating Layer conv2b_conv2b_0_split
I0630 14:51:30.918406 47538 net.cpp:425] conv2b_conv2b_0_split <- conv2b
I0630 14:51:30.918414 47538 net.cpp:399] conv2b_conv2b_0_split -> conv2b_conv2b_0_split_0
I0630 14:51:30.918427 47538 net.cpp:399] conv2b_conv2b_0_split -> conv2b_conv2b_0_split_1
I0630 14:51:30.918503 47538 net.cpp:141] Setting up conv2b_conv2b_0_split
I0630 14:51:30.918512 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.918519 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.918524 47538 net.cpp:156] Memory required for data: 1182793728
I0630 14:51:30.918531 47538 layer_factory.hpp:77] Creating layer bn5
I0630 14:51:30.918545 47538 net.cpp:91] Creating Layer bn5
I0630 14:51:30.918550 47538 net.cpp:425] bn5 <- conv2b_conv2b_0_split_0
I0630 14:51:30.918561 47538 net.cpp:399] bn5 -> conv2b_bn
I0630 14:51:30.918922 47538 net.cpp:141] Setting up bn5
I0630 14:51:30.918932 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.918937 47538 net.cpp:156] Memory required for data: 1189085184
I0630 14:51:30.918948 47538 layer_factory.hpp:77] Creating layer scale_conv5_fine
I0630 14:51:30.918962 47538 net.cpp:91] Creating Layer scale_conv5_fine
I0630 14:51:30.918968 47538 net.cpp:425] scale_conv5_fine <- conv2b_bn
I0630 14:51:30.918987 47538 net.cpp:386] scale_conv5_fine -> conv2b_bn (in-place)
I0630 14:51:30.919061 47538 layer_factory.hpp:77] Creating layer scale_conv5_fine
I0630 14:51:30.919263 47538 net.cpp:141] Setting up scale_conv5_fine
I0630 14:51:30.919273 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.919277 47538 net.cpp:156] Memory required for data: 1195376640
I0630 14:51:30.919286 47538 layer_factory.hpp:77] Creating layer relu2b
I0630 14:51:30.919298 47538 net.cpp:91] Creating Layer relu2b
I0630 14:51:30.919304 47538 net.cpp:425] relu2b <- conv2b_bn
I0630 14:51:30.919312 47538 net.cpp:386] relu2b -> conv2b_bn (in-place)
I0630 14:51:30.919586 47538 net.cpp:141] Setting up relu2b
I0630 14:51:30.919600 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:30.919605 47538 net.cpp:156] Memory required for data: 1201668096
I0630 14:51:30.919610 47538 layer_factory.hpp:77] Creating layer pool2
I0630 14:51:30.919621 47538 net.cpp:91] Creating Layer pool2
I0630 14:51:30.919628 47538 net.cpp:425] pool2 <- conv2b_bn
I0630 14:51:30.919636 47538 net.cpp:399] pool2 -> pool2
I0630 14:51:30.922103 47538 net.cpp:141] Setting up pool2
I0630 14:51:30.922125 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:30.922132 47538 net.cpp:156] Memory required for data: 1202454528
I0630 14:51:30.922138 47538 layer_factory.hpp:77] Creating layer conv3a
I0630 14:51:30.922159 47538 net.cpp:91] Creating Layer conv3a
I0630 14:51:30.922166 47538 net.cpp:425] conv3a <- pool2
I0630 14:51:30.922178 47538 net.cpp:399] conv3a -> conv3a
I0630 14:51:30.931288 47538 net.cpp:141] Setting up conv3a
I0630 14:51:30.931306 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:30.931313 47538 net.cpp:156] Memory required for data: 1203240960
I0630 14:51:30.931326 47538 layer_factory.hpp:77] Creating layer conv3a_conv3a_0_split
I0630 14:51:30.931341 47538 net.cpp:91] Creating Layer conv3a_conv3a_0_split
I0630 14:51:30.931349 47538 net.cpp:425] conv3a_conv3a_0_split <- conv3a
I0630 14:51:30.931357 47538 net.cpp:399] conv3a_conv3a_0_split -> conv3a_conv3a_0_split_0
I0630 14:51:30.931373 47538 net.cpp:399] conv3a_conv3a_0_split -> conv3a_conv3a_0_split_1
I0630 14:51:30.931452 47538 net.cpp:141] Setting up conv3a_conv3a_0_split
I0630 14:51:30.931460 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:30.931468 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:30.931478 47538 net.cpp:156] Memory required for data: 1204813824
I0630 14:51:30.931497 47538 layer_factory.hpp:77] Creating layer bn6
I0630 14:51:30.931510 47538 net.cpp:91] Creating Layer bn6
I0630 14:51:30.931516 47538 net.cpp:425] bn6 <- conv3a_conv3a_0_split_0
I0630 14:51:30.931529 47538 net.cpp:399] bn6 -> conv3a_bn
I0630 14:51:30.931870 47538 net.cpp:141] Setting up bn6
I0630 14:51:30.931879 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:30.931885 47538 net.cpp:156] Memory required for data: 1205600256
I0630 14:51:30.931896 47538 layer_factory.hpp:77] Creating layer scale_conv6
I0630 14:51:30.931905 47538 net.cpp:91] Creating Layer scale_conv6
I0630 14:51:30.931910 47538 net.cpp:425] scale_conv6 <- conv3a_bn
I0630 14:51:30.931921 47538 net.cpp:386] scale_conv6 -> conv3a_bn (in-place)
I0630 14:51:30.931988 47538 layer_factory.hpp:77] Creating layer scale_conv6
I0630 14:51:30.932169 47538 net.cpp:141] Setting up scale_conv6
I0630 14:51:30.932181 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:30.932186 47538 net.cpp:156] Memory required for data: 1206386688
I0630 14:51:30.932199 47538 layer_factory.hpp:77] Creating layer relu3a
I0630 14:51:30.932206 47538 net.cpp:91] Creating Layer relu3a
I0630 14:51:30.932212 47538 net.cpp:425] relu3a <- conv3a_bn
I0630 14:51:30.932219 47538 net.cpp:386] relu3a -> conv3a_bn (in-place)
I0630 14:51:30.932515 47538 net.cpp:141] Setting up relu3a
I0630 14:51:30.932528 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:30.932533 47538 net.cpp:156] Memory required for data: 1207173120
I0630 14:51:30.932539 47538 layer_factory.hpp:77] Creating layer pool3
I0630 14:51:30.932551 47538 net.cpp:91] Creating Layer pool3
I0630 14:51:30.932557 47538 net.cpp:425] pool3 <- conv3a_bn
I0630 14:51:30.932577 47538 net.cpp:399] pool3 -> pool3
I0630 14:51:30.932922 47538 net.cpp:141] Setting up pool3
I0630 14:51:30.932936 47538 net.cpp:148] Top shape: 3 128 4 4 4 (24576)
I0630 14:51:30.932941 47538 net.cpp:156] Memory required for data: 1207271424
I0630 14:51:30.932947 47538 layer_factory.hpp:77] Creating layer deconv4
I0630 14:51:30.932960 47538 net.cpp:91] Creating Layer deconv4
I0630 14:51:30.932967 47538 net.cpp:425] deconv4 <- pool3
I0630 14:51:30.932976 47538 net.cpp:399] deconv4 -> deconv4
I0630 14:51:30.944636 47538 net.cpp:141] Setting up deconv4
I0630 14:51:30.944664 47538 net.cpp:148] Top shape: 3 128 8 8 8 (196608)
I0630 14:51:30.944669 47538 net.cpp:156] Memory required for data: 1208057856
I0630 14:51:30.944679 47538 layer_factory.hpp:77] Creating layer concat8
I0630 14:51:30.944690 47538 net.cpp:91] Creating Layer concat8
I0630 14:51:30.944696 47538 net.cpp:425] concat8 <- conv3a_conv3a_0_split_1
I0630 14:51:30.944705 47538 net.cpp:425] concat8 <- deconv4
I0630 14:51:30.944718 47538 net.cpp:399] concat8 -> concat8
I0630 14:51:30.944763 47538 net.cpp:141] Setting up concat8
I0630 14:51:30.944772 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:30.944777 47538 net.cpp:156] Memory required for data: 1209630720
I0630 14:51:30.944784 47538 layer_factory.hpp:77] Creating layer conv4-Convolution1
I0630 14:51:30.944802 47538 net.cpp:91] Creating Layer conv4-Convolution1
I0630 14:51:30.944808 47538 net.cpp:425] conv4-Convolution1 <- concat8
I0630 14:51:30.944818 47538 net.cpp:399] conv4-Convolution1 -> conv4-Convolution1
I0630 14:51:30.963299 47538 net.cpp:141] Setting up conv4-Convolution1
I0630 14:51:30.963320 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:30.963325 47538 net.cpp:156] Memory required for data: 1211203584
I0630 14:51:30.963335 47538 layer_factory.hpp:77] Creating layer conv4-Convolution1_conv4-Convolution1_0_split
I0630 14:51:30.963344 47538 net.cpp:91] Creating Layer conv4-Convolution1_conv4-Convolution1_0_split
I0630 14:51:30.963351 47538 net.cpp:425] conv4-Convolution1_conv4-Convolution1_0_split <- conv4-Convolution1
I0630 14:51:30.963362 47538 net.cpp:399] conv4-Convolution1_conv4-Convolution1_0_split -> conv4-Convolution1_conv4-Convolution1_0_split_0
I0630 14:51:30.963374 47538 net.cpp:399] conv4-Convolution1_conv4-Convolution1_0_split -> conv4-Convolution1_conv4-Convolution1_0_split_1
I0630 14:51:30.963467 47538 net.cpp:141] Setting up conv4-Convolution1_conv4-Convolution1_0_split
I0630 14:51:30.963476 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:30.963482 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:30.963488 47538 net.cpp:156] Memory required for data: 1214349312
I0630 14:51:30.963492 47538 layer_factory.hpp:77] Creating layer conv4-BatchNorm1
I0630 14:51:30.963505 47538 net.cpp:91] Creating Layer conv4-BatchNorm1
I0630 14:51:30.963510 47538 net.cpp:425] conv4-BatchNorm1 <- conv4-Convolution1_conv4-Convolution1_0_split_0
I0630 14:51:30.963519 47538 net.cpp:399] conv4-BatchNorm1 -> conv4-BatchNorm1
I0630 14:51:30.963829 47538 net.cpp:141] Setting up conv4-BatchNorm1
I0630 14:51:30.963836 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:30.963841 47538 net.cpp:156] Memory required for data: 1215922176
I0630 14:51:30.963855 47538 layer_factory.hpp:77] Creating layer conv4-Scale1
I0630 14:51:30.963865 47538 net.cpp:91] Creating Layer conv4-Scale1
I0630 14:51:30.963869 47538 net.cpp:425] conv4-Scale1 <- conv4-BatchNorm1
I0630 14:51:30.963881 47538 net.cpp:386] conv4-Scale1 -> conv4-BatchNorm1 (in-place)
I0630 14:51:30.963945 47538 layer_factory.hpp:77] Creating layer conv4-Scale1
I0630 14:51:30.964138 47538 net.cpp:141] Setting up conv4-Scale1
I0630 14:51:30.964148 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:30.964151 47538 net.cpp:156] Memory required for data: 1217495040
I0630 14:51:30.964160 47538 layer_factory.hpp:77] Creating layer conv4-ReLU1
I0630 14:51:30.964170 47538 net.cpp:91] Creating Layer conv4-ReLU1
I0630 14:51:30.964176 47538 net.cpp:425] conv4-ReLU1 <- conv4-BatchNorm1
I0630 14:51:30.964184 47538 net.cpp:386] conv4-ReLU1 -> conv4-BatchNorm1 (in-place)
I0630 14:51:30.964448 47538 net.cpp:141] Setting up conv4-ReLU1
I0630 14:51:30.964459 47538 net.cpp:148] Top shape: 3 256 8 8 8 (393216)
I0630 14:51:30.964464 47538 net.cpp:156] Memory required for data: 1219067904
I0630 14:51:30.964468 47538 layer_factory.hpp:77] Creating layer conv4-Convolution2
I0630 14:51:30.964488 47538 net.cpp:91] Creating Layer conv4-Convolution2
I0630 14:51:30.964493 47538 net.cpp:425] conv4-Convolution2 <- conv4-BatchNorm1
I0630 14:51:30.964502 47538 net.cpp:399] conv4-Convolution2 -> conv4-Convolution2
I0630 14:51:30.971750 47538 net.cpp:141] Setting up conv4-Convolution2
I0630 14:51:30.971769 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:30.971774 47538 net.cpp:156] Memory required for data: 1219264512
I0630 14:51:30.971783 47538 layer_factory.hpp:77] Creating layer conv4-Dropout1
I0630 14:51:30.971796 47538 net.cpp:91] Creating Layer conv4-Dropout1
I0630 14:51:30.971803 47538 net.cpp:425] conv4-Dropout1 <- conv4-Convolution2
I0630 14:51:30.971812 47538 net.cpp:399] conv4-Dropout1 -> conv4-Dropout1
I0630 14:51:30.971882 47538 net.cpp:141] Setting up conv4-Dropout1
I0630 14:51:30.971890 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:30.971896 47538 net.cpp:156] Memory required for data: 1219461120
I0630 14:51:30.971904 47538 layer_factory.hpp:77] Creating layer conv4-Concat1
I0630 14:51:30.971915 47538 net.cpp:91] Creating Layer conv4-Concat1
I0630 14:51:30.971920 47538 net.cpp:425] conv4-Concat1 <- conv4-Convolution1_conv4-Convolution1_0_split_1
I0630 14:51:30.971927 47538 net.cpp:425] conv4-Concat1 <- conv4-Dropout1
I0630 14:51:30.971935 47538 net.cpp:399] conv4-Concat1 -> conv4-Concat1
I0630 14:51:30.971973 47538 net.cpp:141] Setting up conv4-Concat1
I0630 14:51:30.971982 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:30.971987 47538 net.cpp:156] Memory required for data: 1221230592
I0630 14:51:30.971992 47538 layer_factory.hpp:77] Creating layer conv4-Concat1_conv4-Concat1_0_split
I0630 14:51:30.971999 47538 net.cpp:91] Creating Layer conv4-Concat1_conv4-Concat1_0_split
I0630 14:51:30.972004 47538 net.cpp:425] conv4-Concat1_conv4-Concat1_0_split <- conv4-Concat1
I0630 14:51:30.972015 47538 net.cpp:399] conv4-Concat1_conv4-Concat1_0_split -> conv4-Concat1_conv4-Concat1_0_split_0
I0630 14:51:30.972044 47538 net.cpp:399] conv4-Concat1_conv4-Concat1_0_split -> conv4-Concat1_conv4-Concat1_0_split_1
I0630 14:51:30.972107 47538 net.cpp:141] Setting up conv4-Concat1_conv4-Concat1_0_split
I0630 14:51:30.972115 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:30.972122 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:30.972126 47538 net.cpp:156] Memory required for data: 1224769536
I0630 14:51:30.972131 47538 layer_factory.hpp:77] Creating layer conv4-BatchNorm2
I0630 14:51:30.972142 47538 net.cpp:91] Creating Layer conv4-BatchNorm2
I0630 14:51:30.972148 47538 net.cpp:425] conv4-BatchNorm2 <- conv4-Concat1_conv4-Concat1_0_split_0
I0630 14:51:30.972157 47538 net.cpp:399] conv4-BatchNorm2 -> conv4-BatchNorm2
I0630 14:51:30.972489 47538 net.cpp:141] Setting up conv4-BatchNorm2
I0630 14:51:30.972498 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:30.972503 47538 net.cpp:156] Memory required for data: 1226539008
I0630 14:51:30.972515 47538 layer_factory.hpp:77] Creating layer conv4-Scale2
I0630 14:51:30.972523 47538 net.cpp:91] Creating Layer conv4-Scale2
I0630 14:51:30.972528 47538 net.cpp:425] conv4-Scale2 <- conv4-BatchNorm2
I0630 14:51:30.972537 47538 net.cpp:386] conv4-Scale2 -> conv4-BatchNorm2 (in-place)
I0630 14:51:30.972599 47538 layer_factory.hpp:77] Creating layer conv4-Scale2
I0630 14:51:30.972785 47538 net.cpp:141] Setting up conv4-Scale2
I0630 14:51:30.972795 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:30.972800 47538 net.cpp:156] Memory required for data: 1228308480
I0630 14:51:30.972807 47538 layer_factory.hpp:77] Creating layer conv4-ReLU2
I0630 14:51:30.972817 47538 net.cpp:91] Creating Layer conv4-ReLU2
I0630 14:51:30.972822 47538 net.cpp:425] conv4-ReLU2 <- conv4-BatchNorm2
I0630 14:51:30.972829 47538 net.cpp:386] conv4-ReLU2 -> conv4-BatchNorm2 (in-place)
I0630 14:51:30.973091 47538 net.cpp:141] Setting up conv4-ReLU2
I0630 14:51:30.973104 47538 net.cpp:148] Top shape: 3 288 8 8 8 (442368)
I0630 14:51:30.973107 47538 net.cpp:156] Memory required for data: 1230077952
I0630 14:51:30.973114 47538 layer_factory.hpp:77] Creating layer conv4-Convolution3
I0630 14:51:30.973132 47538 net.cpp:91] Creating Layer conv4-Convolution3
I0630 14:51:30.973138 47538 net.cpp:425] conv4-Convolution3 <- conv4-BatchNorm2
I0630 14:51:30.973146 47538 net.cpp:399] conv4-Convolution3 -> conv4-Convolution3
I0630 14:51:30.976969 47538 net.cpp:141] Setting up conv4-Convolution3
I0630 14:51:30.976984 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:30.976989 47538 net.cpp:156] Memory required for data: 1230274560
I0630 14:51:30.976999 47538 layer_factory.hpp:77] Creating layer conv4-Dropout2
I0630 14:51:30.977011 47538 net.cpp:91] Creating Layer conv4-Dropout2
I0630 14:51:30.977017 47538 net.cpp:425] conv4-Dropout2 <- conv4-Convolution3
I0630 14:51:30.977025 47538 net.cpp:399] conv4-Dropout2 -> conv4-Dropout2
I0630 14:51:30.977093 47538 net.cpp:141] Setting up conv4-Dropout2
I0630 14:51:30.977103 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:30.977108 47538 net.cpp:156] Memory required for data: 1230471168
I0630 14:51:30.977115 47538 layer_factory.hpp:77] Creating layer conv4-Concat2
I0630 14:51:30.977123 47538 net.cpp:91] Creating Layer conv4-Concat2
I0630 14:51:30.977128 47538 net.cpp:425] conv4-Concat2 <- conv4-Concat1_conv4-Concat1_0_split_1
I0630 14:51:30.977134 47538 net.cpp:425] conv4-Concat2 <- conv4-Dropout2
I0630 14:51:30.977147 47538 net.cpp:399] conv4-Concat2 -> conv4-Concat2
I0630 14:51:30.977183 47538 net.cpp:141] Setting up conv4-Concat2
I0630 14:51:30.977195 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:30.977200 47538 net.cpp:156] Memory required for data: 1232437248
I0630 14:51:30.977205 47538 layer_factory.hpp:77] Creating layer conv4-Concat2_conv4-Concat2_0_split
I0630 14:51:30.977211 47538 net.cpp:91] Creating Layer conv4-Concat2_conv4-Concat2_0_split
I0630 14:51:30.977217 47538 net.cpp:425] conv4-Concat2_conv4-Concat2_0_split <- conv4-Concat2
I0630 14:51:30.977231 47538 net.cpp:399] conv4-Concat2_conv4-Concat2_0_split -> conv4-Concat2_conv4-Concat2_0_split_0
I0630 14:51:30.977255 47538 net.cpp:399] conv4-Concat2_conv4-Concat2_0_split -> conv4-Concat2_conv4-Concat2_0_split_1
I0630 14:51:30.977316 47538 net.cpp:141] Setting up conv4-Concat2_conv4-Concat2_0_split
I0630 14:51:30.977324 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:30.977330 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:30.977334 47538 net.cpp:156] Memory required for data: 1236369408
I0630 14:51:30.977339 47538 layer_factory.hpp:77] Creating layer conv4-BatchNorm3
I0630 14:51:30.977352 47538 net.cpp:91] Creating Layer conv4-BatchNorm3
I0630 14:51:30.977357 47538 net.cpp:425] conv4-BatchNorm3 <- conv4-Concat2_conv4-Concat2_0_split_0
I0630 14:51:30.977367 47538 net.cpp:399] conv4-BatchNorm3 -> conv4-BatchNorm3
I0630 14:51:30.977725 47538 net.cpp:141] Setting up conv4-BatchNorm3
I0630 14:51:30.977737 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:30.977742 47538 net.cpp:156] Memory required for data: 1238335488
I0630 14:51:30.977754 47538 layer_factory.hpp:77] Creating layer conv4-Scale3
I0630 14:51:30.977763 47538 net.cpp:91] Creating Layer conv4-Scale3
I0630 14:51:30.977771 47538 net.cpp:425] conv4-Scale3 <- conv4-BatchNorm3
I0630 14:51:30.977777 47538 net.cpp:386] conv4-Scale3 -> conv4-BatchNorm3 (in-place)
I0630 14:51:30.977843 47538 layer_factory.hpp:77] Creating layer conv4-Scale3
I0630 14:51:30.978027 47538 net.cpp:141] Setting up conv4-Scale3
I0630 14:51:30.978037 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:30.978041 47538 net.cpp:156] Memory required for data: 1240301568
I0630 14:51:30.978050 47538 layer_factory.hpp:77] Creating layer conv4-ReLU3
I0630 14:51:30.978057 47538 net.cpp:91] Creating Layer conv4-ReLU3
I0630 14:51:30.978063 47538 net.cpp:425] conv4-ReLU3 <- conv4-BatchNorm3
I0630 14:51:30.978070 47538 net.cpp:386] conv4-ReLU3 -> conv4-BatchNorm3 (in-place)
I0630 14:51:30.979362 47538 net.cpp:141] Setting up conv4-ReLU3
I0630 14:51:30.979377 47538 net.cpp:148] Top shape: 3 320 8 8 8 (491520)
I0630 14:51:30.979382 47538 net.cpp:156] Memory required for data: 1242267648
I0630 14:51:30.979387 47538 layer_factory.hpp:77] Creating layer conv4-Convolution4
I0630 14:51:30.979403 47538 net.cpp:91] Creating Layer conv4-Convolution4
I0630 14:51:30.979409 47538 net.cpp:425] conv4-Convolution4 <- conv4-BatchNorm3
I0630 14:51:30.979424 47538 net.cpp:399] conv4-Convolution4 -> conv4-Convolution4
I0630 14:51:30.984462 47538 net.cpp:141] Setting up conv4-Convolution4
I0630 14:51:30.984479 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:30.984484 47538 net.cpp:156] Memory required for data: 1242464256
I0630 14:51:30.984498 47538 layer_factory.hpp:77] Creating layer conv4-Dropout3
I0630 14:51:30.984506 47538 net.cpp:91] Creating Layer conv4-Dropout3
I0630 14:51:30.984513 47538 net.cpp:425] conv4-Dropout3 <- conv4-Convolution4
I0630 14:51:30.984524 47538 net.cpp:399] conv4-Dropout3 -> conv4-Dropout3
I0630 14:51:30.984592 47538 net.cpp:141] Setting up conv4-Dropout3
I0630 14:51:30.984603 47538 net.cpp:148] Top shape: 3 32 8 8 8 (49152)
I0630 14:51:30.984608 47538 net.cpp:156] Memory required for data: 1242660864
I0630 14:51:30.984612 47538 layer_factory.hpp:77] Creating layer conv4-Concat3
I0630 14:51:30.984622 47538 net.cpp:91] Creating Layer conv4-Concat3
I0630 14:51:30.984627 47538 net.cpp:425] conv4-Concat3 <- conv4-Concat2_conv4-Concat2_0_split_1
I0630 14:51:30.984633 47538 net.cpp:425] conv4-Concat3 <- conv4-Dropout3
I0630 14:51:30.984640 47538 net.cpp:399] conv4-Concat3 -> conv4
I0630 14:51:30.984679 47538 net.cpp:141] Setting up conv4-Concat3
I0630 14:51:30.984686 47538 net.cpp:148] Top shape: 3 352 8 8 8 (540672)
I0630 14:51:30.984690 47538 net.cpp:156] Memory required for data: 1244823552
I0630 14:51:30.984695 47538 layer_factory.hpp:77] Creating layer conv4_bn
I0630 14:51:30.984706 47538 net.cpp:91] Creating Layer conv4_bn
I0630 14:51:30.984711 47538 net.cpp:425] conv4_bn <- conv4
I0630 14:51:30.984725 47538 net.cpp:399] conv4_bn -> conv4_bn
I0630 14:51:30.985085 47538 net.cpp:141] Setting up conv4_bn
I0630 14:51:30.985095 47538 net.cpp:148] Top shape: 3 352 8 8 8 (540672)
I0630 14:51:30.985100 47538 net.cpp:156] Memory required for data: 1246986240
I0630 14:51:30.985110 47538 layer_factory.hpp:77] Creating layer scale_conv4_fine
I0630 14:51:30.985121 47538 net.cpp:91] Creating Layer scale_conv4_fine
I0630 14:51:30.985126 47538 net.cpp:425] scale_conv4_fine <- conv4_bn
I0630 14:51:30.985133 47538 net.cpp:386] scale_conv4_fine -> conv4_bn (in-place)
I0630 14:51:30.985191 47538 layer_factory.hpp:77] Creating layer scale_conv4_fine
I0630 14:51:30.985375 47538 net.cpp:141] Setting up scale_conv4_fine
I0630 14:51:30.985384 47538 net.cpp:148] Top shape: 3 352 8 8 8 (540672)
I0630 14:51:30.985389 47538 net.cpp:156] Memory required for data: 1249148928
I0630 14:51:30.985399 47538 layer_factory.hpp:77] Creating layer relu4a
I0630 14:51:30.985409 47538 net.cpp:91] Creating Layer relu4a
I0630 14:51:30.985415 47538 net.cpp:425] relu4a <- conv4_bn
I0630 14:51:30.985421 47538 net.cpp:386] relu4a -> conv4_bn (in-place)
I0630 14:51:30.991067 47538 net.cpp:141] Setting up relu4a
I0630 14:51:30.991088 47538 net.cpp:148] Top shape: 3 352 8 8 8 (540672)
I0630 14:51:30.991096 47538 net.cpp:156] Memory required for data: 1251311616
I0630 14:51:30.991101 47538 layer_factory.hpp:77] Creating layer deconv5
I0630 14:51:30.991116 47538 net.cpp:91] Creating Layer deconv5
I0630 14:51:30.991122 47538 net.cpp:425] deconv5 <- conv4_bn
I0630 14:51:30.991132 47538 net.cpp:399] deconv5 -> deconv5
I0630 14:51:31.024340 47538 net.cpp:141] Setting up deconv5
I0630 14:51:31.024360 47538 net.cpp:148] Top shape: 3 128 16 16 16 (1572864)
I0630 14:51:31.024365 47538 net.cpp:156] Memory required for data: 1257603072
I0630 14:51:31.024375 47538 layer_factory.hpp:77] Creating layer concat16
I0630 14:51:31.024386 47538 net.cpp:91] Creating Layer concat16
I0630 14:51:31.024392 47538 net.cpp:425] concat16 <- conv2b_conv2b_0_split_1
I0630 14:51:31.024399 47538 net.cpp:425] concat16 <- deconv5
I0630 14:51:31.024411 47538 net.cpp:399] concat16 -> concat16
I0630 14:51:31.024458 47538 net.cpp:141] Setting up concat16
I0630 14:51:31.024466 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.024471 47538 net.cpp:156] Memory required for data: 1270185984
I0630 14:51:31.024477 47538 layer_factory.hpp:77] Creating layer conv5-Convolution1
I0630 14:51:31.024495 47538 net.cpp:91] Creating Layer conv5-Convolution1
I0630 14:51:31.024500 47538 net.cpp:425] conv5-Convolution1 <- concat16
I0630 14:51:31.024513 47538 net.cpp:399] conv5-Convolution1 -> conv5-Convolution1
I0630 14:51:31.045315 47538 net.cpp:141] Setting up conv5-Convolution1
I0630 14:51:31.045354 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.045359 47538 net.cpp:156] Memory required for data: 1282768896
I0630 14:51:31.045368 47538 layer_factory.hpp:77] Creating layer conv5-Convolution1_conv5-Convolution1_0_split
I0630 14:51:31.045382 47538 net.cpp:91] Creating Layer conv5-Convolution1_conv5-Convolution1_0_split
I0630 14:51:31.045388 47538 net.cpp:425] conv5-Convolution1_conv5-Convolution1_0_split <- conv5-Convolution1
I0630 14:51:31.045399 47538 net.cpp:399] conv5-Convolution1_conv5-Convolution1_0_split -> conv5-Convolution1_conv5-Convolution1_0_split_0
I0630 14:51:31.045411 47538 net.cpp:399] conv5-Convolution1_conv5-Convolution1_0_split -> conv5-Convolution1_conv5-Convolution1_0_split_1
I0630 14:51:31.045493 47538 net.cpp:141] Setting up conv5-Convolution1_conv5-Convolution1_0_split
I0630 14:51:31.045502 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.045508 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.045512 47538 net.cpp:156] Memory required for data: 1307934720
I0630 14:51:31.045518 47538 layer_factory.hpp:77] Creating layer conv5-BatchNorm1
I0630 14:51:31.045531 47538 net.cpp:91] Creating Layer conv5-BatchNorm1
I0630 14:51:31.045536 47538 net.cpp:425] conv5-BatchNorm1 <- conv5-Convolution1_conv5-Convolution1_0_split_0
I0630 14:51:31.045549 47538 net.cpp:399] conv5-BatchNorm1 -> conv5-BatchNorm1
I0630 14:51:31.045902 47538 net.cpp:141] Setting up conv5-BatchNorm1
I0630 14:51:31.045912 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.045915 47538 net.cpp:156] Memory required for data: 1320517632
I0630 14:51:31.045926 47538 layer_factory.hpp:77] Creating layer conv5-Scale1
I0630 14:51:31.045938 47538 net.cpp:91] Creating Layer conv5-Scale1
I0630 14:51:31.045944 47538 net.cpp:425] conv5-Scale1 <- conv5-BatchNorm1
I0630 14:51:31.045951 47538 net.cpp:386] conv5-Scale1 -> conv5-BatchNorm1 (in-place)
I0630 14:51:31.046016 47538 layer_factory.hpp:77] Creating layer conv5-Scale1
I0630 14:51:31.046201 47538 net.cpp:141] Setting up conv5-Scale1
I0630 14:51:31.046211 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.046214 47538 net.cpp:156] Memory required for data: 1333100544
I0630 14:51:31.046226 47538 layer_factory.hpp:77] Creating layer conv5-ReLU1
I0630 14:51:31.046234 47538 net.cpp:91] Creating Layer conv5-ReLU1
I0630 14:51:31.046239 47538 net.cpp:425] conv5-ReLU1 <- conv5-BatchNorm1
I0630 14:51:31.046248 47538 net.cpp:386] conv5-ReLU1 -> conv5-BatchNorm1 (in-place)
I0630 14:51:31.046516 47538 net.cpp:141] Setting up conv5-ReLU1
I0630 14:51:31.046528 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.046533 47538 net.cpp:156] Memory required for data: 1345683456
I0630 14:51:31.046538 47538 layer_factory.hpp:77] Creating layer conv5-Convolution2
I0630 14:51:31.046553 47538 net.cpp:91] Creating Layer conv5-Convolution2
I0630 14:51:31.046561 47538 net.cpp:425] conv5-Convolution2 <- conv5-BatchNorm1
I0630 14:51:31.046571 47538 net.cpp:399] conv5-Convolution2 -> conv5-Convolution2
I0630 14:51:31.056533 47538 net.cpp:141] Setting up conv5-Convolution2
I0630 14:51:31.056552 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.056558 47538 net.cpp:156] Memory required for data: 1347256320
I0630 14:51:31.056567 47538 layer_factory.hpp:77] Creating layer conv5-Dropout1
I0630 14:51:31.056578 47538 net.cpp:91] Creating Layer conv5-Dropout1
I0630 14:51:31.056583 47538 net.cpp:425] conv5-Dropout1 <- conv5-Convolution2
I0630 14:51:31.056596 47538 net.cpp:399] conv5-Dropout1 -> conv5-Dropout1
I0630 14:51:31.056668 47538 net.cpp:141] Setting up conv5-Dropout1
I0630 14:51:31.056675 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.056679 47538 net.cpp:156] Memory required for data: 1348829184
I0630 14:51:31.056685 47538 layer_factory.hpp:77] Creating layer conv5-Concat1
I0630 14:51:31.056699 47538 net.cpp:91] Creating Layer conv5-Concat1
I0630 14:51:31.056705 47538 net.cpp:425] conv5-Concat1 <- conv5-Convolution1_conv5-Convolution1_0_split_1
I0630 14:51:31.056711 47538 net.cpp:425] conv5-Concat1 <- conv5-Dropout1
I0630 14:51:31.056722 47538 net.cpp:399] conv5-Concat1 -> conv5-Concat1
I0630 14:51:31.056759 47538 net.cpp:141] Setting up conv5-Concat1
I0630 14:51:31.056767 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.056771 47538 net.cpp:156] Memory required for data: 1362984960
I0630 14:51:31.056777 47538 layer_factory.hpp:77] Creating layer conv5-Concat1_conv5-Concat1_0_split
I0630 14:51:31.056787 47538 net.cpp:91] Creating Layer conv5-Concat1_conv5-Concat1_0_split
I0630 14:51:31.056793 47538 net.cpp:425] conv5-Concat1_conv5-Concat1_0_split <- conv5-Concat1
I0630 14:51:31.056800 47538 net.cpp:399] conv5-Concat1_conv5-Concat1_0_split -> conv5-Concat1_conv5-Concat1_0_split_0
I0630 14:51:31.056813 47538 net.cpp:399] conv5-Concat1_conv5-Concat1_0_split -> conv5-Concat1_conv5-Concat1_0_split_1
I0630 14:51:31.056869 47538 net.cpp:141] Setting up conv5-Concat1_conv5-Concat1_0_split
I0630 14:51:31.056879 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.056885 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.056890 47538 net.cpp:156] Memory required for data: 1391296512
I0630 14:51:31.056895 47538 layer_factory.hpp:77] Creating layer conv5-BatchNorm2
I0630 14:51:31.056905 47538 net.cpp:91] Creating Layer conv5-BatchNorm2
I0630 14:51:31.056915 47538 net.cpp:425] conv5-BatchNorm2 <- conv5-Concat1_conv5-Concat1_0_split_0
I0630 14:51:31.056941 47538 net.cpp:399] conv5-BatchNorm2 -> conv5-BatchNorm2
I0630 14:51:31.057286 47538 net.cpp:141] Setting up conv5-BatchNorm2
I0630 14:51:31.057296 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.057301 47538 net.cpp:156] Memory required for data: 1405452288
I0630 14:51:31.057312 47538 layer_factory.hpp:77] Creating layer conv5-Scale2
I0630 14:51:31.057324 47538 net.cpp:91] Creating Layer conv5-Scale2
I0630 14:51:31.057330 47538 net.cpp:425] conv5-Scale2 <- conv5-BatchNorm2
I0630 14:51:31.057337 47538 net.cpp:386] conv5-Scale2 -> conv5-BatchNorm2 (in-place)
I0630 14:51:31.057407 47538 layer_factory.hpp:77] Creating layer conv5-Scale2
I0630 14:51:31.057610 47538 net.cpp:141] Setting up conv5-Scale2
I0630 14:51:31.057618 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.057623 47538 net.cpp:156] Memory required for data: 1419608064
I0630 14:51:31.057646 47538 layer_factory.hpp:77] Creating layer conv5-ReLU2
I0630 14:51:31.057655 47538 net.cpp:91] Creating Layer conv5-ReLU2
I0630 14:51:31.057662 47538 net.cpp:425] conv5-ReLU2 <- conv5-BatchNorm2
I0630 14:51:31.057667 47538 net.cpp:386] conv5-ReLU2 -> conv5-BatchNorm2 (in-place)
I0630 14:51:31.057932 47538 net.cpp:141] Setting up conv5-ReLU2
I0630 14:51:31.057943 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.057948 47538 net.cpp:156] Memory required for data: 1433763840
I0630 14:51:31.057952 47538 layer_factory.hpp:77] Creating layer conv5-Convolution3
I0630 14:51:31.057971 47538 net.cpp:91] Creating Layer conv5-Convolution3
I0630 14:51:31.057977 47538 net.cpp:425] conv5-Convolution3 <- conv5-BatchNorm2
I0630 14:51:31.057986 47538 net.cpp:399] conv5-Convolution3 -> conv5-Convolution3
I0630 14:51:31.064014 47538 net.cpp:141] Setting up conv5-Convolution3
I0630 14:51:31.064033 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.064038 47538 net.cpp:156] Memory required for data: 1435336704
I0630 14:51:31.064047 47538 layer_factory.hpp:77] Creating layer conv5-Dropout2
I0630 14:51:31.064056 47538 net.cpp:91] Creating Layer conv5-Dropout2
I0630 14:51:31.064064 47538 net.cpp:425] conv5-Dropout2 <- conv5-Convolution3
I0630 14:51:31.064074 47538 net.cpp:399] conv5-Dropout2 -> conv5-Dropout2
I0630 14:51:31.064141 47538 net.cpp:141] Setting up conv5-Dropout2
I0630 14:51:31.064150 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.064155 47538 net.cpp:156] Memory required for data: 1436909568
I0630 14:51:31.064163 47538 layer_factory.hpp:77] Creating layer conv5-Concat2
I0630 14:51:31.064174 47538 net.cpp:91] Creating Layer conv5-Concat2
I0630 14:51:31.064179 47538 net.cpp:425] conv5-Concat2 <- conv5-Concat1_conv5-Concat1_0_split_1
I0630 14:51:31.064188 47538 net.cpp:425] conv5-Concat2 <- conv5-Dropout2
I0630 14:51:31.064194 47538 net.cpp:399] conv5-Concat2 -> conv5-Concat2
I0630 14:51:31.064230 47538 net.cpp:141] Setting up conv5-Concat2
I0630 14:51:31.064239 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.064244 47538 net.cpp:156] Memory required for data: 1452638208
I0630 14:51:31.064249 47538 layer_factory.hpp:77] Creating layer conv5-Concat2_conv5-Concat2_0_split
I0630 14:51:31.064258 47538 net.cpp:91] Creating Layer conv5-Concat2_conv5-Concat2_0_split
I0630 14:51:31.064263 47538 net.cpp:425] conv5-Concat2_conv5-Concat2_0_split <- conv5-Concat2
I0630 14:51:31.064272 47538 net.cpp:399] conv5-Concat2_conv5-Concat2_0_split -> conv5-Concat2_conv5-Concat2_0_split_0
I0630 14:51:31.064281 47538 net.cpp:399] conv5-Concat2_conv5-Concat2_0_split -> conv5-Concat2_conv5-Concat2_0_split_1
I0630 14:51:31.064334 47538 net.cpp:141] Setting up conv5-Concat2_conv5-Concat2_0_split
I0630 14:51:31.064342 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.064348 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.064353 47538 net.cpp:156] Memory required for data: 1484095488
I0630 14:51:31.064357 47538 layer_factory.hpp:77] Creating layer conv5-BatchNorm3
I0630 14:51:31.064370 47538 net.cpp:91] Creating Layer conv5-BatchNorm3
I0630 14:51:31.064389 47538 net.cpp:425] conv5-BatchNorm3 <- conv5-Concat2_conv5-Concat2_0_split_0
I0630 14:51:31.064399 47538 net.cpp:399] conv5-BatchNorm3 -> conv5-BatchNorm3
I0630 14:51:31.064760 47538 net.cpp:141] Setting up conv5-BatchNorm3
I0630 14:51:31.064770 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.064776 47538 net.cpp:156] Memory required for data: 1499824128
I0630 14:51:31.064786 47538 layer_factory.hpp:77] Creating layer conv5-Scale3
I0630 14:51:31.064796 47538 net.cpp:91] Creating Layer conv5-Scale3
I0630 14:51:31.064802 47538 net.cpp:425] conv5-Scale3 <- conv5-BatchNorm3
I0630 14:51:31.064810 47538 net.cpp:386] conv5-Scale3 -> conv5-BatchNorm3 (in-place)
I0630 14:51:31.064882 47538 layer_factory.hpp:77] Creating layer conv5-Scale3
I0630 14:51:31.065083 47538 net.cpp:141] Setting up conv5-Scale3
I0630 14:51:31.065093 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.065097 47538 net.cpp:156] Memory required for data: 1515552768
I0630 14:51:31.065105 47538 layer_factory.hpp:77] Creating layer conv5-ReLU3
I0630 14:51:31.065115 47538 net.cpp:91] Creating Layer conv5-ReLU3
I0630 14:51:31.065120 47538 net.cpp:425] conv5-ReLU3 <- conv5-BatchNorm3
I0630 14:51:31.065129 47538 net.cpp:386] conv5-ReLU3 -> conv5-BatchNorm3 (in-place)
I0630 14:51:31.065389 47538 net.cpp:141] Setting up conv5-ReLU3
I0630 14:51:31.065402 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.065405 47538 net.cpp:156] Memory required for data: 1531281408
I0630 14:51:31.065412 47538 layer_factory.hpp:77] Creating layer conv5-Convolution4
I0630 14:51:31.065428 47538 net.cpp:91] Creating Layer conv5-Convolution4
I0630 14:51:31.065434 47538 net.cpp:425] conv5-Convolution4 <- conv5-BatchNorm3
I0630 14:51:31.065443 47538 net.cpp:399] conv5-Convolution4 -> conv5-Convolution4
I0630 14:51:31.072075 47538 net.cpp:141] Setting up conv5-Convolution4
I0630 14:51:31.072093 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.072099 47538 net.cpp:156] Memory required for data: 1532854272
I0630 14:51:31.072108 47538 layer_factory.hpp:77] Creating layer conv5-Dropout3
I0630 14:51:31.072122 47538 net.cpp:91] Creating Layer conv5-Dropout3
I0630 14:51:31.072129 47538 net.cpp:425] conv5-Dropout3 <- conv5-Convolution4
I0630 14:51:31.072136 47538 net.cpp:399] conv5-Dropout3 -> conv5-Dropout3
I0630 14:51:31.072209 47538 net.cpp:141] Setting up conv5-Dropout3
I0630 14:51:31.072218 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.072224 47538 net.cpp:156] Memory required for data: 1534427136
I0630 14:51:31.072232 47538 layer_factory.hpp:77] Creating layer conv5-Concat3
I0630 14:51:31.072242 47538 net.cpp:91] Creating Layer conv5-Concat3
I0630 14:51:31.072247 47538 net.cpp:425] conv5-Concat3 <- conv5-Concat2_conv5-Concat2_0_split_1
I0630 14:51:31.072255 47538 net.cpp:425] conv5-Concat3 <- conv5-Dropout3
I0630 14:51:31.072263 47538 net.cpp:399] conv5-Concat3 -> conv5
I0630 14:51:31.072304 47538 net.cpp:141] Setting up conv5-Concat3
I0630 14:51:31.072311 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:31.072316 47538 net.cpp:156] Memory required for data: 1551728640
I0630 14:51:31.072321 47538 layer_factory.hpp:77] Creating layer conv5_bn
I0630 14:51:31.072331 47538 net.cpp:91] Creating Layer conv5_bn
I0630 14:51:31.072336 47538 net.cpp:425] conv5_bn <- conv5
I0630 14:51:31.072345 47538 net.cpp:399] conv5_bn -> conv5_bn
I0630 14:51:31.072696 47538 net.cpp:141] Setting up conv5_bn
I0630 14:51:31.072705 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:31.072710 47538 net.cpp:156] Memory required for data: 1569030144
I0630 14:51:31.072721 47538 layer_factory.hpp:77] Creating layer scale_conv5
I0630 14:51:31.072729 47538 net.cpp:91] Creating Layer scale_conv5
I0630 14:51:31.072734 47538 net.cpp:425] scale_conv5 <- conv5_bn
I0630 14:51:31.072747 47538 net.cpp:386] scale_conv5 -> conv5_bn (in-place)
I0630 14:51:31.072825 47538 layer_factory.hpp:77] Creating layer scale_conv5
I0630 14:51:31.073050 47538 net.cpp:141] Setting up scale_conv5
I0630 14:51:31.073060 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:31.073065 47538 net.cpp:156] Memory required for data: 1586331648
I0630 14:51:31.073074 47538 layer_factory.hpp:77] Creating layer relu5a
I0630 14:51:31.073093 47538 net.cpp:91] Creating Layer relu5a
I0630 14:51:31.073098 47538 net.cpp:425] relu5a <- conv5_bn
I0630 14:51:31.073105 47538 net.cpp:386] relu5a -> conv5_bn (in-place)
I0630 14:51:31.073367 47538 net.cpp:141] Setting up relu5a
I0630 14:51:31.073379 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:31.073385 47538 net.cpp:156] Memory required for data: 1603633152
I0630 14:51:31.073390 47538 layer_factory.hpp:77] Creating layer conv5_2-Convolution1
I0630 14:51:31.073406 47538 net.cpp:91] Creating Layer conv5_2-Convolution1
I0630 14:51:31.073412 47538 net.cpp:425] conv5_2-Convolution1 <- conv5_bn
I0630 14:51:31.073423 47538 net.cpp:399] conv5_2-Convolution1 -> conv5_2-Convolution1
I0630 14:51:31.098309 47538 net.cpp:141] Setting up conv5_2-Convolution1
I0630 14:51:31.098330 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.098335 47538 net.cpp:156] Memory required for data: 1616216064
I0630 14:51:31.098345 47538 layer_factory.hpp:77] Creating layer conv5_2-Convolution1_conv5_2-Convolution1_0_split
I0630 14:51:31.098354 47538 net.cpp:91] Creating Layer conv5_2-Convolution1_conv5_2-Convolution1_0_split
I0630 14:51:31.098361 47538 net.cpp:425] conv5_2-Convolution1_conv5_2-Convolution1_0_split <- conv5_2-Convolution1
I0630 14:51:31.098372 47538 net.cpp:399] conv5_2-Convolution1_conv5_2-Convolution1_0_split -> conv5_2-Convolution1_conv5_2-Convolution1_0_split_0
I0630 14:51:31.098384 47538 net.cpp:399] conv5_2-Convolution1_conv5_2-Convolution1_0_split -> conv5_2-Convolution1_conv5_2-Convolution1_0_split_1
I0630 14:51:31.098456 47538 net.cpp:141] Setting up conv5_2-Convolution1_conv5_2-Convolution1_0_split
I0630 14:51:31.098466 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.098472 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.098476 47538 net.cpp:156] Memory required for data: 1641381888
I0630 14:51:31.098481 47538 layer_factory.hpp:77] Creating layer conv5_2-BatchNorm1
I0630 14:51:31.098493 47538 net.cpp:91] Creating Layer conv5_2-BatchNorm1
I0630 14:51:31.098500 47538 net.cpp:425] conv5_2-BatchNorm1 <- conv5_2-Convolution1_conv5_2-Convolution1_0_split_0
I0630 14:51:31.098507 47538 net.cpp:399] conv5_2-BatchNorm1 -> conv5_2-BatchNorm1
I0630 14:51:31.098837 47538 net.cpp:141] Setting up conv5_2-BatchNorm1
I0630 14:51:31.098847 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.098851 47538 net.cpp:156] Memory required for data: 1653964800
I0630 14:51:31.098865 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale1
I0630 14:51:31.098873 47538 net.cpp:91] Creating Layer conv5_2-Scale1
I0630 14:51:31.098879 47538 net.cpp:425] conv5_2-Scale1 <- conv5_2-BatchNorm1
I0630 14:51:31.098889 47538 net.cpp:386] conv5_2-Scale1 -> conv5_2-BatchNorm1 (in-place)
I0630 14:51:31.098955 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale1
I0630 14:51:31.099157 47538 net.cpp:141] Setting up conv5_2-Scale1
I0630 14:51:31.099169 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.099172 47538 net.cpp:156] Memory required for data: 1666547712
I0630 14:51:31.099180 47538 layer_factory.hpp:77] Creating layer conv5_2-ReLU1
I0630 14:51:31.099191 47538 net.cpp:91] Creating Layer conv5_2-ReLU1
I0630 14:51:31.099197 47538 net.cpp:425] conv5_2-ReLU1 <- conv5_2-BatchNorm1
I0630 14:51:31.099205 47538 net.cpp:386] conv5_2-ReLU1 -> conv5_2-BatchNorm1 (in-place)
I0630 14:51:31.100483 47538 net.cpp:141] Setting up conv5_2-ReLU1
I0630 14:51:31.100499 47538 net.cpp:148] Top shape: 3 256 16 16 16 (3145728)
I0630 14:51:31.100505 47538 net.cpp:156] Memory required for data: 1679130624
I0630 14:51:31.100510 47538 layer_factory.hpp:77] Creating layer conv5_2-Convolution2
I0630 14:51:31.100531 47538 net.cpp:91] Creating Layer conv5_2-Convolution2
I0630 14:51:31.100553 47538 net.cpp:425] conv5_2-Convolution2 <- conv5_2-BatchNorm1
I0630 14:51:31.100567 47538 net.cpp:399] conv5_2-Convolution2 -> conv5_2-Convolution2
I0630 14:51:31.103281 47538 net.cpp:141] Setting up conv5_2-Convolution2
I0630 14:51:31.103294 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.103299 47538 net.cpp:156] Memory required for data: 1680703488
I0630 14:51:31.103309 47538 layer_factory.hpp:77] Creating layer conv5_2-Dropout1
I0630 14:51:31.103322 47538 net.cpp:91] Creating Layer conv5_2-Dropout1
I0630 14:51:31.103327 47538 net.cpp:425] conv5_2-Dropout1 <- conv5_2-Convolution2
I0630 14:51:31.103334 47538 net.cpp:399] conv5_2-Dropout1 -> conv5_2-Dropout1
I0630 14:51:31.103407 47538 net.cpp:141] Setting up conv5_2-Dropout1
I0630 14:51:31.103415 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.103420 47538 net.cpp:156] Memory required for data: 1682276352
I0630 14:51:31.103427 47538 layer_factory.hpp:77] Creating layer conv5_2-Concat1
I0630 14:51:31.103436 47538 net.cpp:91] Creating Layer conv5_2-Concat1
I0630 14:51:31.103441 47538 net.cpp:425] conv5_2-Concat1 <- conv5_2-Convolution1_conv5_2-Convolution1_0_split_1
I0630 14:51:31.103448 47538 net.cpp:425] conv5_2-Concat1 <- conv5_2-Dropout1
I0630 14:51:31.103458 47538 net.cpp:399] conv5_2-Concat1 -> conv5_2-Concat1
I0630 14:51:31.103500 47538 net.cpp:141] Setting up conv5_2-Concat1
I0630 14:51:31.103508 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.103513 47538 net.cpp:156] Memory required for data: 1696432128
I0630 14:51:31.103518 47538 layer_factory.hpp:77] Creating layer conv5_2-Concat1_conv5_2-Concat1_0_split
I0630 14:51:31.103525 47538 net.cpp:91] Creating Layer conv5_2-Concat1_conv5_2-Concat1_0_split
I0630 14:51:31.103530 47538 net.cpp:425] conv5_2-Concat1_conv5_2-Concat1_0_split <- conv5_2-Concat1
I0630 14:51:31.103541 47538 net.cpp:399] conv5_2-Concat1_conv5_2-Concat1_0_split -> conv5_2-Concat1_conv5_2-Concat1_0_split_0
I0630 14:51:31.103552 47538 net.cpp:399] conv5_2-Concat1_conv5_2-Concat1_0_split -> conv5_2-Concat1_conv5_2-Concat1_0_split_1
I0630 14:51:31.103610 47538 net.cpp:141] Setting up conv5_2-Concat1_conv5_2-Concat1_0_split
I0630 14:51:31.103618 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.103624 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.103628 47538 net.cpp:156] Memory required for data: 1724743680
I0630 14:51:31.103634 47538 layer_factory.hpp:77] Creating layer conv5_2-BatchNorm2
I0630 14:51:31.103646 47538 net.cpp:91] Creating Layer conv5_2-BatchNorm2
I0630 14:51:31.103652 47538 net.cpp:425] conv5_2-BatchNorm2 <- conv5_2-Concat1_conv5_2-Concat1_0_split_0
I0630 14:51:31.103662 47538 net.cpp:399] conv5_2-BatchNorm2 -> conv5_2-BatchNorm2
I0630 14:51:31.104005 47538 net.cpp:141] Setting up conv5_2-BatchNorm2
I0630 14:51:31.104014 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.104019 47538 net.cpp:156] Memory required for data: 1738899456
I0630 14:51:31.104029 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale2
I0630 14:51:31.104038 47538 net.cpp:91] Creating Layer conv5_2-Scale2
I0630 14:51:31.104043 47538 net.cpp:425] conv5_2-Scale2 <- conv5_2-BatchNorm2
I0630 14:51:31.104053 47538 net.cpp:386] conv5_2-Scale2 -> conv5_2-BatchNorm2 (in-place)
I0630 14:51:31.104125 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale2
I0630 14:51:31.104331 47538 net.cpp:141] Setting up conv5_2-Scale2
I0630 14:51:31.104341 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.104344 47538 net.cpp:156] Memory required for data: 1753055232
I0630 14:51:31.104352 47538 layer_factory.hpp:77] Creating layer conv5_2-ReLU2
I0630 14:51:31.104360 47538 net.cpp:91] Creating Layer conv5_2-ReLU2
I0630 14:51:31.104367 47538 net.cpp:425] conv5_2-ReLU2 <- conv5_2-BatchNorm2
I0630 14:51:31.104375 47538 net.cpp:386] conv5_2-ReLU2 -> conv5_2-BatchNorm2 (in-place)
I0630 14:51:31.105633 47538 net.cpp:141] Setting up conv5_2-ReLU2
I0630 14:51:31.105651 47538 net.cpp:148] Top shape: 3 288 16 16 16 (3538944)
I0630 14:51:31.105670 47538 net.cpp:156] Memory required for data: 1767211008
I0630 14:51:31.105675 47538 layer_factory.hpp:77] Creating layer conv5_2-Convolution3
I0630 14:51:31.105691 47538 net.cpp:91] Creating Layer conv5_2-Convolution3
I0630 14:51:31.105698 47538 net.cpp:425] conv5_2-Convolution3 <- conv5_2-BatchNorm2
I0630 14:51:31.105712 47538 net.cpp:399] conv5_2-Convolution3 -> conv5_2-Convolution3
I0630 14:51:31.111984 47538 net.cpp:141] Setting up conv5_2-Convolution3
I0630 14:51:31.112004 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.112008 47538 net.cpp:156] Memory required for data: 1768783872
I0630 14:51:31.112022 47538 layer_factory.hpp:77] Creating layer conv5_2-Dropout2
I0630 14:51:31.112032 47538 net.cpp:91] Creating Layer conv5_2-Dropout2
I0630 14:51:31.112038 47538 net.cpp:425] conv5_2-Dropout2 <- conv5_2-Convolution3
I0630 14:51:31.112051 47538 net.cpp:399] conv5_2-Dropout2 -> conv5_2-Dropout2
I0630 14:51:31.112125 47538 net.cpp:141] Setting up conv5_2-Dropout2
I0630 14:51:31.112133 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.112138 47538 net.cpp:156] Memory required for data: 1770356736
I0630 14:51:31.112143 47538 layer_factory.hpp:77] Creating layer conv5_2-Concat2
I0630 14:51:31.112151 47538 net.cpp:91] Creating Layer conv5_2-Concat2
I0630 14:51:31.112157 47538 net.cpp:425] conv5_2-Concat2 <- conv5_2-Concat1_conv5_2-Concat1_0_split_1
I0630 14:51:31.112164 47538 net.cpp:425] conv5_2-Concat2 <- conv5_2-Dropout2
I0630 14:51:31.112171 47538 net.cpp:399] conv5_2-Concat2 -> conv5_2-Concat2
I0630 14:51:31.112210 47538 net.cpp:141] Setting up conv5_2-Concat2
I0630 14:51:31.112218 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.112223 47538 net.cpp:156] Memory required for data: 1786085376
I0630 14:51:31.112227 47538 layer_factory.hpp:77] Creating layer conv5_2-Concat2_conv5_2-Concat2_0_split
I0630 14:51:31.112236 47538 net.cpp:91] Creating Layer conv5_2-Concat2_conv5_2-Concat2_0_split
I0630 14:51:31.112241 47538 net.cpp:425] conv5_2-Concat2_conv5_2-Concat2_0_split <- conv5_2-Concat2
I0630 14:51:31.112248 47538 net.cpp:399] conv5_2-Concat2_conv5_2-Concat2_0_split -> conv5_2-Concat2_conv5_2-Concat2_0_split_0
I0630 14:51:31.112258 47538 net.cpp:399] conv5_2-Concat2_conv5_2-Concat2_0_split -> conv5_2-Concat2_conv5_2-Concat2_0_split_1
I0630 14:51:31.112314 47538 net.cpp:141] Setting up conv5_2-Concat2_conv5_2-Concat2_0_split
I0630 14:51:31.112321 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.112327 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.112331 47538 net.cpp:156] Memory required for data: 1817542656
I0630 14:51:31.112337 47538 layer_factory.hpp:77] Creating layer conv5_2-BatchNorm3
I0630 14:51:31.112351 47538 net.cpp:91] Creating Layer conv5_2-BatchNorm3
I0630 14:51:31.112356 47538 net.cpp:425] conv5_2-BatchNorm3 <- conv5_2-Concat2_conv5_2-Concat2_0_split_0
I0630 14:51:31.112366 47538 net.cpp:399] conv5_2-BatchNorm3 -> conv5_2-BatchNorm3
I0630 14:51:31.112730 47538 net.cpp:141] Setting up conv5_2-BatchNorm3
I0630 14:51:31.112738 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.112742 47538 net.cpp:156] Memory required for data: 1833271296
I0630 14:51:31.112752 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale3
I0630 14:51:31.112761 47538 net.cpp:91] Creating Layer conv5_2-Scale3
I0630 14:51:31.112766 47538 net.cpp:425] conv5_2-Scale3 <- conv5_2-BatchNorm3
I0630 14:51:31.112776 47538 net.cpp:386] conv5_2-Scale3 -> conv5_2-BatchNorm3 (in-place)
I0630 14:51:31.112846 47538 layer_factory.hpp:77] Creating layer conv5_2-Scale3
I0630 14:51:31.113049 47538 net.cpp:141] Setting up conv5_2-Scale3
I0630 14:51:31.113059 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.113063 47538 net.cpp:156] Memory required for data: 1848999936
I0630 14:51:31.113071 47538 layer_factory.hpp:77] Creating layer conv5_2-ReLU3
I0630 14:51:31.113080 47538 net.cpp:91] Creating Layer conv5_2-ReLU3
I0630 14:51:31.113090 47538 net.cpp:425] conv5_2-ReLU3 <- conv5_2-BatchNorm3
I0630 14:51:31.113113 47538 net.cpp:386] conv5_2-ReLU3 -> conv5_2-BatchNorm3 (in-place)
I0630 14:51:31.113391 47538 net.cpp:141] Setting up conv5_2-ReLU3
I0630 14:51:31.113404 47538 net.cpp:148] Top shape: 3 320 16 16 16 (3932160)
I0630 14:51:31.113409 47538 net.cpp:156] Memory required for data: 1864728576
I0630 14:51:31.113415 47538 layer_factory.hpp:77] Creating layer conv5_2-Convolution4
I0630 14:51:31.113430 47538 net.cpp:91] Creating Layer conv5_2-Convolution4
I0630 14:51:31.113436 47538 net.cpp:425] conv5_2-Convolution4 <- conv5_2-BatchNorm3
I0630 14:51:31.113448 47538 net.cpp:399] conv5_2-Convolution4 -> conv5_2-Convolution4
I0630 14:51:31.119990 47538 net.cpp:141] Setting up conv5_2-Convolution4
I0630 14:51:31.120008 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.120015 47538 net.cpp:156] Memory required for data: 1866301440
I0630 14:51:31.120028 47538 layer_factory.hpp:77] Creating layer conv5_2-Dropout3
I0630 14:51:31.120038 47538 net.cpp:91] Creating Layer conv5_2-Dropout3
I0630 14:51:31.120044 47538 net.cpp:425] conv5_2-Dropout3 <- conv5_2-Convolution4
I0630 14:51:31.120054 47538 net.cpp:399] conv5_2-Dropout3 -> conv5_2-Dropout3
I0630 14:51:31.120121 47538 net.cpp:141] Setting up conv5_2-Dropout3
I0630 14:51:31.120129 47538 net.cpp:148] Top shape: 3 32 16 16 16 (393216)
I0630 14:51:31.120134 47538 net.cpp:156] Memory required for data: 1867874304
I0630 14:51:31.120139 47538 layer_factory.hpp:77] Creating layer conv5_2-Concat3
I0630 14:51:31.120147 47538 net.cpp:91] Creating Layer conv5_2-Concat3
I0630 14:51:31.120153 47538 net.cpp:425] conv5_2-Concat3 <- conv5_2-Concat2_conv5_2-Concat2_0_split_1
I0630 14:51:31.120159 47538 net.cpp:425] conv5_2-Concat3 <- conv5_2-Dropout3
I0630 14:51:31.120177 47538 net.cpp:399] conv5_2-Concat3 -> conv5_2
I0630 14:51:31.120218 47538 net.cpp:141] Setting up conv5_2-Concat3
I0630 14:51:31.120225 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:31.120229 47538 net.cpp:156] Memory required for data: 1885175808
I0630 14:51:31.120235 47538 layer_factory.hpp:77] Creating layer conv5_2_bn
I0630 14:51:31.120244 47538 net.cpp:91] Creating Layer conv5_2_bn
I0630 14:51:31.120249 47538 net.cpp:425] conv5_2_bn <- conv5_2
I0630 14:51:31.120256 47538 net.cpp:399] conv5_2_bn -> conv5_2_bn
I0630 14:51:31.120594 47538 net.cpp:141] Setting up conv5_2_bn
I0630 14:51:31.120604 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:31.120609 47538 net.cpp:156] Memory required for data: 1902477312
I0630 14:51:31.120618 47538 layer_factory.hpp:77] Creating layer scale_conv5_2
I0630 14:51:31.120632 47538 net.cpp:91] Creating Layer scale_conv5_2
I0630 14:51:31.120637 47538 net.cpp:425] scale_conv5_2 <- conv5_2_bn
I0630 14:51:31.120647 47538 net.cpp:386] scale_conv5_2 -> conv5_2_bn (in-place)
I0630 14:51:31.120718 47538 layer_factory.hpp:77] Creating layer scale_conv5_2
I0630 14:51:31.120923 47538 net.cpp:141] Setting up scale_conv5_2
I0630 14:51:31.120931 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:31.120936 47538 net.cpp:156] Memory required for data: 1919778816
I0630 14:51:31.120944 47538 layer_factory.hpp:77] Creating layer relu5a_2
I0630 14:51:31.120954 47538 net.cpp:91] Creating Layer relu5a_2
I0630 14:51:31.120960 47538 net.cpp:425] relu5a_2 <- conv5_2_bn
I0630 14:51:31.120966 47538 net.cpp:386] relu5a_2 -> conv5_2_bn (in-place)
I0630 14:51:31.121220 47538 net.cpp:141] Setting up relu5a_2
I0630 14:51:31.121235 47538 net.cpp:148] Top shape: 3 352 16 16 16 (4325376)
I0630 14:51:31.121240 47538 net.cpp:156] Memory required for data: 1937080320
I0630 14:51:31.121245 47538 layer_factory.hpp:77] Creating layer deconv6
I0630 14:51:31.121255 47538 net.cpp:91] Creating Layer deconv6
I0630 14:51:31.121261 47538 net.cpp:425] deconv6 <- conv5_2_bn
I0630 14:51:31.121273 47538 net.cpp:399] deconv6 -> deconv6
I0630 14:51:31.135413 47538 net.cpp:141] Setting up deconv6
I0630 14:51:31.135437 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:31.135443 47538 net.cpp:156] Memory required for data: 1962246144
I0630 14:51:31.135457 47538 layer_factory.hpp:77] Creating layer concat32
I0630 14:51:31.135481 47538 net.cpp:91] Creating Layer concat32
I0630 14:51:31.135488 47538 net.cpp:425] concat32 <- conv1c_conv1c_0_split_1
I0630 14:51:31.135496 47538 net.cpp:425] concat32 <- deconv6
I0630 14:51:31.135504 47538 net.cpp:399] concat32 -> concat32
I0630 14:51:31.135556 47538 net.cpp:141] Setting up concat32
I0630 14:51:31.135565 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:31.135571 47538 net.cpp:156] Memory required for data: 2012577792
I0630 14:51:31.135578 47538 layer_factory.hpp:77] Creating layer conv6-Convolution1
I0630 14:51:31.135594 47538 net.cpp:91] Creating Layer conv6-Convolution1
I0630 14:51:31.135599 47538 net.cpp:425] conv6-Convolution1 <- concat32
I0630 14:51:31.135612 47538 net.cpp:399] conv6-Convolution1 -> conv6-Convolution1
I0630 14:51:31.149591 47538 net.cpp:141] Setting up conv6-Convolution1
I0630 14:51:31.149610 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:31.149616 47538 net.cpp:156] Memory required for data: 2062909440
I0630 14:51:31.149626 47538 layer_factory.hpp:77] Creating layer conv6-Convolution1_conv6-Convolution1_0_split
I0630 14:51:31.149638 47538 net.cpp:91] Creating Layer conv6-Convolution1_conv6-Convolution1_0_split
I0630 14:51:31.149646 47538 net.cpp:425] conv6-Convolution1_conv6-Convolution1_0_split <- conv6-Convolution1
I0630 14:51:31.149653 47538 net.cpp:399] conv6-Convolution1_conv6-Convolution1_0_split -> conv6-Convolution1_conv6-Convolution1_0_split_0
I0630 14:51:31.149665 47538 net.cpp:399] conv6-Convolution1_conv6-Convolution1_0_split -> conv6-Convolution1_conv6-Convolution1_0_split_1
I0630 14:51:31.149746 47538 net.cpp:141] Setting up conv6-Convolution1_conv6-Convolution1_0_split
I0630 14:51:31.149755 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:31.149761 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:31.149766 47538 net.cpp:156] Memory required for data: 2163572736
I0630 14:51:31.149771 47538 layer_factory.hpp:77] Creating layer conv6-BatchNorm1
I0630 14:51:31.149782 47538 net.cpp:91] Creating Layer conv6-BatchNorm1
I0630 14:51:31.149788 47538 net.cpp:425] conv6-BatchNorm1 <- conv6-Convolution1_conv6-Convolution1_0_split_0
I0630 14:51:31.149799 47538 net.cpp:399] conv6-BatchNorm1 -> conv6-BatchNorm1
I0630 14:51:31.150182 47538 net.cpp:141] Setting up conv6-BatchNorm1
I0630 14:51:31.150190 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:31.150195 47538 net.cpp:156] Memory required for data: 2213904384
I0630 14:51:31.150207 47538 layer_factory.hpp:77] Creating layer conv6-Scale1
I0630 14:51:31.150214 47538 net.cpp:91] Creating Layer conv6-Scale1
I0630 14:51:31.150220 47538 net.cpp:425] conv6-Scale1 <- conv6-BatchNorm1
I0630 14:51:31.150228 47538 net.cpp:386] conv6-Scale1 -> conv6-BatchNorm1 (in-place)
I0630 14:51:31.150297 47538 layer_factory.hpp:77] Creating layer conv6-Scale1
I0630 14:51:31.150554 47538 net.cpp:141] Setting up conv6-Scale1
I0630 14:51:31.150563 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:31.150568 47538 net.cpp:156] Memory required for data: 2264236032
I0630 14:51:31.150580 47538 layer_factory.hpp:77] Creating layer conv6-ReLU1
I0630 14:51:31.150594 47538 net.cpp:91] Creating Layer conv6-ReLU1
I0630 14:51:31.150600 47538 net.cpp:425] conv6-ReLU1 <- conv6-BatchNorm1
I0630 14:51:31.150606 47538 net.cpp:386] conv6-ReLU1 -> conv6-BatchNorm1 (in-place)
I0630 14:51:31.150878 47538 net.cpp:141] Setting up conv6-ReLU1
I0630 14:51:31.150893 47538 net.cpp:148] Top shape: 3 128 32 32 32 (12582912)
I0630 14:51:31.150897 47538 net.cpp:156] Memory required for data: 2314567680
I0630 14:51:31.150902 47538 layer_factory.hpp:77] Creating layer conv6-Convolution2
I0630 14:51:31.150918 47538 net.cpp:91] Creating Layer conv6-Convolution2
I0630 14:51:31.150924 47538 net.cpp:425] conv6-Convolution2 <- conv6-BatchNorm1
I0630 14:51:31.150933 47538 net.cpp:399] conv6-Convolution2 -> conv6-Convolution2
I0630 14:51:31.156111 47538 net.cpp:141] Setting up conv6-Convolution2
I0630 14:51:31.156129 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.156149 47538 net.cpp:156] Memory required for data: 2320859136
I0630 14:51:31.156160 47538 layer_factory.hpp:77] Creating layer conv6-Dropout1
I0630 14:51:31.156173 47538 net.cpp:91] Creating Layer conv6-Dropout1
I0630 14:51:31.156180 47538 net.cpp:425] conv6-Dropout1 <- conv6-Convolution2
I0630 14:51:31.156191 47538 net.cpp:399] conv6-Dropout1 -> conv6-Dropout1
I0630 14:51:31.156276 47538 net.cpp:141] Setting up conv6-Dropout1
I0630 14:51:31.156286 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.156291 47538 net.cpp:156] Memory required for data: 2327150592
I0630 14:51:31.156297 47538 layer_factory.hpp:77] Creating layer conv6-Concat1
I0630 14:51:31.156308 47538 net.cpp:91] Creating Layer conv6-Concat1
I0630 14:51:31.156313 47538 net.cpp:425] conv6-Concat1 <- conv6-Convolution1_conv6-Convolution1_0_split_1
I0630 14:51:31.156320 47538 net.cpp:425] conv6-Concat1 <- conv6-Dropout1
I0630 14:51:31.156328 47538 net.cpp:399] conv6-Concat1 -> conv6-Concat1
I0630 14:51:31.156371 47538 net.cpp:141] Setting up conv6-Concat1
I0630 14:51:31.156379 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:31.156384 47538 net.cpp:156] Memory required for data: 2383773696
I0630 14:51:31.156389 47538 layer_factory.hpp:77] Creating layer conv6-Concat1_conv6-Concat1_0_split
I0630 14:51:31.156396 47538 net.cpp:91] Creating Layer conv6-Concat1_conv6-Concat1_0_split
I0630 14:51:31.156401 47538 net.cpp:425] conv6-Concat1_conv6-Concat1_0_split <- conv6-Concat1
I0630 14:51:31.156412 47538 net.cpp:399] conv6-Concat1_conv6-Concat1_0_split -> conv6-Concat1_conv6-Concat1_0_split_0
I0630 14:51:31.156422 47538 net.cpp:399] conv6-Concat1_conv6-Concat1_0_split -> conv6-Concat1_conv6-Concat1_0_split_1
I0630 14:51:31.156487 47538 net.cpp:141] Setting up conv6-Concat1_conv6-Concat1_0_split
I0630 14:51:31.156495 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:31.156502 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:31.156507 47538 net.cpp:156] Memory required for data: 2497019904
I0630 14:51:31.156512 47538 layer_factory.hpp:77] Creating layer conv6-BatchNorm2
I0630 14:51:31.156522 47538 net.cpp:91] Creating Layer conv6-BatchNorm2
I0630 14:51:31.156528 47538 net.cpp:425] conv6-BatchNorm2 <- conv6-Concat1_conv6-Concat1_0_split_0
I0630 14:51:31.156536 47538 net.cpp:399] conv6-BatchNorm2 -> conv6-BatchNorm2
I0630 14:51:31.158936 47538 net.cpp:141] Setting up conv6-BatchNorm2
I0630 14:51:31.158955 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:31.158962 47538 net.cpp:156] Memory required for data: 2553643008
I0630 14:51:31.158987 47538 layer_factory.hpp:77] Creating layer conv6-Scale2
I0630 14:51:31.158998 47538 net.cpp:91] Creating Layer conv6-Scale2
I0630 14:51:31.159003 47538 net.cpp:425] conv6-Scale2 <- conv6-BatchNorm2
I0630 14:51:31.159015 47538 net.cpp:386] conv6-Scale2 -> conv6-BatchNorm2 (in-place)
I0630 14:51:31.159094 47538 layer_factory.hpp:77] Creating layer conv6-Scale2
I0630 14:51:31.159335 47538 net.cpp:141] Setting up conv6-Scale2
I0630 14:51:31.159345 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:31.159350 47538 net.cpp:156] Memory required for data: 2610266112
I0630 14:51:31.159358 47538 layer_factory.hpp:77] Creating layer conv6-ReLU2
I0630 14:51:31.159369 47538 net.cpp:91] Creating Layer conv6-ReLU2
I0630 14:51:31.159374 47538 net.cpp:425] conv6-ReLU2 <- conv6-BatchNorm2
I0630 14:51:31.159384 47538 net.cpp:386] conv6-ReLU2 -> conv6-BatchNorm2 (in-place)
I0630 14:51:31.159658 47538 net.cpp:141] Setting up conv6-ReLU2
I0630 14:51:31.159673 47538 net.cpp:148] Top shape: 3 144 32 32 32 (14155776)
I0630 14:51:31.159678 47538 net.cpp:156] Memory required for data: 2666889216
I0630 14:51:31.159684 47538 layer_factory.hpp:77] Creating layer conv6-Convolution3
I0630 14:51:31.159699 47538 net.cpp:91] Creating Layer conv6-Convolution3
I0630 14:51:31.159705 47538 net.cpp:425] conv6-Convolution3 <- conv6-BatchNorm2
I0630 14:51:31.159724 47538 net.cpp:399] conv6-Convolution3 -> conv6-Convolution3
I0630 14:51:31.166533 47538 net.cpp:141] Setting up conv6-Convolution3
I0630 14:51:31.166581 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.166587 47538 net.cpp:156] Memory required for data: 2673180672
I0630 14:51:31.166597 47538 layer_factory.hpp:77] Creating layer conv6-Dropout2
I0630 14:51:31.166607 47538 net.cpp:91] Creating Layer conv6-Dropout2
I0630 14:51:31.166613 47538 net.cpp:425] conv6-Dropout2 <- conv6-Convolution3
I0630 14:51:31.166621 47538 net.cpp:399] conv6-Dropout2 -> conv6-Dropout2
I0630 14:51:31.166709 47538 net.cpp:141] Setting up conv6-Dropout2
I0630 14:51:31.166719 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.166723 47538 net.cpp:156] Memory required for data: 2679472128
I0630 14:51:31.166730 47538 layer_factory.hpp:77] Creating layer conv6-Concat2
I0630 14:51:31.166739 47538 net.cpp:91] Creating Layer conv6-Concat2
I0630 14:51:31.166745 47538 net.cpp:425] conv6-Concat2 <- conv6-Concat1_conv6-Concat1_0_split_1
I0630 14:51:31.166751 47538 net.cpp:425] conv6-Concat2 <- conv6-Dropout2
I0630 14:51:31.166761 47538 net.cpp:399] conv6-Concat2 -> conv6-Concat2
I0630 14:51:31.166806 47538 net.cpp:141] Setting up conv6-Concat2
I0630 14:51:31.166816 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:31.166821 47538 net.cpp:156] Memory required for data: 2742386688
I0630 14:51:31.166826 47538 layer_factory.hpp:77] Creating layer conv6-Concat2_conv6-Concat2_0_split
I0630 14:51:31.166832 47538 net.cpp:91] Creating Layer conv6-Concat2_conv6-Concat2_0_split
I0630 14:51:31.166838 47538 net.cpp:425] conv6-Concat2_conv6-Concat2_0_split <- conv6-Concat2
I0630 14:51:31.166848 47538 net.cpp:399] conv6-Concat2_conv6-Concat2_0_split -> conv6-Concat2_conv6-Concat2_0_split_0
I0630 14:51:31.166858 47538 net.cpp:399] conv6-Concat2_conv6-Concat2_0_split -> conv6-Concat2_conv6-Concat2_0_split_1
I0630 14:51:31.166923 47538 net.cpp:141] Setting up conv6-Concat2_conv6-Concat2_0_split
I0630 14:51:31.166931 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:31.166937 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:31.166941 47538 net.cpp:156] Memory required for data: 2868215808
I0630 14:51:31.166945 47538 layer_factory.hpp:77] Creating layer conv6-BatchNorm3
I0630 14:51:31.166957 47538 net.cpp:91] Creating Layer conv6-BatchNorm3
I0630 14:51:31.166963 47538 net.cpp:425] conv6-BatchNorm3 <- conv6-Concat2_conv6-Concat2_0_split_0
I0630 14:51:31.166980 47538 net.cpp:399] conv6-BatchNorm3 -> conv6-BatchNorm3
I0630 14:51:31.167351 47538 net.cpp:141] Setting up conv6-BatchNorm3
I0630 14:51:31.167362 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:31.167367 47538 net.cpp:156] Memory required for data: 2931130368
I0630 14:51:31.167379 47538 layer_factory.hpp:77] Creating layer conv6-Scale3
I0630 14:51:31.167390 47538 net.cpp:91] Creating Layer conv6-Scale3
I0630 14:51:31.167397 47538 net.cpp:425] conv6-Scale3 <- conv6-BatchNorm3
I0630 14:51:31.167403 47538 net.cpp:386] conv6-Scale3 -> conv6-BatchNorm3 (in-place)
I0630 14:51:31.167474 47538 layer_factory.hpp:77] Creating layer conv6-Scale3
I0630 14:51:31.167712 47538 net.cpp:141] Setting up conv6-Scale3
I0630 14:51:31.167722 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:31.167727 47538 net.cpp:156] Memory required for data: 2994044928
I0630 14:51:31.167735 47538 layer_factory.hpp:77] Creating layer conv6-ReLU3
I0630 14:51:31.167742 47538 net.cpp:91] Creating Layer conv6-ReLU3
I0630 14:51:31.167748 47538 net.cpp:425] conv6-ReLU3 <- conv6-BatchNorm3
I0630 14:51:31.167757 47538 net.cpp:386] conv6-ReLU3 -> conv6-BatchNorm3 (in-place)
I0630 14:51:31.169044 47538 net.cpp:141] Setting up conv6-ReLU3
I0630 14:51:31.169059 47538 net.cpp:148] Top shape: 3 160 32 32 32 (15728640)
I0630 14:51:31.169064 47538 net.cpp:156] Memory required for data: 3056959488
I0630 14:51:31.169070 47538 layer_factory.hpp:77] Creating layer conv6-Convolution4
I0630 14:51:31.169085 47538 net.cpp:91] Creating Layer conv6-Convolution4
I0630 14:51:31.169096 47538 net.cpp:425] conv6-Convolution4 <- conv6-BatchNorm3
I0630 14:51:31.169123 47538 net.cpp:399] conv6-Convolution4 -> conv6-Convolution4
I0630 14:51:31.171974 47538 net.cpp:141] Setting up conv6-Convolution4
I0630 14:51:31.171995 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.172003 47538 net.cpp:156] Memory required for data: 3063250944
I0630 14:51:31.172017 47538 layer_factory.hpp:77] Creating layer conv6-Dropout3
I0630 14:51:31.172035 47538 net.cpp:91] Creating Layer conv6-Dropout3
I0630 14:51:31.172051 47538 net.cpp:425] conv6-Dropout3 <- conv6-Convolution4
I0630 14:51:31.172062 47538 net.cpp:399] conv6-Dropout3 -> conv6-Dropout3
I0630 14:51:31.172173 47538 net.cpp:141] Setting up conv6-Dropout3
I0630 14:51:31.172186 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.172194 47538 net.cpp:156] Memory required for data: 3069542400
I0630 14:51:31.172200 47538 layer_factory.hpp:77] Creating layer conv6-Concat3
I0630 14:51:31.172214 47538 net.cpp:91] Creating Layer conv6-Concat3
I0630 14:51:31.172224 47538 net.cpp:425] conv6-Concat3 <- conv6-Concat2_conv6-Concat2_0_split_1
I0630 14:51:31.172235 47538 net.cpp:425] conv6-Concat3 <- conv6-Dropout3
I0630 14:51:31.172248 47538 net.cpp:399] conv6-Concat3 -> conv6
I0630 14:51:31.172307 47538 net.cpp:141] Setting up conv6-Concat3
I0630 14:51:31.172322 47538 net.cpp:148] Top shape: 3 176 32 32 32 (17301504)
I0630 14:51:31.172329 47538 net.cpp:156] Memory required for data: 3138748416
I0630 14:51:31.172336 47538 layer_factory.hpp:77] Creating layer conv6_bn
I0630 14:51:31.172350 47538 net.cpp:91] Creating Layer conv6_bn
I0630 14:51:31.172358 47538 net.cpp:425] conv6_bn <- conv6
I0630 14:51:31.172372 47538 net.cpp:399] conv6_bn -> conv6_bn
I0630 14:51:31.173282 47538 net.cpp:141] Setting up conv6_bn
I0630 14:51:31.173301 47538 net.cpp:148] Top shape: 3 176 32 32 32 (17301504)
I0630 14:51:31.173308 47538 net.cpp:156] Memory required for data: 3207954432
I0630 14:51:31.173326 47538 layer_factory.hpp:77] Creating layer scale_conv6_fine
I0630 14:51:31.173341 47538 net.cpp:91] Creating Layer scale_conv6_fine
I0630 14:51:31.173352 47538 net.cpp:425] scale_conv6_fine <- conv6_bn
I0630 14:51:31.173362 47538 net.cpp:386] scale_conv6_fine -> conv6_bn (in-place)
I0630 14:51:31.173463 47538 layer_factory.hpp:77] Creating layer scale_conv6_fine
I0630 14:51:31.173840 47538 net.cpp:141] Setting up scale_conv6_fine
I0630 14:51:31.173856 47538 net.cpp:148] Top shape: 3 176 32 32 32 (17301504)
I0630 14:51:31.173863 47538 net.cpp:156] Memory required for data: 3277160448
I0630 14:51:31.173878 47538 layer_factory.hpp:77] Creating layer relu6
I0630 14:51:31.173892 47538 net.cpp:91] Creating Layer relu6
I0630 14:51:31.173900 47538 net.cpp:425] relu6 <- conv6_bn
I0630 14:51:31.173910 47538 net.cpp:386] relu6 -> conv6_bn (in-place)
I0630 14:51:31.181679 47538 net.cpp:141] Setting up relu6
I0630 14:51:31.181707 47538 net.cpp:148] Top shape: 3 176 32 32 32 (17301504)
I0630 14:51:31.181715 47538 net.cpp:156] Memory required for data: 3346366464
I0630 14:51:31.181721 47538 layer_factory.hpp:77] Creating layer conv6_2-Convolution1
I0630 14:51:31.181742 47538 net.cpp:91] Creating Layer conv6_2-Convolution1
I0630 14:51:31.181749 47538 net.cpp:425] conv6_2-Convolution1 <- conv6_bn
I0630 14:51:31.181763 47538 net.cpp:399] conv6_2-Convolution1 -> conv6_2-Convolution1
I0630 14:51:31.198658 47538 net.cpp:141] Setting up conv6_2-Convolution1
I0630 14:51:31.198709 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:31.198717 47538 net.cpp:156] Memory required for data: 3371532288
I0630 14:51:31.198740 47538 layer_factory.hpp:77] Creating layer conv6_2-Convolution1_conv6_2-Convolution1_0_split
I0630 14:51:31.198760 47538 net.cpp:91] Creating Layer conv6_2-Convolution1_conv6_2-Convolution1_0_split
I0630 14:51:31.198771 47538 net.cpp:425] conv6_2-Convolution1_conv6_2-Convolution1_0_split <- conv6_2-Convolution1
I0630 14:51:31.198791 47538 net.cpp:399] conv6_2-Convolution1_conv6_2-Convolution1_0_split -> conv6_2-Convolution1_conv6_2-Convolution1_0_split_0
I0630 14:51:31.198823 47538 net.cpp:399] conv6_2-Convolution1_conv6_2-Convolution1_0_split -> conv6_2-Convolution1_conv6_2-Convolution1_0_split_1
I0630 14:51:31.199003 47538 net.cpp:141] Setting up conv6_2-Convolution1_conv6_2-Convolution1_0_split
I0630 14:51:31.199019 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:31.199029 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:31.199038 47538 net.cpp:156] Memory required for data: 3421863936
I0630 14:51:31.199046 47538 layer_factory.hpp:77] Creating layer conv6_2-BatchNorm1
I0630 14:51:31.199069 47538 net.cpp:91] Creating Layer conv6_2-BatchNorm1
I0630 14:51:31.199077 47538 net.cpp:425] conv6_2-BatchNorm1 <- conv6_2-Convolution1_conv6_2-Convolution1_0_split_0
I0630 14:51:31.199092 47538 net.cpp:399] conv6_2-BatchNorm1 -> conv6_2-BatchNorm1
I0630 14:51:31.199733 47538 net.cpp:141] Setting up conv6_2-BatchNorm1
I0630 14:51:31.199746 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:31.199754 47538 net.cpp:156] Memory required for data: 3447029760
I0630 14:51:31.199772 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale1
I0630 14:51:31.199790 47538 net.cpp:91] Creating Layer conv6_2-Scale1
I0630 14:51:31.199800 47538 net.cpp:425] conv6_2-Scale1 <- conv6_2-BatchNorm1
I0630 14:51:31.199810 47538 net.cpp:386] conv6_2-Scale1 -> conv6_2-BatchNorm1 (in-place)
I0630 14:51:31.199936 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale1
I0630 14:51:31.204025 47538 net.cpp:141] Setting up conv6_2-Scale1
I0630 14:51:31.204051 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:31.204064 47538 net.cpp:156] Memory required for data: 3472195584
I0630 14:51:31.204080 47538 layer_factory.hpp:77] Creating layer conv6_2-ReLU1
I0630 14:51:31.204094 47538 net.cpp:91] Creating Layer conv6_2-ReLU1
I0630 14:51:31.204103 47538 net.cpp:425] conv6_2-ReLU1 <- conv6_2-BatchNorm1
I0630 14:51:31.204115 47538 net.cpp:386] conv6_2-ReLU1 -> conv6_2-BatchNorm1 (in-place)
I0630 14:51:31.204553 47538 net.cpp:141] Setting up conv6_2-ReLU1
I0630 14:51:31.204571 47538 net.cpp:148] Top shape: 3 64 32 32 32 (6291456)
I0630 14:51:31.204578 47538 net.cpp:156] Memory required for data: 3497361408
I0630 14:51:31.204586 47538 layer_factory.hpp:77] Creating layer conv6_2-Convolution2
I0630 14:51:31.204614 47538 net.cpp:91] Creating Layer conv6_2-Convolution2
I0630 14:51:31.204623 47538 net.cpp:425] conv6_2-Convolution2 <- conv6_2-BatchNorm1
I0630 14:51:31.204638 47538 net.cpp:399] conv6_2-Convolution2 -> conv6_2-Convolution2
I0630 14:51:31.211944 47538 net.cpp:141] Setting up conv6_2-Convolution2
I0630 14:51:31.211973 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.211982 47538 net.cpp:156] Memory required for data: 3503652864
I0630 14:51:31.211997 47538 layer_factory.hpp:77] Creating layer conv6_2-Dropout1
I0630 14:51:31.212016 47538 net.cpp:91] Creating Layer conv6_2-Dropout1
I0630 14:51:31.212028 47538 net.cpp:425] conv6_2-Dropout1 <- conv6_2-Convolution2
I0630 14:51:31.212040 47538 net.cpp:399] conv6_2-Dropout1 -> conv6_2-Dropout1
I0630 14:51:31.212169 47538 net.cpp:141] Setting up conv6_2-Dropout1
I0630 14:51:31.212182 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.212190 47538 net.cpp:156] Memory required for data: 3509944320
I0630 14:51:31.212198 47538 layer_factory.hpp:77] Creating layer conv6_2-Concat1
I0630 14:51:31.212214 47538 net.cpp:91] Creating Layer conv6_2-Concat1
I0630 14:51:31.212222 47538 net.cpp:425] conv6_2-Concat1 <- conv6_2-Convolution1_conv6_2-Convolution1_0_split_1
I0630 14:51:31.212234 47538 net.cpp:425] conv6_2-Concat1 <- conv6_2-Dropout1
I0630 14:51:31.212245 47538 net.cpp:399] conv6_2-Concat1 -> conv6_2-Concat1
I0630 14:51:31.212311 47538 net.cpp:141] Setting up conv6_2-Concat1
I0630 14:51:31.212322 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:31.212330 47538 net.cpp:156] Memory required for data: 3541401600
I0630 14:51:31.212337 47538 layer_factory.hpp:77] Creating layer conv6_2-Concat1_conv6_2-Concat1_0_split
I0630 14:51:31.212355 47538 net.cpp:91] Creating Layer conv6_2-Concat1_conv6_2-Concat1_0_split
I0630 14:51:31.212384 47538 net.cpp:425] conv6_2-Concat1_conv6_2-Concat1_0_split <- conv6_2-Concat1
I0630 14:51:31.212404 47538 net.cpp:399] conv6_2-Concat1_conv6_2-Concat1_0_split -> conv6_2-Concat1_conv6_2-Concat1_0_split_0
I0630 14:51:31.212420 47538 net.cpp:399] conv6_2-Concat1_conv6_2-Concat1_0_split -> conv6_2-Concat1_conv6_2-Concat1_0_split_1
I0630 14:51:31.212522 47538 net.cpp:141] Setting up conv6_2-Concat1_conv6_2-Concat1_0_split
I0630 14:51:31.212533 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:31.212543 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:31.212551 47538 net.cpp:156] Memory required for data: 3604316160
I0630 14:51:31.212558 47538 layer_factory.hpp:77] Creating layer conv6_2-BatchNorm2
I0630 14:51:31.212574 47538 net.cpp:91] Creating Layer conv6_2-BatchNorm2
I0630 14:51:31.212582 47538 net.cpp:425] conv6_2-BatchNorm2 <- conv6_2-Concat1_conv6_2-Concat1_0_split_0
I0630 14:51:31.212595 47538 net.cpp:399] conv6_2-BatchNorm2 -> conv6_2-BatchNorm2
I0630 14:51:31.213179 47538 net.cpp:141] Setting up conv6_2-BatchNorm2
I0630 14:51:31.213193 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:31.213201 47538 net.cpp:156] Memory required for data: 3635773440
I0630 14:51:31.213222 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale2
I0630 14:51:31.213235 47538 net.cpp:91] Creating Layer conv6_2-Scale2
I0630 14:51:31.213243 47538 net.cpp:425] conv6_2-Scale2 <- conv6_2-BatchNorm2
I0630 14:51:31.213254 47538 net.cpp:386] conv6_2-Scale2 -> conv6_2-BatchNorm2 (in-place)
I0630 14:51:31.213364 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale2
I0630 14:51:31.213726 47538 net.cpp:141] Setting up conv6_2-Scale2
I0630 14:51:31.213742 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:31.213748 47538 net.cpp:156] Memory required for data: 3667230720
I0630 14:51:31.213762 47538 layer_factory.hpp:77] Creating layer conv6_2-ReLU2
I0630 14:51:31.213776 47538 net.cpp:91] Creating Layer conv6_2-ReLU2
I0630 14:51:31.213784 47538 net.cpp:425] conv6_2-ReLU2 <- conv6_2-BatchNorm2
I0630 14:51:31.213794 47538 net.cpp:386] conv6_2-ReLU2 -> conv6_2-BatchNorm2 (in-place)
I0630 14:51:31.214218 47538 net.cpp:141] Setting up conv6_2-ReLU2
I0630 14:51:31.214236 47538 net.cpp:148] Top shape: 3 80 32 32 32 (7864320)
I0630 14:51:31.214242 47538 net.cpp:156] Memory required for data: 3698688000
I0630 14:51:31.214251 47538 layer_factory.hpp:77] Creating layer conv6_2-Convolution3
I0630 14:51:31.214279 47538 net.cpp:91] Creating Layer conv6_2-Convolution3
I0630 14:51:31.214288 47538 net.cpp:425] conv6_2-Convolution3 <- conv6_2-BatchNorm2
I0630 14:51:31.214303 47538 net.cpp:399] conv6_2-Convolution3 -> conv6_2-Convolution3
I0630 14:51:31.226006 47538 net.cpp:141] Setting up conv6_2-Convolution3
I0630 14:51:31.226034 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.226042 47538 net.cpp:156] Memory required for data: 3704979456
I0630 14:51:31.226056 47538 layer_factory.hpp:77] Creating layer conv6_2-Dropout2
I0630 14:51:31.226074 47538 net.cpp:91] Creating Layer conv6_2-Dropout2
I0630 14:51:31.226085 47538 net.cpp:425] conv6_2-Dropout2 <- conv6_2-Convolution3
I0630 14:51:31.226097 47538 net.cpp:399] conv6_2-Dropout2 -> conv6_2-Dropout2
I0630 14:51:31.226220 47538 net.cpp:141] Setting up conv6_2-Dropout2
I0630 14:51:31.226233 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.226241 47538 net.cpp:156] Memory required for data: 3711270912
I0630 14:51:31.226248 47538 layer_factory.hpp:77] Creating layer conv6_2-Concat2
I0630 14:51:31.226260 47538 net.cpp:91] Creating Layer conv6_2-Concat2
I0630 14:51:31.226267 47538 net.cpp:425] conv6_2-Concat2 <- conv6_2-Concat1_conv6_2-Concat1_0_split_1
I0630 14:51:31.226279 47538 net.cpp:425] conv6_2-Concat2 <- conv6_2-Dropout2
I0630 14:51:31.226295 47538 net.cpp:399] conv6_2-Concat2 -> conv6_2-Concat2
I0630 14:51:31.226356 47538 net.cpp:141] Setting up conv6_2-Concat2
I0630 14:51:31.226366 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:31.226380 47538 net.cpp:156] Memory required for data: 3749019648
I0630 14:51:31.226408 47538 layer_factory.hpp:77] Creating layer conv6_2-Concat2_conv6_2-Concat2_0_split
I0630 14:51:31.226419 47538 net.cpp:91] Creating Layer conv6_2-Concat2_conv6_2-Concat2_0_split
I0630 14:51:31.226428 47538 net.cpp:425] conv6_2-Concat2_conv6_2-Concat2_0_split <- conv6_2-Concat2
I0630 14:51:31.226444 47538 net.cpp:399] conv6_2-Concat2_conv6_2-Concat2_0_split -> conv6_2-Concat2_conv6_2-Concat2_0_split_0
I0630 14:51:31.226457 47538 net.cpp:399] conv6_2-Concat2_conv6_2-Concat2_0_split -> conv6_2-Concat2_conv6_2-Concat2_0_split_1
I0630 14:51:31.226552 47538 net.cpp:141] Setting up conv6_2-Concat2_conv6_2-Concat2_0_split
I0630 14:51:31.226563 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:31.226573 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:31.226579 47538 net.cpp:156] Memory required for data: 3824517120
I0630 14:51:31.226586 47538 layer_factory.hpp:77] Creating layer conv6_2-BatchNorm3
I0630 14:51:31.226598 47538 net.cpp:91] Creating Layer conv6_2-BatchNorm3
I0630 14:51:31.226608 47538 net.cpp:425] conv6_2-BatchNorm3 <- conv6_2-Concat2_conv6_2-Concat2_0_split_0
I0630 14:51:31.226622 47538 net.cpp:399] conv6_2-BatchNorm3 -> conv6_2-BatchNorm3
I0630 14:51:31.227197 47538 net.cpp:141] Setting up conv6_2-BatchNorm3
I0630 14:51:31.227211 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:31.227219 47538 net.cpp:156] Memory required for data: 3862265856
I0630 14:51:31.227234 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale3
I0630 14:51:31.227250 47538 net.cpp:91] Creating Layer conv6_2-Scale3
I0630 14:51:31.227258 47538 net.cpp:425] conv6_2-Scale3 <- conv6_2-BatchNorm3
I0630 14:51:31.227269 47538 net.cpp:386] conv6_2-Scale3 -> conv6_2-BatchNorm3 (in-place)
I0630 14:51:31.227370 47538 layer_factory.hpp:77] Creating layer conv6_2-Scale3
I0630 14:51:31.227735 47538 net.cpp:141] Setting up conv6_2-Scale3
I0630 14:51:31.227747 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:31.227756 47538 net.cpp:156] Memory required for data: 3900014592
I0630 14:51:31.227767 47538 layer_factory.hpp:77] Creating layer conv6_2-ReLU3
I0630 14:51:31.227782 47538 net.cpp:91] Creating Layer conv6_2-ReLU3
I0630 14:51:31.227788 47538 net.cpp:425] conv6_2-ReLU3 <- conv6_2-BatchNorm3
I0630 14:51:31.227799 47538 net.cpp:386] conv6_2-ReLU3 -> conv6_2-BatchNorm3 (in-place)
I0630 14:51:31.228195 47538 net.cpp:141] Setting up conv6_2-ReLU3
I0630 14:51:31.228211 47538 net.cpp:148] Top shape: 3 96 32 32 32 (9437184)
I0630 14:51:31.228219 47538 net.cpp:156] Memory required for data: 3937763328
I0630 14:51:31.228226 47538 layer_factory.hpp:77] Creating layer conv6_2-Convolution4
I0630 14:51:31.228252 47538 net.cpp:91] Creating Layer conv6_2-Convolution4
I0630 14:51:31.228260 47538 net.cpp:425] conv6_2-Convolution4 <- conv6_2-BatchNorm3
I0630 14:51:31.228277 47538 net.cpp:399] conv6_2-Convolution4 -> conv6_2-Convolution4
I0630 14:51:31.233165 47538 net.cpp:141] Setting up conv6_2-Convolution4
I0630 14:51:31.233187 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.233194 47538 net.cpp:156] Memory required for data: 3944054784
I0630 14:51:31.233208 47538 layer_factory.hpp:77] Creating layer conv6_2-Dropout3
I0630 14:51:31.233222 47538 net.cpp:91] Creating Layer conv6_2-Dropout3
I0630 14:51:31.233232 47538 net.cpp:425] conv6_2-Dropout3 <- conv6_2-Convolution4
I0630 14:51:31.233247 47538 net.cpp:399] conv6_2-Dropout3 -> conv6_2-Dropout3
I0630 14:51:31.233362 47538 net.cpp:141] Setting up conv6_2-Dropout3
I0630 14:51:31.233376 47538 net.cpp:148] Top shape: 3 16 32 32 32 (1572864)
I0630 14:51:31.233382 47538 net.cpp:156] Memory required for data: 3950346240
I0630 14:51:31.233389 47538 layer_factory.hpp:77] Creating layer conv6_2-Concat3
I0630 14:51:31.233400 47538 net.cpp:91] Creating Layer conv6_2-Concat3
I0630 14:51:31.233409 47538 net.cpp:425] conv6_2-Concat3 <- conv6_2-Concat2_conv6_2-Concat2_0_split_1
I0630 14:51:31.233418 47538 net.cpp:425] conv6_2-Concat3 <- conv6_2-Dropout3
I0630 14:51:31.233441 47538 net.cpp:399] conv6_2-Concat3 -> conv6_2
I0630 14:51:31.233520 47538 net.cpp:141] Setting up conv6_2-Concat3
I0630 14:51:31.233534 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:31.233541 47538 net.cpp:156] Memory required for data: 3994386432
I0630 14:51:31.233547 47538 layer_factory.hpp:77] Creating layer conv6_2_bn
I0630 14:51:31.233563 47538 net.cpp:91] Creating Layer conv6_2_bn
I0630 14:51:31.233573 47538 net.cpp:425] conv6_2_bn <- conv6_2
I0630 14:51:31.233587 47538 net.cpp:399] conv6_2_bn -> conv6_2_bn
I0630 14:51:31.234149 47538 net.cpp:141] Setting up conv6_2_bn
I0630 14:51:31.234163 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:31.234170 47538 net.cpp:156] Memory required for data: 4038426624
I0630 14:51:31.234189 47538 layer_factory.hpp:77] Creating layer scale_conv6_2
I0630 14:51:31.234200 47538 net.cpp:91] Creating Layer scale_conv6_2
I0630 14:51:31.234206 47538 net.cpp:425] scale_conv6_2 <- conv6_2_bn
I0630 14:51:31.234221 47538 net.cpp:386] scale_conv6_2 -> conv6_2_bn (in-place)
I0630 14:51:31.234318 47538 layer_factory.hpp:77] Creating layer scale_conv6_2
I0630 14:51:31.237280 47538 net.cpp:141] Setting up scale_conv6_2
I0630 14:51:31.237303 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:31.237310 47538 net.cpp:156] Memory required for data: 4082466816
I0630 14:51:31.237325 47538 layer_factory.hpp:77] Creating layer relu6_2
I0630 14:51:31.237336 47538 net.cpp:91] Creating Layer relu6_2
I0630 14:51:31.237344 47538 net.cpp:425] relu6_2 <- conv6_2_bn
I0630 14:51:31.237360 47538 net.cpp:386] relu6_2 -> conv6_2_bn (in-place)
I0630 14:51:31.237769 47538 net.cpp:141] Setting up relu6_2
I0630 14:51:31.237785 47538 net.cpp:148] Top shape: 3 112 32 32 32 (11010048)
I0630 14:51:31.237792 47538 net.cpp:156] Memory required for data: 4126507008
I0630 14:51:31.237800 47538 layer_factory.hpp:77] Creating layer conv6_3-Convolution1
I0630 14:51:31.237823 47538 net.cpp:91] Creating Layer conv6_3-Convolution1
I0630 14:51:31.237830 47538 net.cpp:425] conv6_3-Convolution1 <- conv6_2_bn
I0630 14:51:31.237848 47538 net.cpp:399] conv6_3-Convolution1 -> conv6_3-Convolution1
I0630 14:51:31.246121 47538 net.cpp:141] Setting up conv6_3-Convolution1
I0630 14:51:31.246145 47538 net.cpp:148] Top shape: 3 4 32 32 32 (393216)
I0630 14:51:31.246152 47538 net.cpp:156] Memory required for data: 4128079872
I0630 14:51:31.246165 47538 layer_factory.hpp:77] Creating layer conv6_3-BatchNorm1
I0630 14:51:31.246186 47538 net.cpp:91] Creating Layer conv6_3-BatchNorm1
I0630 14:51:31.246196 47538 net.cpp:425] conv6_3-BatchNorm1 <- conv6_3-Convolution1
I0630 14:51:31.246210 47538 net.cpp:399] conv6_3-BatchNorm1 -> conv6_3-BatchNorm1
I0630 14:51:31.246769 47538 net.cpp:141] Setting up conv6_3-BatchNorm1
I0630 14:51:31.246783 47538 net.cpp:148] Top shape: 3 4 32 32 32 (393216)
I0630 14:51:31.246789 47538 net.cpp:156] Memory required for data: 4129652736
I0630 14:51:31.246803 47538 layer_factory.hpp:77] Creating layer conv6_3-Scale1
I0630 14:51:31.246814 47538 net.cpp:91] Creating Layer conv6_3-Scale1
I0630 14:51:31.246822 47538 net.cpp:425] conv6_3-Scale1 <- conv6_3-BatchNorm1
I0630 14:51:31.246831 47538 net.cpp:386] conv6_3-Scale1 -> conv6_3-BatchNorm1 (in-place)
I0630 14:51:31.246928 47538 layer_factory.hpp:77] Creating layer conv6_3-Scale1
I0630 14:51:31.247264 47538 net.cpp:141] Setting up conv6_3-Scale1
I0630 14:51:31.247282 47538 net.cpp:148] Top shape: 3 4 32 32 32 (393216)
I0630 14:51:31.247289 47538 net.cpp:156] Memory required for data: 4131225600
I0630 14:51:31.247300 47538 layer_factory.hpp:77] Creating layer conv6_3-ReLU1
I0630 14:51:31.247309 47538 net.cpp:91] Creating Layer conv6_3-ReLU1
I0630 14:51:31.247318 47538 net.cpp:425] conv6_3-ReLU1 <- conv6_3-BatchNorm1
I0630 14:51:31.247328 47538 net.cpp:386] conv6_3-ReLU1 -> conv6_3-BatchNorm1 (in-place)
I0630 14:51:31.248963 47538 net.cpp:141] Setting up conv6_3-ReLU1
I0630 14:51:31.248983 47538 net.cpp:148] Top shape: 3 4 32 32 32 (393216)
I0630 14:51:31.248997 47538 net.cpp:156] Memory required for data: 4132798464
I0630 14:51:31.249023 47538 layer_factory.hpp:77] Creating layer conv6_3-BatchNorm1_conv6_3-ReLU1_0_split
I0630 14:51:31.249039 47538 net.cpp:91] Creating Layer conv6_3-BatchNorm1_conv6_3-ReLU1_0_split
I0630 14:51:31.249047 47538 net.cpp:425] conv6_3-BatchNorm1_conv6_3-ReLU1_0_split <- conv6_3-BatchNorm1
I0630 14:51:31.249060 47538 net.cpp:399] conv6_3-BatchNorm1_conv6_3-ReLU1_0_split -> conv6_3-BatchNorm1_conv6_3-ReLU1_0_split_0
I0630 14:51:31.249079 47538 net.cpp:399] conv6_3-BatchNorm1_conv6_3-ReLU1_0_split -> conv6_3-BatchNorm1_conv6_3-ReLU1_0_split_1
I0630 14:51:31.249182 47538 net.cpp:141] Setting up conv6_3-BatchNorm1_conv6_3-ReLU1_0_split
I0630 14:51:31.249194 47538 net.cpp:148] Top shape: 3 4 32 32 32 (393216)
I0630 14:51:31.249204 47538 net.cpp:148] Top shape: 3 4 32 32 32 (393216)
I0630 14:51:31.249210 47538 net.cpp:156] Memory required for data: 4135944192
I0630 14:51:31.249217 47538 layer_factory.hpp:77] Creating layer accuracy
I0630 14:51:31.249236 47538 net.cpp:91] Creating Layer accuracy
I0630 14:51:31.249245 47538 net.cpp:425] accuracy <- conv6_3-BatchNorm1_conv6_3-ReLU1_0_split_0
I0630 14:51:31.249254 47538 net.cpp:425] accuracy <- dataSeg_data_2_split_0
I0630 14:51:31.249272 47538 net.cpp:399] accuracy -> accuracy
I0630 14:51:31.249287 47538 net.cpp:141] Setting up accuracy
I0630 14:51:31.249297 47538 net.cpp:148] Top shape: (1)
I0630 14:51:31.249303 47538 net.cpp:156] Memory required for data: 4135944196
I0630 14:51:31.249310 47538 layer_factory.hpp:77] Creating layer loss
I0630 14:51:31.249322 47538 net.cpp:91] Creating Layer loss
I0630 14:51:31.249330 47538 net.cpp:425] loss <- conv6_3-BatchNorm1_conv6_3-ReLU1_0_split_1
I0630 14:51:31.249339 47538 net.cpp:425] loss <- dataSeg_data_2_split_1
I0630 14:51:31.249347 47538 net.cpp:425] loss <- dataCp
I0630 14:51:31.249362 47538 net.cpp:399] loss -> loss
I0630 14:51:31.249379 47538 layer_factory.hpp:77] Creating layer loss
I0630 14:51:31.252823 47538 net.cpp:141] Setting up loss
I0630 14:51:31.252843 47538 net.cpp:148] Top shape: (1)
I0630 14:51:31.252851 47538 net.cpp:151]     with loss weight 1
I0630 14:51:31.252893 47538 net.cpp:156] Memory required for data: 4135944200
I0630 14:51:31.252902 47538 net.cpp:217] loss needs backward computation.
I0630 14:51:31.252912 47538 net.cpp:219] accuracy does not need backward computation.
I0630 14:51:31.252920 47538 net.cpp:217] conv6_3-BatchNorm1_conv6_3-ReLU1_0_split needs backward computation.
I0630 14:51:31.252928 47538 net.cpp:217] conv6_3-ReLU1 needs backward computation.
I0630 14:51:31.252934 47538 net.cpp:217] conv6_3-Scale1 needs backward computation.
I0630 14:51:31.252940 47538 net.cpp:217] conv6_3-BatchNorm1 needs backward computation.
I0630 14:51:31.252948 47538 net.cpp:217] conv6_3-Convolution1 needs backward computation.
I0630 14:51:31.252955 47538 net.cpp:217] relu6_2 needs backward computation.
I0630 14:51:31.252961 47538 net.cpp:217] scale_conv6_2 needs backward computation.
I0630 14:51:31.252967 47538 net.cpp:217] conv6_2_bn needs backward computation.
I0630 14:51:31.252974 47538 net.cpp:217] conv6_2-Concat3 needs backward computation.
I0630 14:51:31.252984 47538 net.cpp:217] conv6_2-Dropout3 needs backward computation.
I0630 14:51:31.252990 47538 net.cpp:217] conv6_2-Convolution4 needs backward computation.
I0630 14:51:31.252997 47538 net.cpp:217] conv6_2-ReLU3 needs backward computation.
I0630 14:51:31.253003 47538 net.cpp:217] conv6_2-Scale3 needs backward computation.
I0630 14:51:31.253011 47538 net.cpp:217] conv6_2-BatchNorm3 needs backward computation.
I0630 14:51:31.253018 47538 net.cpp:217] conv6_2-Concat2_conv6_2-Concat2_0_split needs backward computation.
I0630 14:51:31.253026 47538 net.cpp:217] conv6_2-Concat2 needs backward computation.
I0630 14:51:31.253041 47538 net.cpp:217] conv6_2-Dropout2 needs backward computation.
I0630 14:51:31.253051 47538 net.cpp:217] conv6_2-Convolution3 needs backward computation.
I0630 14:51:31.253057 47538 net.cpp:217] conv6_2-ReLU2 needs backward computation.
I0630 14:51:31.253063 47538 net.cpp:217] conv6_2-Scale2 needs backward computation.
I0630 14:51:31.253090 47538 net.cpp:217] conv6_2-BatchNorm2 needs backward computation.
I0630 14:51:31.253099 47538 net.cpp:217] conv6_2-Concat1_conv6_2-Concat1_0_split needs backward computation.
I0630 14:51:31.253106 47538 net.cpp:217] conv6_2-Concat1 needs backward computation.
I0630 14:51:31.253115 47538 net.cpp:217] conv6_2-Dropout1 needs backward computation.
I0630 14:51:31.253123 47538 net.cpp:217] conv6_2-Convolution2 needs backward computation.
I0630 14:51:31.253130 47538 net.cpp:217] conv6_2-ReLU1 needs backward computation.
I0630 14:51:31.253136 47538 net.cpp:217] conv6_2-Scale1 needs backward computation.
I0630 14:51:31.253144 47538 net.cpp:217] conv6_2-BatchNorm1 needs backward computation.
I0630 14:51:31.253150 47538 net.cpp:217] conv6_2-Convolution1_conv6_2-Convolution1_0_split needs backward computation.
I0630 14:51:31.253159 47538 net.cpp:217] conv6_2-Convolution1 needs backward computation.
I0630 14:51:31.253166 47538 net.cpp:217] relu6 needs backward computation.
I0630 14:51:31.253172 47538 net.cpp:217] scale_conv6_fine needs backward computation.
I0630 14:51:31.253178 47538 net.cpp:217] conv6_bn needs backward computation.
I0630 14:51:31.253187 47538 net.cpp:217] conv6-Concat3 needs backward computation.
I0630 14:51:31.253196 47538 net.cpp:217] conv6-Dropout3 needs backward computation.
I0630 14:51:31.253202 47538 net.cpp:217] conv6-Convolution4 needs backward computation.
I0630 14:51:31.253209 47538 net.cpp:217] conv6-ReLU3 needs backward computation.
I0630 14:51:31.253221 47538 net.cpp:217] conv6-Scale3 needs backward computation.
I0630 14:51:31.253227 47538 net.cpp:217] conv6-BatchNorm3 needs backward computation.
I0630 14:51:31.253235 47538 net.cpp:217] conv6-Concat2_conv6-Concat2_0_split needs backward computation.
I0630 14:51:31.253242 47538 net.cpp:217] conv6-Concat2 needs backward computation.
I0630 14:51:31.253252 47538 net.cpp:217] conv6-Dropout2 needs backward computation.
I0630 14:51:31.253259 47538 net.cpp:217] conv6-Convolution3 needs backward computation.
I0630 14:51:31.253266 47538 net.cpp:217] conv6-ReLU2 needs backward computation.
I0630 14:51:31.253273 47538 net.cpp:217] conv6-Scale2 needs backward computation.
I0630 14:51:31.253279 47538 net.cpp:217] conv6-BatchNorm2 needs backward computation.
I0630 14:51:31.253286 47538 net.cpp:217] conv6-Concat1_conv6-Concat1_0_split needs backward computation.
I0630 14:51:31.253294 47538 net.cpp:217] conv6-Concat1 needs backward computation.
I0630 14:51:31.253302 47538 net.cpp:217] conv6-Dropout1 needs backward computation.
I0630 14:51:31.253310 47538 net.cpp:217] conv6-Convolution2 needs backward computation.
I0630 14:51:31.253317 47538 net.cpp:217] conv6-ReLU1 needs backward computation.
I0630 14:51:31.253324 47538 net.cpp:217] conv6-Scale1 needs backward computation.
I0630 14:51:31.253329 47538 net.cpp:217] conv6-BatchNorm1 needs backward computation.
I0630 14:51:31.253338 47538 net.cpp:217] conv6-Convolution1_conv6-Convolution1_0_split needs backward computation.
I0630 14:51:31.253345 47538 net.cpp:217] conv6-Convolution1 needs backward computation.
I0630 14:51:31.253352 47538 net.cpp:217] concat32 needs backward computation.
I0630 14:51:31.253360 47538 net.cpp:217] deconv6 needs backward computation.
I0630 14:51:31.253370 47538 net.cpp:217] relu5a_2 needs backward computation.
I0630 14:51:31.253376 47538 net.cpp:217] scale_conv5_2 needs backward computation.
I0630 14:51:31.253381 47538 net.cpp:217] conv5_2_bn needs backward computation.
I0630 14:51:31.253388 47538 net.cpp:217] conv5_2-Concat3 needs backward computation.
I0630 14:51:31.253398 47538 net.cpp:217] conv5_2-Dropout3 needs backward computation.
I0630 14:51:31.253408 47538 net.cpp:217] conv5_2-Convolution4 needs backward computation.
I0630 14:51:31.253417 47538 net.cpp:217] conv5_2-ReLU3 needs backward computation.
I0630 14:51:31.253423 47538 net.cpp:217] conv5_2-Scale3 needs backward computation.
I0630 14:51:31.253430 47538 net.cpp:217] conv5_2-BatchNorm3 needs backward computation.
I0630 14:51:31.253438 47538 net.cpp:217] conv5_2-Concat2_conv5_2-Concat2_0_split needs backward computation.
I0630 14:51:31.253458 47538 net.cpp:217] conv5_2-Concat2 needs backward computation.
I0630 14:51:31.253468 47538 net.cpp:217] conv5_2-Dropout2 needs backward computation.
I0630 14:51:31.253476 47538 net.cpp:217] conv5_2-Convolution3 needs backward computation.
I0630 14:51:31.253484 47538 net.cpp:217] conv5_2-ReLU2 needs backward computation.
I0630 14:51:31.253489 47538 net.cpp:217] conv5_2-Scale2 needs backward computation.
I0630 14:51:31.253495 47538 net.cpp:217] conv5_2-BatchNorm2 needs backward computation.
I0630 14:51:31.253504 47538 net.cpp:217] conv5_2-Concat1_conv5_2-Concat1_0_split needs backward computation.
I0630 14:51:31.253511 47538 net.cpp:217] conv5_2-Concat1 needs backward computation.
I0630 14:51:31.253520 47538 net.cpp:217] conv5_2-Dropout1 needs backward computation.
I0630 14:51:31.253526 47538 net.cpp:217] conv5_2-Convolution2 needs backward computation.
I0630 14:51:31.253535 47538 net.cpp:217] conv5_2-ReLU1 needs backward computation.
I0630 14:51:31.253541 47538 net.cpp:217] conv5_2-Scale1 needs backward computation.
I0630 14:51:31.253547 47538 net.cpp:217] conv5_2-BatchNorm1 needs backward computation.
I0630 14:51:31.253556 47538 net.cpp:217] conv5_2-Convolution1_conv5_2-Convolution1_0_split needs backward computation.
I0630 14:51:31.253567 47538 net.cpp:217] conv5_2-Convolution1 needs backward computation.
I0630 14:51:31.253574 47538 net.cpp:217] relu5a needs backward computation.
I0630 14:51:31.253581 47538 net.cpp:217] scale_conv5 needs backward computation.
I0630 14:51:31.253587 47538 net.cpp:217] conv5_bn needs backward computation.
I0630 14:51:31.253594 47538 net.cpp:217] conv5-Concat3 needs backward computation.
I0630 14:51:31.253603 47538 net.cpp:217] conv5-Dropout3 needs backward computation.
I0630 14:51:31.253610 47538 net.cpp:217] conv5-Convolution4 needs backward computation.
I0630 14:51:31.253618 47538 net.cpp:217] conv5-ReLU3 needs backward computation.
I0630 14:51:31.253625 47538 net.cpp:217] conv5-Scale3 needs backward computation.
I0630 14:51:31.253631 47538 net.cpp:217] conv5-BatchNorm3 needs backward computation.
I0630 14:51:31.253638 47538 net.cpp:217] conv5-Concat2_conv5-Concat2_0_split needs backward computation.
I0630 14:51:31.253646 47538 net.cpp:217] conv5-Concat2 needs backward computation.
I0630 14:51:31.253655 47538 net.cpp:217] conv5-Dropout2 needs backward computation.
I0630 14:51:31.253662 47538 net.cpp:217] conv5-Convolution3 needs backward computation.
I0630 14:51:31.253669 47538 net.cpp:217] conv5-ReLU2 needs backward computation.
I0630 14:51:31.253675 47538 net.cpp:217] conv5-Scale2 needs backward computation.
I0630 14:51:31.253682 47538 net.cpp:217] conv5-BatchNorm2 needs backward computation.
I0630 14:51:31.253690 47538 net.cpp:217] conv5-Concat1_conv5-Concat1_0_split needs backward computation.
I0630 14:51:31.253697 47538 net.cpp:217] conv5-Concat1 needs backward computation.
I0630 14:51:31.253705 47538 net.cpp:217] conv5-Dropout1 needs backward computation.
I0630 14:51:31.253713 47538 net.cpp:217] conv5-Convolution2 needs backward computation.
I0630 14:51:31.253721 47538 net.cpp:217] conv5-ReLU1 needs backward computation.
I0630 14:51:31.253727 47538 net.cpp:217] conv5-Scale1 needs backward computation.
I0630 14:51:31.253733 47538 net.cpp:217] conv5-BatchNorm1 needs backward computation.
I0630 14:51:31.253742 47538 net.cpp:217] conv5-Convolution1_conv5-Convolution1_0_split needs backward computation.
I0630 14:51:31.253751 47538 net.cpp:217] conv5-Convolution1 needs backward computation.
I0630 14:51:31.253756 47538 net.cpp:217] concat16 needs backward computation.
I0630 14:51:31.253768 47538 net.cpp:217] deconv5 needs backward computation.
I0630 14:51:31.253777 47538 net.cpp:217] relu4a needs backward computation.
I0630 14:51:31.253783 47538 net.cpp:217] scale_conv4_fine needs backward computation.
I0630 14:51:31.253790 47538 net.cpp:217] conv4_bn needs backward computation.
I0630 14:51:31.253798 47538 net.cpp:217] conv4-Concat3 needs backward computation.
I0630 14:51:31.253806 47538 net.cpp:217] conv4-Dropout3 needs backward computation.
I0630 14:51:31.253821 47538 net.cpp:217] conv4-Convolution4 needs backward computation.
I0630 14:51:31.253837 47538 net.cpp:217] conv4-ReLU3 needs backward computation.
I0630 14:51:31.253844 47538 net.cpp:217] conv4-Scale3 needs backward computation.
I0630 14:51:31.253852 47538 net.cpp:217] conv4-BatchNorm3 needs backward computation.
I0630 14:51:31.253859 47538 net.cpp:217] conv4-Concat2_conv4-Concat2_0_split needs backward computation.
I0630 14:51:31.253866 47538 net.cpp:217] conv4-Concat2 needs backward computation.
I0630 14:51:31.253875 47538 net.cpp:217] conv4-Dropout2 needs backward computation.
I0630 14:51:31.253883 47538 net.cpp:217] conv4-Convolution3 needs backward computation.
I0630 14:51:31.253891 47538 net.cpp:217] conv4-ReLU2 needs backward computation.
I0630 14:51:31.253897 47538 net.cpp:217] conv4-Scale2 needs backward computation.
I0630 14:51:31.253903 47538 net.cpp:217] conv4-BatchNorm2 needs backward computation.
I0630 14:51:31.253911 47538 net.cpp:217] conv4-Concat1_conv4-Concat1_0_split needs backward computation.
I0630 14:51:31.253919 47538 net.cpp:217] conv4-Concat1 needs backward computation.
I0630 14:51:31.253927 47538 net.cpp:217] conv4-Dropout1 needs backward computation.
I0630 14:51:31.253937 47538 net.cpp:217] conv4-Convolution2 needs backward computation.
I0630 14:51:31.253947 47538 net.cpp:217] conv4-ReLU1 needs backward computation.
I0630 14:51:31.253952 47538 net.cpp:217] conv4-Scale1 needs backward computation.
I0630 14:51:31.253958 47538 net.cpp:217] conv4-BatchNorm1 needs backward computation.
I0630 14:51:31.253967 47538 net.cpp:217] conv4-Convolution1_conv4-Convolution1_0_split needs backward computation.
I0630 14:51:31.253974 47538 net.cpp:217] conv4-Convolution1 needs backward computation.
I0630 14:51:31.253981 47538 net.cpp:217] concat8 needs backward computation.
I0630 14:51:31.253989 47538 net.cpp:217] deconv4 needs backward computation.
I0630 14:51:31.253996 47538 net.cpp:217] pool3 needs backward computation.
I0630 14:51:31.254004 47538 net.cpp:217] relu3a needs backward computation.
I0630 14:51:31.254011 47538 net.cpp:217] scale_conv6 needs backward computation.
I0630 14:51:31.254017 47538 net.cpp:217] bn6 needs backward computation.
I0630 14:51:31.254024 47538 net.cpp:217] conv3a_conv3a_0_split needs backward computation.
I0630 14:51:31.254034 47538 net.cpp:217] conv3a needs backward computation.
I0630 14:51:31.254040 47538 net.cpp:217] pool2 needs backward computation.
I0630 14:51:31.254047 47538 net.cpp:217] relu2b needs backward computation.
I0630 14:51:31.254053 47538 net.cpp:217] scale_conv5_fine needs backward computation.
I0630 14:51:31.254060 47538 net.cpp:217] bn5 needs backward computation.
I0630 14:51:31.254068 47538 net.cpp:217] conv2b_conv2b_0_split needs backward computation.
I0630 14:51:31.254076 47538 net.cpp:217] conv2b needs backward computation.
I0630 14:51:31.254082 47538 net.cpp:217] relu2a needs backward computation.
I0630 14:51:31.254089 47538 net.cpp:217] scale_conv4 needs backward computation.
I0630 14:51:31.254096 47538 net.cpp:217] bn4 needs backward computation.
I0630 14:51:31.254103 47538 net.cpp:217] conv2a-Concat3 needs backward computation.
I0630 14:51:31.254112 47538 net.cpp:217] conv2a-Dropout3 needs backward computation.
I0630 14:51:31.254120 47538 net.cpp:217] conv2a-Convolution4 needs backward computation.
I0630 14:51:31.254128 47538 net.cpp:217] conv2a-ReLU3 needs backward computation.
I0630 14:51:31.254135 47538 net.cpp:217] conv2a-Scale3 needs backward computation.
I0630 14:51:31.254142 47538 net.cpp:217] conv2a-BatchNorm3 needs backward computation.
I0630 14:51:31.254149 47538 net.cpp:217] conv2a-Concat2_conv2a-Concat2_0_split needs backward computation.
I0630 14:51:31.254158 47538 net.cpp:217] conv2a-Concat2 needs backward computation.
I0630 14:51:31.254169 47538 net.cpp:217] conv2a-Dropout2 needs backward computation.
I0630 14:51:31.254177 47538 net.cpp:217] conv2a-Convolution3 needs backward computation.
I0630 14:51:31.254184 47538 net.cpp:217] conv2a-ReLU2 needs backward computation.
I0630 14:51:31.254196 47538 net.cpp:217] conv2a-Scale2 needs backward computation.
I0630 14:51:31.254213 47538 net.cpp:217] conv2a-BatchNorm2 needs backward computation.
I0630 14:51:31.254220 47538 net.cpp:217] conv2a-Concat1_conv2a-Concat1_0_split needs backward computation.
I0630 14:51:31.254228 47538 net.cpp:217] conv2a-Concat1 needs backward computation.
I0630 14:51:31.254237 47538 net.cpp:217] conv2a-Dropout1 needs backward computation.
I0630 14:51:31.254245 47538 net.cpp:217] conv2a-Convolution2 needs backward computation.
I0630 14:51:31.254252 47538 net.cpp:217] conv2a-ReLU1 needs backward computation.
I0630 14:51:31.254259 47538 net.cpp:217] conv2a-Scale1 needs backward computation.
I0630 14:51:31.254266 47538 net.cpp:217] conv2a-BatchNorm1 needs backward computation.
I0630 14:51:31.254274 47538 net.cpp:217] conv2a-Convolution1_conv2a-Convolution1_0_split needs backward computation.
I0630 14:51:31.254281 47538 net.cpp:217] conv2a-Convolution1 needs backward computation.
I0630 14:51:31.254288 47538 net.cpp:217] pool1 needs backward computation.
I0630 14:51:31.254297 47538 net.cpp:217] relu1c needs backward computation.
I0630 14:51:31.254304 47538 net.cpp:217] scale_conv3 needs backward computation.
I0630 14:51:31.254310 47538 net.cpp:217] bn3 needs backward computation.
I0630 14:51:31.254317 47538 net.cpp:217] conv1c_conv1c_0_split needs backward computation.
I0630 14:51:31.254326 47538 net.cpp:217] conv1c needs backward computation.
I0630 14:51:31.254333 47538 net.cpp:217] relu1b needs backward computation.
I0630 14:51:31.254339 47538 net.cpp:217] scale_conv2 needs backward computation.
I0630 14:51:31.254349 47538 net.cpp:217] bn2 needs backward computation.
I0630 14:51:31.254357 47538 net.cpp:217] Concat3 needs backward computation.
I0630 14:51:31.254366 47538 net.cpp:217] Dropout3 needs backward computation.
I0630 14:51:31.254374 47538 net.cpp:217] Convolution4 needs backward computation.
I0630 14:51:31.254381 47538 net.cpp:217] ReLU3 needs backward computation.
I0630 14:51:31.254390 47538 net.cpp:217] Scale3 needs backward computation.
I0630 14:51:31.254396 47538 net.cpp:217] BatchNorm3 needs backward computation.
I0630 14:51:31.254403 47538 net.cpp:217] Concat2_Concat2_0_split needs backward computation.
I0630 14:51:31.254410 47538 net.cpp:217] Concat2 needs backward computation.
I0630 14:51:31.254420 47538 net.cpp:217] Dropout2 needs backward computation.
I0630 14:51:31.254427 47538 net.cpp:217] Convolution3 needs backward computation.
I0630 14:51:31.254434 47538 net.cpp:217] ReLU2 needs backward computation.
I0630 14:51:31.254441 47538 net.cpp:217] Scale2 needs backward computation.
I0630 14:51:31.254448 47538 net.cpp:217] BatchNorm2 needs backward computation.
I0630 14:51:31.254456 47538 net.cpp:217] Concat1_Concat1_0_split needs backward computation.
I0630 14:51:31.254462 47538 net.cpp:217] Concat1 needs backward computation.
I0630 14:51:31.254470 47538 net.cpp:217] Dropout1 needs backward computation.
I0630 14:51:31.254479 47538 net.cpp:217] Convolution2 needs backward computation.
I0630 14:51:31.254485 47538 net.cpp:217] ReLU1 needs backward computation.
I0630 14:51:31.254492 47538 net.cpp:217] Scale1 needs backward computation.
I0630 14:51:31.254498 47538 net.cpp:217] BatchNorm1 needs backward computation.
I0630 14:51:31.254508 47538 net.cpp:217] Convolution1_Convolution1_0_split needs backward computation.
I0630 14:51:31.254515 47538 net.cpp:217] Convolution1 needs backward computation.
I0630 14:51:31.254523 47538 net.cpp:217] relu1a needs backward computation.
I0630 14:51:31.254529 47538 net.cpp:217] scale_conv1 needs backward computation.
I0630 14:51:31.254536 47538 net.cpp:217] bn1 needs backward computation.
I0630 14:51:31.254544 47538 net.cpp:217] conv1a needs backward computation.
I0630 14:51:31.254551 47538 net.cpp:219] concat does not need backward computation.
I0630 14:51:31.254565 47538 net.cpp:219] dataSeg_data_2_split does not need backward computation.
I0630 14:51:31.254575 47538 net.cpp:219] data does not need backward computation.
I0630 14:51:31.254580 47538 net.cpp:261] This network produces output accuracy
I0630 14:51:31.254591 47538 net.cpp:261] This network produces output loss
I0630 14:51:31.254863 47538 net.cpp:274] Network initialization done.
I0630 14:51:31.256446 47538 solver.cpp:60] Solver scaffolding done.
I0630 14:51:31.276078 47538 caffe.cpp:209] Resuming from _iter_44000.solverstate
I0630 14:51:32.636332 47538 sgd_solver.cpp:318] SGDSolver: restoring history
I0630 14:51:32.753324 47538 caffe.cpp:219] Starting Optimization
I0630 14:51:32.753362 47538 solver.cpp:279] Solving 
I0630 14:51:32.753370 47538 solver.cpp:280] Learning Rate Policy: step
I0630 14:51:32.804816 47538 solver.cpp:337] Iteration 44000, Testing net (#0)
I0630 14:54:19.333284 47538 solver.cpp:404]     Test net output #0: accuracy = 0.959705
I0630 14:54:19.333515 47538 solver.cpp:404]     Test net output #1: loss = 0.0703184 (* 1 = 0.0703184 loss)
I0630 14:54:21.492609 47538 solver.cpp:228] Iteration 44000, loss = 0.0708677
I0630 14:54:21.492682 47538 solver.cpp:244]     Train net output #0: loss = 0.0790984 (* 1 = 0.0790984 loss)
I0630 14:54:21.492723 47538 sgd_solver.cpp:106] Iteration 44000, lr = 5e-11
I0630 14:57:24.744076 47538 solver.cpp:228] Iteration 44100, loss = 0.0725977
I0630 14:57:24.745344 47538 solver.cpp:244]     Train net output #0: loss = 0.0731848 (* 1 = 0.0731848 loss)
I0630 14:57:24.745358 47538 sgd_solver.cpp:106] Iteration 44100, lr = 5e-11
I0630 15:00:29.283118 47538 solver.cpp:228] Iteration 44200, loss = 0.0774986
I0630 15:00:29.286026 47538 solver.cpp:244]     Train net output #0: loss = 0.0757825 (* 1 = 0.0757825 loss)
I0630 15:00:29.286057 47538 sgd_solver.cpp:106] Iteration 44200, lr = 5e-11
I0630 15:03:34.091248 47538 solver.cpp:228] Iteration 44300, loss = 0.0661083
I0630 15:03:34.092772 47538 solver.cpp:244]     Train net output #0: loss = 0.0690766 (* 1 = 0.0690766 loss)
I0630 15:03:34.092801 47538 sgd_solver.cpp:106] Iteration 44300, lr = 5e-11
I0630 15:06:38.279577 47538 solver.cpp:228] Iteration 44400, loss = 0.066602
I0630 15:06:38.279915 47538 solver.cpp:244]     Train net output #0: loss = 0.070289 (* 1 = 0.070289 loss)
I0630 15:06:38.279929 47538 sgd_solver.cpp:106] Iteration 44400, lr = 5e-11
I0630 15:09:42.863672 47538 solver.cpp:228] Iteration 44500, loss = 0.0690372
I0630 15:09:42.864023 47538 solver.cpp:244]     Train net output #0: loss = 0.0726018 (* 1 = 0.0726018 loss)
I0630 15:09:42.864042 47538 sgd_solver.cpp:106] Iteration 44500, lr = 5e-11
I0630 15:12:51.328464 47538 solver.cpp:228] Iteration 44600, loss = 0.096112
I0630 15:12:51.328809 47538 solver.cpp:244]     Train net output #0: loss = 0.0829227 (* 1 = 0.0829227 loss)
I0630 15:12:51.328822 47538 sgd_solver.cpp:106] Iteration 44600, lr = 5e-11
I0630 15:15:55.485352 47538 solver.cpp:228] Iteration 44700, loss = 0.0806753
I0630 15:15:55.485740 47538 solver.cpp:244]     Train net output #0: loss = 0.0828999 (* 1 = 0.0828999 loss)
I0630 15:15:55.485769 47538 sgd_solver.cpp:106] Iteration 44700, lr = 5e-11
I0630 15:19:00.207631 47538 solver.cpp:228] Iteration 44800, loss = 0.064653
I0630 15:19:00.208161 47538 solver.cpp:244]     Train net output #0: loss = 0.0695042 (* 1 = 0.0695042 loss)
I0630 15:19:00.208184 47538 sgd_solver.cpp:106] Iteration 44800, lr = 5e-11
I0630 15:22:09.437443 47538 solver.cpp:228] Iteration 44900, loss = 0.0656021
I0630 15:22:09.437891 47538 solver.cpp:244]     Train net output #0: loss = 0.0707609 (* 1 = 0.0707609 loss)
I0630 15:22:09.437925 47538 sgd_solver.cpp:106] Iteration 44900, lr = 5e-11
I0630 15:25:12.121779 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_45000.caffemodel
I0630 15:25:13.084069 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_45000.solverstate
I0630 15:25:13.826017 47538 solver.cpp:337] Iteration 45000, Testing net (#0)
I0630 15:28:03.225039 47538 solver.cpp:404]     Test net output #0: accuracy = 0.959704
I0630 15:28:03.226684 47538 solver.cpp:404]     Test net output #1: loss = 0.0703069 (* 1 = 0.0703069 loss)
I0630 15:28:05.426898 47538 solver.cpp:228] Iteration 45000, loss = 0.0737858
I0630 15:28:05.426985 47538 solver.cpp:244]     Train net output #0: loss = 0.0647445 (* 1 = 0.0647445 loss)
I0630 15:28:05.427000 47538 sgd_solver.cpp:106] Iteration 45000, lr = 5e-12
I0630 15:31:08.210986 47538 solver.cpp:228] Iteration 45100, loss = 0.07427
I0630 15:31:08.211400 47538 solver.cpp:244]     Train net output #0: loss = 0.0665832 (* 1 = 0.0665832 loss)
I0630 15:31:08.211421 47538 sgd_solver.cpp:106] Iteration 45100, lr = 5e-12
I0630 15:34:12.489174 47538 solver.cpp:228] Iteration 45200, loss = 0.0693224
I0630 15:34:12.490402 47538 solver.cpp:244]     Train net output #0: loss = 0.0704632 (* 1 = 0.0704632 loss)
I0630 15:34:12.490418 47538 sgd_solver.cpp:106] Iteration 45200, lr = 5e-12
I0630 15:37:16.503610 47538 solver.cpp:228] Iteration 45300, loss = 0.0773563
I0630 15:37:16.505394 47538 solver.cpp:244]     Train net output #0: loss = 0.0955222 (* 1 = 0.0955222 loss)
I0630 15:37:16.505424 47538 sgd_solver.cpp:106] Iteration 45300, lr = 5e-12
I0630 15:40:20.856365 47538 solver.cpp:228] Iteration 45400, loss = 0.0711126
I0630 15:40:20.856797 47538 solver.cpp:244]     Train net output #0: loss = 0.0774235 (* 1 = 0.0774235 loss)
I0630 15:40:20.856827 47538 sgd_solver.cpp:106] Iteration 45400, lr = 5e-12
I0630 15:43:26.107121 47538 solver.cpp:228] Iteration 45500, loss = 0.0667265
I0630 15:43:26.107523 47538 solver.cpp:244]     Train net output #0: loss = 0.0694976 (* 1 = 0.0694976 loss)
I0630 15:43:26.107558 47538 sgd_solver.cpp:106] Iteration 45500, lr = 5e-12
I0630 15:46:30.290413 47538 solver.cpp:228] Iteration 45600, loss = 0.0696014
I0630 15:46:30.291294 47538 solver.cpp:244]     Train net output #0: loss = 0.0758742 (* 1 = 0.0758742 loss)
I0630 15:46:30.291313 47538 sgd_solver.cpp:106] Iteration 45600, lr = 5e-12
I0630 15:49:34.784278 47538 solver.cpp:228] Iteration 45700, loss = 0.0791171
I0630 15:49:34.784662 47538 solver.cpp:244]     Train net output #0: loss = 0.079911 (* 1 = 0.079911 loss)
I0630 15:49:34.784679 47538 sgd_solver.cpp:106] Iteration 45700, lr = 5e-12
I0630 15:52:40.227262 47538 solver.cpp:228] Iteration 45800, loss = 0.0796419
I0630 15:52:40.227653 47538 solver.cpp:244]     Train net output #0: loss = 0.0821198 (* 1 = 0.0821198 loss)
I0630 15:52:40.227669 47538 sgd_solver.cpp:106] Iteration 45800, lr = 5e-12
I0630 15:55:45.316910 47538 solver.cpp:228] Iteration 45900, loss = 0.0677473
I0630 15:55:45.320147 47538 solver.cpp:244]     Train net output #0: loss = 0.0641714 (* 1 = 0.0641714 loss)
I0630 15:55:45.320161 47538 sgd_solver.cpp:106] Iteration 45900, lr = 5e-12
I0630 15:58:49.329980 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_46000.caffemodel
I0630 15:58:50.244514 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_46000.solverstate
I0630 15:58:50.977841 47538 solver.cpp:337] Iteration 46000, Testing net (#0)
I0630 16:01:43.965498 47538 solver.cpp:404]     Test net output #0: accuracy = 0.959704
I0630 16:01:43.969025 47538 solver.cpp:404]     Test net output #1: loss = 0.0702006 (* 1 = 0.0702006 loss)
I0630 16:01:46.226729 47538 solver.cpp:228] Iteration 46000, loss = 0.075388
I0630 16:01:46.226788 47538 solver.cpp:244]     Train net output #0: loss = 0.0693424 (* 1 = 0.0693424 loss)
I0630 16:01:46.226804 47538 sgd_solver.cpp:106] Iteration 46000, lr = 5e-12
I0630 16:04:51.608867 47538 solver.cpp:228] Iteration 46100, loss = 0.0823896
I0630 16:04:51.611114 47538 solver.cpp:244]     Train net output #0: loss = 0.0582158 (* 1 = 0.0582158 loss)
I0630 16:04:51.611129 47538 sgd_solver.cpp:106] Iteration 46100, lr = 5e-12
I0630 16:07:57.787289 47538 solver.cpp:228] Iteration 46200, loss = 0.073424
I0630 16:07:57.787724 47538 solver.cpp:244]     Train net output #0: loss = 0.0771299 (* 1 = 0.0771299 loss)
I0630 16:07:57.787753 47538 sgd_solver.cpp:106] Iteration 46200, lr = 5e-12
I0630 16:11:02.474946 47538 solver.cpp:228] Iteration 46300, loss = 0.0719225
I0630 16:11:02.478467 47538 solver.cpp:244]     Train net output #0: loss = 0.0726949 (* 1 = 0.0726949 loss)
I0630 16:11:02.478484 47538 sgd_solver.cpp:106] Iteration 46300, lr = 5e-12
I0630 16:14:08.580408 47538 solver.cpp:228] Iteration 46400, loss = 0.0700286
I0630 16:14:08.583796 47538 solver.cpp:244]     Train net output #0: loss = 0.0639303 (* 1 = 0.0639303 loss)
I0630 16:14:08.583811 47538 sgd_solver.cpp:106] Iteration 46400, lr = 5e-12
I0630 16:17:14.002125 47538 solver.cpp:228] Iteration 46500, loss = 0.0715814
I0630 16:17:14.007256 47538 solver.cpp:244]     Train net output #0: loss = 0.0702823 (* 1 = 0.0702823 loss)
I0630 16:17:14.007272 47538 sgd_solver.cpp:106] Iteration 46500, lr = 5e-12
I0630 16:20:19.979033 47538 solver.cpp:228] Iteration 46600, loss = 0.0666041
I0630 16:20:19.979351 47538 solver.cpp:244]     Train net output #0: loss = 0.0576057 (* 1 = 0.0576057 loss)
I0630 16:20:19.979365 47538 sgd_solver.cpp:106] Iteration 46600, lr = 5e-12
I0630 16:23:26.252472 47538 solver.cpp:228] Iteration 46700, loss = 0.0666976
I0630 16:23:26.253975 47538 solver.cpp:244]     Train net output #0: loss = 0.066056 (* 1 = 0.066056 loss)
I0630 16:23:26.253993 47538 sgd_solver.cpp:106] Iteration 46700, lr = 5e-12
I0630 16:26:31.153079 47538 solver.cpp:228] Iteration 46800, loss = 0.0928141
I0630 16:26:31.155620 47538 solver.cpp:244]     Train net output #0: loss = 0.0607207 (* 1 = 0.0607207 loss)
I0630 16:26:31.155649 47538 sgd_solver.cpp:106] Iteration 46800, lr = 5e-12
I0630 16:29:36.663199 47538 solver.cpp:228] Iteration 46900, loss = 0.0691093
I0630 16:29:36.663586 47538 solver.cpp:244]     Train net output #0: loss = 0.0755188 (* 1 = 0.0755188 loss)
I0630 16:29:36.663602 47538 sgd_solver.cpp:106] Iteration 46900, lr = 5e-12
I0630 16:32:39.487437 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_47000.caffemodel
I0630 16:32:40.364897 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_47000.solverstate
I0630 16:32:41.108896 47538 solver.cpp:337] Iteration 47000, Testing net (#0)
I0630 16:35:34.297426 47538 solver.cpp:404]     Test net output #0: accuracy = 0.959702
I0630 16:35:34.300544 47538 solver.cpp:404]     Test net output #1: loss = 0.0702681 (* 1 = 0.0702681 loss)
I0630 16:35:36.523149 47538 solver.cpp:228] Iteration 47000, loss = 0.07422
I0630 16:35:36.523208 47538 solver.cpp:244]     Train net output #0: loss = 0.0753928 (* 1 = 0.0753928 loss)
I0630 16:35:36.523226 47538 sgd_solver.cpp:106] Iteration 47000, lr = 5e-12
I0630 16:38:40.789279 47538 solver.cpp:228] Iteration 47100, loss = 0.0699158
I0630 16:38:40.795127 47538 solver.cpp:244]     Train net output #0: loss = 0.0585906 (* 1 = 0.0585906 loss)
I0630 16:38:40.795164 47538 sgd_solver.cpp:106] Iteration 47100, lr = 5e-12
I0630 16:41:45.714706 47538 solver.cpp:228] Iteration 47200, loss = 0.0776457
I0630 16:41:45.715081 47538 solver.cpp:244]     Train net output #0: loss = 0.0730193 (* 1 = 0.0730193 loss)
I0630 16:41:45.715129 47538 sgd_solver.cpp:106] Iteration 47200, lr = 5e-12
I0630 16:44:51.033026 47538 solver.cpp:228] Iteration 47300, loss = 0.0665337
I0630 16:44:51.034457 47538 solver.cpp:244]     Train net output #0: loss = 0.0613864 (* 1 = 0.0613864 loss)
I0630 16:44:51.034476 47538 sgd_solver.cpp:106] Iteration 47300, lr = 5e-12
I0630 16:47:56.750586 47538 solver.cpp:228] Iteration 47400, loss = 0.0851468
I0630 16:47:56.750903 47538 solver.cpp:244]     Train net output #0: loss = 0.0940986 (* 1 = 0.0940986 loss)
I0630 16:47:56.750926 47538 sgd_solver.cpp:106] Iteration 47400, lr = 5e-12
I0630 16:51:02.244786 47538 solver.cpp:228] Iteration 47500, loss = 0.0772193
I0630 16:51:02.246510 47538 solver.cpp:244]     Train net output #0: loss = 0.0869421 (* 1 = 0.0869421 loss)
I0630 16:51:02.246528 47538 sgd_solver.cpp:106] Iteration 47500, lr = 5e-12
I0630 16:54:07.314913 47538 solver.cpp:228] Iteration 47600, loss = 0.0685716
I0630 16:54:07.315289 47538 solver.cpp:244]     Train net output #0: loss = 0.0629057 (* 1 = 0.0629057 loss)
I0630 16:54:07.315304 47538 sgd_solver.cpp:106] Iteration 47600, lr = 5e-12
I0630 16:57:12.300184 47538 solver.cpp:228] Iteration 47700, loss = 0.0815631
I0630 16:57:12.301563 47538 solver.cpp:244]     Train net output #0: loss = 0.0792936 (* 1 = 0.0792936 loss)
I0630 16:57:12.301580 47538 sgd_solver.cpp:106] Iteration 47700, lr = 5e-12
I0630 17:00:18.065078 47538 solver.cpp:228] Iteration 47800, loss = 0.0706703
I0630 17:00:18.065927 47538 solver.cpp:244]     Train net output #0: loss = 0.0790436 (* 1 = 0.0790436 loss)
I0630 17:00:18.065943 47538 sgd_solver.cpp:106] Iteration 47800, lr = 5e-12
I0630 17:03:22.802300 47538 solver.cpp:228] Iteration 47900, loss = 0.079522
I0630 17:03:22.805114 47538 solver.cpp:244]     Train net output #0: loss = 0.0738426 (* 1 = 0.0738426 loss)
I0630 17:03:22.805128 47538 sgd_solver.cpp:106] Iteration 47900, lr = 5e-12
I0630 17:06:25.668578 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_48000.caffemodel
I0630 17:06:26.584444 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_48000.solverstate
I0630 17:06:27.318671 47538 solver.cpp:337] Iteration 48000, Testing net (#0)
I0630 17:09:20.006110 47538 solver.cpp:404]     Test net output #0: accuracy = 0.959719
I0630 17:09:20.006495 47538 solver.cpp:404]     Test net output #1: loss = 0.0702841 (* 1 = 0.0702841 loss)
I0630 17:09:22.179591 47538 solver.cpp:228] Iteration 48000, loss = 0.0875864
I0630 17:09:22.179666 47538 solver.cpp:244]     Train net output #0: loss = 0.0786177 (* 1 = 0.0786177 loss)
I0630 17:09:22.179682 47538 sgd_solver.cpp:106] Iteration 48000, lr = 5e-12
I0630 17:12:26.772614 47538 solver.cpp:228] Iteration 48100, loss = 0.0690316
I0630 17:12:26.775535 47538 solver.cpp:244]     Train net output #0: loss = 0.0666176 (* 1 = 0.0666176 loss)
I0630 17:12:26.775549 47538 sgd_solver.cpp:106] Iteration 48100, lr = 5e-12
I0630 17:15:31.870425 47538 solver.cpp:228] Iteration 48200, loss = 0.0750939
I0630 17:15:31.872123 47538 solver.cpp:244]     Train net output #0: loss = 0.0810524 (* 1 = 0.0810524 loss)
I0630 17:15:31.872138 47538 sgd_solver.cpp:106] Iteration 48200, lr = 5e-12
I0630 17:18:36.795262 47538 solver.cpp:228] Iteration 48300, loss = 0.066743
I0630 17:18:36.796453 47538 solver.cpp:244]     Train net output #0: loss = 0.0667274 (* 1 = 0.0667274 loss)
I0630 17:18:36.796468 47538 sgd_solver.cpp:106] Iteration 48300, lr = 5e-12
I0630 17:21:42.172526 47538 solver.cpp:228] Iteration 48400, loss = 0.064158
I0630 17:21:42.172835 47538 solver.cpp:244]     Train net output #0: loss = 0.05708 (* 1 = 0.05708 loss)
I0630 17:21:42.172849 47538 sgd_solver.cpp:106] Iteration 48400, lr = 5e-12
I0630 17:24:47.294153 47538 solver.cpp:228] Iteration 48500, loss = 0.0810306
I0630 17:24:47.294438 47538 solver.cpp:244]     Train net output #0: loss = 0.065971 (* 1 = 0.065971 loss)
I0630 17:24:47.294454 47538 sgd_solver.cpp:106] Iteration 48500, lr = 5e-12
I0630 17:27:52.002490 47538 solver.cpp:228] Iteration 48600, loss = 0.078879
I0630 17:27:52.004366 47538 solver.cpp:244]     Train net output #0: loss = 0.0745092 (* 1 = 0.0745092 loss)
I0630 17:27:52.004380 47538 sgd_solver.cpp:106] Iteration 48600, lr = 5e-12
I0630 17:30:56.128584 47538 solver.cpp:228] Iteration 48700, loss = 0.0781247
I0630 17:30:56.133386 47538 solver.cpp:244]     Train net output #0: loss = 0.0720932 (* 1 = 0.0720932 loss)
I0630 17:30:56.133406 47538 sgd_solver.cpp:106] Iteration 48700, lr = 5e-12
I0630 17:34:01.159165 47538 solver.cpp:228] Iteration 48800, loss = 0.0823685
I0630 17:34:01.159435 47538 solver.cpp:244]     Train net output #0: loss = 0.0938177 (* 1 = 0.0938177 loss)
I0630 17:34:01.159451 47538 sgd_solver.cpp:106] Iteration 48800, lr = 5e-12
I0630 17:37:06.305939 47538 solver.cpp:228] Iteration 48900, loss = 0.0785369
I0630 17:37:06.306571 47538 solver.cpp:244]     Train net output #0: loss = 0.0711602 (* 1 = 0.0711602 loss)
I0630 17:37:06.306603 47538 sgd_solver.cpp:106] Iteration 48900, lr = 5e-12
I0630 17:40:09.211428 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_49000.caffemodel
I0630 17:40:10.094525 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_49000.solverstate
I0630 17:40:10.873186 47538 solver.cpp:337] Iteration 49000, Testing net (#0)
I0630 17:43:04.236181 47538 solver.cpp:404]     Test net output #0: accuracy = 0.959747
I0630 17:43:04.236600 47538 solver.cpp:404]     Test net output #1: loss = 0.0700881 (* 1 = 0.0700881 loss)
I0630 17:43:06.527367 47538 solver.cpp:228] Iteration 49000, loss = 0.0722372
I0630 17:43:06.527443 47538 solver.cpp:244]     Train net output #0: loss = 0.0608721 (* 1 = 0.0608721 loss)
I0630 17:43:06.527460 47538 sgd_solver.cpp:106] Iteration 49000, lr = 5e-12
I0630 17:46:10.880879 47538 solver.cpp:228] Iteration 49100, loss = 0.0738726
I0630 17:46:10.881163 47538 solver.cpp:244]     Train net output #0: loss = 0.0673907 (* 1 = 0.0673907 loss)
I0630 17:46:10.881191 47538 sgd_solver.cpp:106] Iteration 49100, lr = 5e-12
I0630 17:49:16.225061 47538 solver.cpp:228] Iteration 49200, loss = 0.10642
I0630 17:49:16.226812 47538 solver.cpp:244]     Train net output #0: loss = 0.0886671 (* 1 = 0.0886671 loss)
I0630 17:49:16.226830 47538 sgd_solver.cpp:106] Iteration 49200, lr = 5e-12
I0630 17:52:22.809126 47538 solver.cpp:228] Iteration 49300, loss = 0.0738425
I0630 17:52:22.812018 47538 solver.cpp:244]     Train net output #0: loss = 0.0673546 (* 1 = 0.0673546 loss)
I0630 17:52:22.812034 47538 sgd_solver.cpp:106] Iteration 49300, lr = 5e-12
I0630 17:55:29.560565 47538 solver.cpp:228] Iteration 49400, loss = 0.073407
I0630 17:55:29.560930 47538 solver.cpp:244]     Train net output #0: loss = 0.083364 (* 1 = 0.083364 loss)
I0630 17:55:29.560947 47538 sgd_solver.cpp:106] Iteration 49400, lr = 5e-12
I0630 17:58:34.721433 47538 solver.cpp:228] Iteration 49500, loss = 0.0789471
I0630 17:58:34.722942 47538 solver.cpp:244]     Train net output #0: loss = 0.0818323 (* 1 = 0.0818323 loss)
I0630 17:58:34.722961 47538 sgd_solver.cpp:106] Iteration 49500, lr = 5e-12
I0630 18:01:39.647497 47538 solver.cpp:228] Iteration 49600, loss = 0.0645629
I0630 18:01:39.649030 47538 solver.cpp:244]     Train net output #0: loss = 0.0726098 (* 1 = 0.0726098 loss)
I0630 18:01:39.649046 47538 sgd_solver.cpp:106] Iteration 49600, lr = 5e-12
I0630 18:04:44.138829 47538 solver.cpp:228] Iteration 49700, loss = 0.0735143
I0630 18:04:44.142154 47538 solver.cpp:244]     Train net output #0: loss = 0.0715762 (* 1 = 0.0715762 loss)
I0630 18:04:44.142172 47538 sgd_solver.cpp:106] Iteration 49700, lr = 5e-12
I0630 18:07:50.366372 47538 solver.cpp:228] Iteration 49800, loss = 0.0751689
I0630 18:07:50.368319 47538 solver.cpp:244]     Train net output #0: loss = 0.0730068 (* 1 = 0.0730068 loss)
I0630 18:07:50.368333 47538 sgd_solver.cpp:106] Iteration 49800, lr = 5e-12
I0630 18:10:56.309963 47538 solver.cpp:228] Iteration 49900, loss = 0.071285
I0630 18:10:56.310549 47538 solver.cpp:244]     Train net output #0: loss = 0.0623471 (* 1 = 0.0623471 loss)
I0630 18:10:56.310580 47538 sgd_solver.cpp:106] Iteration 49900, lr = 5e-12
I0630 18:14:00.807386 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_50000.caffemodel
I0630 18:14:01.655891 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_50000.solverstate
I0630 18:14:02.406898 47538 solver.cpp:337] Iteration 50000, Testing net (#0)
I0630 18:16:56.814064 47538 solver.cpp:404]     Test net output #0: accuracy = 0.959705
I0630 18:16:56.816756 47538 solver.cpp:404]     Test net output #1: loss = 0.0703551 (* 1 = 0.0703551 loss)
I0630 18:16:59.071897 47538 solver.cpp:228] Iteration 50000, loss = 0.0678417
I0630 18:16:59.071985 47538 solver.cpp:244]     Train net output #0: loss = 0.0647469 (* 1 = 0.0647469 loss)
I0630 18:16:59.072011 47538 sgd_solver.cpp:106] Iteration 50000, lr = 5e-13
I0630 18:20:02.712283 47538 solver.cpp:228] Iteration 50100, loss = 0.0716748
I0630 18:20:02.712636 47538 solver.cpp:244]     Train net output #0: loss = 0.0687084 (* 1 = 0.0687084 loss)
I0630 18:20:02.712653 47538 sgd_solver.cpp:106] Iteration 50100, lr = 5e-13
I0630 18:23:07.836539 47538 solver.cpp:228] Iteration 50200, loss = 0.0710509
I0630 18:23:07.839721 47538 solver.cpp:244]     Train net output #0: loss = 0.0705654 (* 1 = 0.0705654 loss)
I0630 18:23:07.839756 47538 sgd_solver.cpp:106] Iteration 50200, lr = 5e-13
I0630 18:26:12.627568 47538 solver.cpp:228] Iteration 50300, loss = 0.0624724
I0630 18:26:12.628623 47538 solver.cpp:244]     Train net output #0: loss = 0.0552263 (* 1 = 0.0552263 loss)
I0630 18:26:12.628664 47538 sgd_solver.cpp:106] Iteration 50300, lr = 5e-13
I0630 18:29:18.345909 47538 solver.cpp:228] Iteration 50400, loss = 0.0637035
I0630 18:29:18.346541 47538 solver.cpp:244]     Train net output #0: loss = 0.0674815 (* 1 = 0.0674815 loss)
I0630 18:29:18.346556 47538 sgd_solver.cpp:106] Iteration 50400, lr = 5e-13
I0630 18:32:24.182199 47538 solver.cpp:228] Iteration 50500, loss = 0.072961
I0630 18:32:24.182924 47538 solver.cpp:244]     Train net output #0: loss = 0.0719245 (* 1 = 0.0719245 loss)
I0630 18:32:24.182945 47538 sgd_solver.cpp:106] Iteration 50500, lr = 5e-13
I0630 18:35:28.464380 47538 solver.cpp:228] Iteration 50600, loss = 0.0804875
I0630 18:35:28.464728 47538 solver.cpp:244]     Train net output #0: loss = 0.0723285 (* 1 = 0.0723285 loss)
I0630 18:35:28.464753 47538 sgd_solver.cpp:106] Iteration 50600, lr = 5e-13
I0630 18:38:34.022819 47538 solver.cpp:228] Iteration 50700, loss = 0.0759501
I0630 18:38:34.024466 47538 solver.cpp:244]     Train net output #0: loss = 0.0746612 (* 1 = 0.0746612 loss)
I0630 18:38:34.024483 47538 sgd_solver.cpp:106] Iteration 50700, lr = 5e-13
I0630 18:41:39.756193 47538 solver.cpp:228] Iteration 50800, loss = 0.0779662
I0630 18:41:39.756881 47538 solver.cpp:244]     Train net output #0: loss = 0.062427 (* 1 = 0.062427 loss)
I0630 18:41:39.756898 47538 sgd_solver.cpp:106] Iteration 50800, lr = 5e-13
I0630 18:44:44.290506 47538 solver.cpp:228] Iteration 50900, loss = 0.0797354
I0630 18:44:44.291728 47538 solver.cpp:244]     Train net output #0: loss = 0.0700684 (* 1 = 0.0700684 loss)
I0630 18:44:44.291744 47538 sgd_solver.cpp:106] Iteration 50900, lr = 5e-13
I0630 18:47:47.515094 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_51000.caffemodel
I0630 18:47:48.410354 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_51000.solverstate
I0630 18:47:49.172570 47538 solver.cpp:337] Iteration 51000, Testing net (#0)
I0630 18:50:44.473789 47538 solver.cpp:404]     Test net output #0: accuracy = 0.95967
I0630 18:50:44.477141 47538 solver.cpp:404]     Test net output #1: loss = 0.0702207 (* 1 = 0.0702207 loss)
I0630 18:50:46.655432 47538 solver.cpp:228] Iteration 51000, loss = 0.0785804
I0630 18:50:46.655488 47538 solver.cpp:244]     Train net output #0: loss = 0.0899751 (* 1 = 0.0899751 loss)
I0630 18:50:46.655505 47538 sgd_solver.cpp:106] Iteration 51000, lr = 5e-13
I0630 18:53:51.638639 47538 solver.cpp:228] Iteration 51100, loss = 0.0730142
I0630 18:53:51.639021 47538 solver.cpp:244]     Train net output #0: loss = 0.061776 (* 1 = 0.061776 loss)
I0630 18:53:51.639040 47538 sgd_solver.cpp:106] Iteration 51100, lr = 5e-13
I0630 18:56:57.490577 47538 solver.cpp:228] Iteration 51200, loss = 0.0716352
I0630 18:56:57.496377 47538 solver.cpp:244]     Train net output #0: loss = 0.0749375 (* 1 = 0.0749375 loss)
I0630 18:56:57.496397 47538 sgd_solver.cpp:106] Iteration 51200, lr = 5e-13
I0630 19:00:03.093288 47538 solver.cpp:228] Iteration 51300, loss = 0.070129
I0630 19:00:03.093664 47538 solver.cpp:244]     Train net output #0: loss = 0.0664207 (* 1 = 0.0664207 loss)
I0630 19:00:03.093690 47538 sgd_solver.cpp:106] Iteration 51300, lr = 5e-13
I0630 19:03:08.092342 47538 solver.cpp:228] Iteration 51400, loss = 0.07795
I0630 19:03:08.094746 47538 solver.cpp:244]     Train net output #0: loss = 0.0777245 (* 1 = 0.0777245 loss)
I0630 19:03:08.094779 47538 sgd_solver.cpp:106] Iteration 51400, lr = 5e-13
I0630 19:06:13.708521 47538 solver.cpp:228] Iteration 51500, loss = 0.071633
I0630 19:06:13.710376 47538 solver.cpp:244]     Train net output #0: loss = 0.0742562 (* 1 = 0.0742562 loss)
I0630 19:06:13.710397 47538 sgd_solver.cpp:106] Iteration 51500, lr = 5e-13
I0630 19:09:19.137600 47538 solver.cpp:228] Iteration 51600, loss = 0.0737057
I0630 19:09:19.139077 47538 solver.cpp:244]     Train net output #0: loss = 0.0743735 (* 1 = 0.0743735 loss)
I0630 19:09:19.139093 47538 sgd_solver.cpp:106] Iteration 51600, lr = 5e-13
I0630 19:12:24.284209 47538 solver.cpp:228] Iteration 51700, loss = 0.0852502
I0630 19:12:24.287030 47538 solver.cpp:244]     Train net output #0: loss = 0.129042 (* 1 = 0.129042 loss)
I0630 19:12:24.287056 47538 sgd_solver.cpp:106] Iteration 51700, lr = 5e-13
I0630 19:15:29.795038 47538 solver.cpp:228] Iteration 51800, loss = 0.0667013
I0630 19:15:29.797300 47538 solver.cpp:244]     Train net output #0: loss = 0.0651087 (* 1 = 0.0651087 loss)
I0630 19:15:29.797328 47538 sgd_solver.cpp:106] Iteration 51800, lr = 5e-13
I0630 19:18:34.574327 47538 solver.cpp:228] Iteration 51900, loss = 0.0834871
I0630 19:18:34.574546 47538 solver.cpp:244]     Train net output #0: loss = 0.0703577 (* 1 = 0.0703577 loss)
I0630 19:18:34.574563 47538 sgd_solver.cpp:106] Iteration 51900, lr = 5e-13
I0630 19:21:36.580447 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_52000.caffemodel
I0630 19:21:37.462044 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_52000.solverstate
I0630 19:21:38.202011 47538 solver.cpp:337] Iteration 52000, Testing net (#0)
I0630 19:24:32.553822 47538 solver.cpp:404]     Test net output #0: accuracy = 0.959733
I0630 19:24:32.556897 47538 solver.cpp:404]     Test net output #1: loss = 0.0701859 (* 1 = 0.0701859 loss)
I0630 19:24:34.645829 47538 solver.cpp:228] Iteration 52000, loss = 0.0770267
I0630 19:24:34.645886 47538 solver.cpp:244]     Train net output #0: loss = 0.0925299 (* 1 = 0.0925299 loss)
I0630 19:24:34.645902 47538 sgd_solver.cpp:106] Iteration 52000, lr = 5e-13
I0630 19:27:39.159890 47538 solver.cpp:228] Iteration 52100, loss = 0.0685687
I0630 19:27:39.162034 47538 solver.cpp:244]     Train net output #0: loss = 0.0611015 (* 1 = 0.0611015 loss)
I0630 19:27:39.162050 47538 sgd_solver.cpp:106] Iteration 52100, lr = 5e-13
I0630 19:30:44.329701 47538 solver.cpp:228] Iteration 52200, loss = 0.0729295
I0630 19:30:44.331239 47538 solver.cpp:244]     Train net output #0: loss = 0.0664586 (* 1 = 0.0664586 loss)
I0630 19:30:44.331255 47538 sgd_solver.cpp:106] Iteration 52200, lr = 5e-13
I0630 19:33:49.480788 47538 solver.cpp:228] Iteration 52300, loss = 0.0667609
I0630 19:33:49.481026 47538 solver.cpp:244]     Train net output #0: loss = 0.0588355 (* 1 = 0.0588355 loss)
I0630 19:33:49.481042 47538 sgd_solver.cpp:106] Iteration 52300, lr = 5e-13
I0630 19:36:55.510543 47538 solver.cpp:228] Iteration 52400, loss = 0.0692865
I0630 19:36:55.510807 47538 solver.cpp:244]     Train net output #0: loss = 0.0666909 (* 1 = 0.0666909 loss)
I0630 19:36:55.510826 47538 sgd_solver.cpp:106] Iteration 52400, lr = 5e-13
I0630 19:40:00.562811 47538 solver.cpp:228] Iteration 52500, loss = 0.0757449
I0630 19:40:00.563005 47538 solver.cpp:244]     Train net output #0: loss = 0.0694683 (* 1 = 0.0694683 loss)
I0630 19:40:00.563021 47538 sgd_solver.cpp:106] Iteration 52500, lr = 5e-13
I0630 19:43:04.666036 47538 solver.cpp:228] Iteration 52600, loss = 0.0733829
I0630 19:43:04.667937 47538 solver.cpp:244]     Train net output #0: loss = 0.0822121 (* 1 = 0.0822121 loss)
I0630 19:43:04.667956 47538 sgd_solver.cpp:106] Iteration 52600, lr = 5e-13
I0630 19:46:10.040136 47538 solver.cpp:228] Iteration 52700, loss = 0.0641591
I0630 19:46:10.040446 47538 solver.cpp:244]     Train net output #0: loss = 0.0653062 (* 1 = 0.0653062 loss)
I0630 19:46:10.040462 47538 sgd_solver.cpp:106] Iteration 52700, lr = 5e-13
I0630 19:49:15.351791 47538 solver.cpp:228] Iteration 52800, loss = 0.0780398
I0630 19:49:15.354131 47538 solver.cpp:244]     Train net output #0: loss = 0.0896735 (* 1 = 0.0896735 loss)
I0630 19:49:15.354147 47538 sgd_solver.cpp:106] Iteration 52800, lr = 5e-13
I0630 19:52:20.461575 47538 solver.cpp:228] Iteration 52900, loss = 0.0874875
I0630 19:52:20.464112 47538 solver.cpp:244]     Train net output #0: loss = 0.114154 (* 1 = 0.114154 loss)
I0630 19:52:20.464136 47538 sgd_solver.cpp:106] Iteration 52900, lr = 5e-13
I0630 19:55:23.214963 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_53000.caffemodel
I0630 19:55:24.068780 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_53000.solverstate
I0630 19:55:24.805169 47538 solver.cpp:337] Iteration 53000, Testing net (#0)
I0630 19:58:17.843509 47538 solver.cpp:404]     Test net output #0: accuracy = 0.959733
I0630 19:58:17.845013 47538 solver.cpp:404]     Test net output #1: loss = 0.0701879 (* 1 = 0.0701879 loss)
I0630 19:58:20.163990 47538 solver.cpp:228] Iteration 53000, loss = 0.07019
I0630 19:58:20.164048 47538 solver.cpp:244]     Train net output #0: loss = 0.0690596 (* 1 = 0.0690596 loss)
I0630 19:58:20.164064 47538 sgd_solver.cpp:106] Iteration 53000, lr = 5e-13
I0630 20:01:24.135315 47538 solver.cpp:228] Iteration 53100, loss = 0.081371
I0630 20:01:24.136472 47538 solver.cpp:244]     Train net output #0: loss = 0.073475 (* 1 = 0.073475 loss)
I0630 20:01:24.136487 47538 sgd_solver.cpp:106] Iteration 53100, lr = 5e-13
I0630 20:04:29.469120 47538 solver.cpp:228] Iteration 53200, loss = 0.26155
I0630 20:04:29.469529 47538 solver.cpp:244]     Train net output #0: loss = 0.0853131 (* 1 = 0.0853131 loss)
I0630 20:04:29.469568 47538 sgd_solver.cpp:106] Iteration 53200, lr = 5e-13
I0630 20:07:35.009168 47538 solver.cpp:228] Iteration 53300, loss = 0.0705886
I0630 20:07:35.011029 47538 solver.cpp:244]     Train net output #0: loss = 0.0674163 (* 1 = 0.0674163 loss)
I0630 20:07:35.011045 47538 sgd_solver.cpp:106] Iteration 53300, lr = 5e-13
I0630 20:10:40.812949 47538 solver.cpp:228] Iteration 53400, loss = 0.0726027
I0630 20:10:40.815274 47538 solver.cpp:244]     Train net output #0: loss = 0.0745897 (* 1 = 0.0745897 loss)
I0630 20:10:40.815290 47538 sgd_solver.cpp:106] Iteration 53400, lr = 5e-13
I0630 20:13:46.051168 47538 solver.cpp:228] Iteration 53500, loss = 0.087008
I0630 20:13:46.052379 47538 solver.cpp:244]     Train net output #0: loss = 0.0799753 (* 1 = 0.0799753 loss)
I0630 20:13:46.052395 47538 sgd_solver.cpp:106] Iteration 53500, lr = 5e-13
I0630 20:16:51.381340 47538 solver.cpp:228] Iteration 53600, loss = 0.0750865
I0630 20:16:51.381834 47538 solver.cpp:244]     Train net output #0: loss = 0.0697654 (* 1 = 0.0697654 loss)
I0630 20:16:51.381850 47538 sgd_solver.cpp:106] Iteration 53600, lr = 5e-13
I0630 20:19:57.009799 47538 solver.cpp:228] Iteration 53700, loss = 0.0704791
I0630 20:19:57.011353 47538 solver.cpp:244]     Train net output #0: loss = 0.0719401 (* 1 = 0.0719401 loss)
I0630 20:19:57.011369 47538 sgd_solver.cpp:106] Iteration 53700, lr = 5e-13
I0630 20:23:02.503576 47538 solver.cpp:228] Iteration 53800, loss = 0.0826458
I0630 20:23:02.504447 47538 solver.cpp:244]     Train net output #0: loss = 0.0804798 (* 1 = 0.0804798 loss)
I0630 20:23:02.504463 47538 sgd_solver.cpp:106] Iteration 53800, lr = 5e-13
I0630 20:26:08.342011 47538 solver.cpp:228] Iteration 53900, loss = 0.0711375
I0630 20:26:08.344050 47538 solver.cpp:244]     Train net output #0: loss = 0.0737089 (* 1 = 0.0737089 loss)
I0630 20:26:08.344069 47538 sgd_solver.cpp:106] Iteration 53900, lr = 5e-13
I0630 20:27:54.292476 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_53958.caffemodel
I0630 20:27:55.187139 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_53958.solverstate
I0630 20:29:12.920023 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_54000.caffemodel
I0630 20:29:13.976722 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_54000.solverstate
I0630 20:29:14.728792 47538 solver.cpp:337] Iteration 54000, Testing net (#0)
I0630 20:32:07.481732 47538 solver.cpp:404]     Test net output #0: accuracy = 0.959701
I0630 20:32:07.484532 47538 solver.cpp:404]     Test net output #1: loss = 0.0702949 (* 1 = 0.0702949 loss)
I0630 20:32:09.599771 47538 solver.cpp:228] Iteration 54000, loss = 0.0787095
I0630 20:32:09.599843 47538 solver.cpp:244]     Train net output #0: loss = 0.0720238 (* 1 = 0.0720238 loss)
I0630 20:32:09.599862 47538 sgd_solver.cpp:106] Iteration 54000, lr = 5e-13
I0630 20:35:14.210741 47538 solver.cpp:228] Iteration 54100, loss = 0.0699889
I0630 20:35:14.213897 47538 solver.cpp:244]     Train net output #0: loss = 0.0645325 (* 1 = 0.0645325 loss)
I0630 20:35:14.213920 47538 sgd_solver.cpp:106] Iteration 54100, lr = 5e-13
I0630 20:38:19.727566 47538 solver.cpp:228] Iteration 54200, loss = 0.069471
I0630 20:38:19.729447 47538 solver.cpp:244]     Train net output #0: loss = 0.0671581 (* 1 = 0.0671581 loss)
I0630 20:38:19.729462 47538 sgd_solver.cpp:106] Iteration 54200, lr = 5e-13
I0630 20:41:26.192921 47538 solver.cpp:228] Iteration 54300, loss = 0.073769
I0630 20:41:26.193282 47538 solver.cpp:244]     Train net output #0: loss = 0.0719276 (* 1 = 0.0719276 loss)
I0630 20:41:26.193312 47538 sgd_solver.cpp:106] Iteration 54300, lr = 5e-13
I0630 20:44:32.067852 47538 solver.cpp:228] Iteration 54400, loss = 0.0684969
I0630 20:44:32.068310 47538 solver.cpp:244]     Train net output #0: loss = 0.0634878 (* 1 = 0.0634878 loss)
I0630 20:44:32.068325 47538 sgd_solver.cpp:106] Iteration 54400, lr = 5e-13
I0630 20:47:36.299160 47538 solver.cpp:228] Iteration 54500, loss = 0.0812293
I0630 20:47:36.301403 47538 solver.cpp:244]     Train net output #0: loss = 0.0845247 (* 1 = 0.0845247 loss)
I0630 20:47:36.301419 47538 sgd_solver.cpp:106] Iteration 54500, lr = 5e-13
I0630 20:50:42.158040 47538 solver.cpp:228] Iteration 54600, loss = 0.0660153
I0630 20:50:42.159291 47538 solver.cpp:244]     Train net output #0: loss = 0.0677766 (* 1 = 0.0677766 loss)
I0630 20:50:42.159307 47538 sgd_solver.cpp:106] Iteration 54600, lr = 5e-13
I0630 20:53:48.183951 47538 solver.cpp:228] Iteration 54700, loss = 0.0689568
I0630 20:53:48.185379 47538 solver.cpp:244]     Train net output #0: loss = 0.0605327 (* 1 = 0.0605327 loss)
I0630 20:53:48.185395 47538 sgd_solver.cpp:106] Iteration 54700, lr = 5e-13
I0630 20:56:53.511193 47538 solver.cpp:228] Iteration 54800, loss = 0.073618
I0630 20:56:53.514696 47538 solver.cpp:244]     Train net output #0: loss = 0.0741256 (* 1 = 0.0741256 loss)
I0630 20:56:53.514716 47538 sgd_solver.cpp:106] Iteration 54800, lr = 5e-13
I0630 20:59:59.163086 47538 solver.cpp:228] Iteration 54900, loss = 0.0891088
I0630 20:59:59.163313 47538 solver.cpp:244]     Train net output #0: loss = 0.105059 (* 1 = 0.105059 loss)
I0630 20:59:59.163328 47538 sgd_solver.cpp:106] Iteration 54900, lr = 5e-13
I0630 21:03:02.276129 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_55000.caffemodel
I0630 21:03:03.191635 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_55000.solverstate
I0630 21:03:03.939405 47538 solver.cpp:337] Iteration 55000, Testing net (#0)
I0630 21:05:58.869210 47538 solver.cpp:404]     Test net output #0: accuracy = 0.959577
I0630 21:05:58.870184 47538 solver.cpp:404]     Test net output #1: loss = 0.0707978 (* 1 = 0.0707978 loss)
I0630 21:06:01.129962 47538 solver.cpp:228] Iteration 55000, loss = 0.0736214
I0630 21:06:01.130021 47538 solver.cpp:244]     Train net output #0: loss = 0.0807392 (* 1 = 0.0807392 loss)
I0630 21:06:01.130038 47538 sgd_solver.cpp:106] Iteration 55000, lr = 5e-14
I0630 21:09:05.764976 47538 solver.cpp:228] Iteration 55100, loss = 0.0718959
I0630 21:09:05.765242 47538 solver.cpp:244]     Train net output #0: loss = 0.0815816 (* 1 = 0.0815816 loss)
I0630 21:09:05.765266 47538 sgd_solver.cpp:106] Iteration 55100, lr = 5e-14
I0630 21:12:11.292804 47538 solver.cpp:228] Iteration 55200, loss = 0.0828119
I0630 21:12:11.293027 47538 solver.cpp:244]     Train net output #0: loss = 0.0820835 (* 1 = 0.0820835 loss)
I0630 21:12:11.293042 47538 sgd_solver.cpp:106] Iteration 55200, lr = 5e-14
I0630 21:15:16.313427 47538 solver.cpp:228] Iteration 55300, loss = 0.0793001
I0630 21:15:16.314944 47538 solver.cpp:244]     Train net output #0: loss = 0.0866917 (* 1 = 0.0866917 loss)
I0630 21:15:16.314958 47538 sgd_solver.cpp:106] Iteration 55300, lr = 5e-14
I0630 21:18:21.274942 47538 solver.cpp:228] Iteration 55400, loss = 0.079279
I0630 21:18:21.275172 47538 solver.cpp:244]     Train net output #0: loss = 0.0691668 (* 1 = 0.0691668 loss)
I0630 21:18:21.275187 47538 sgd_solver.cpp:106] Iteration 55400, lr = 5e-14
I0630 21:21:26.108495 47538 solver.cpp:228] Iteration 55500, loss = 0.086311
I0630 21:21:26.110015 47538 solver.cpp:244]     Train net output #0: loss = 0.0747693 (* 1 = 0.0747693 loss)
I0630 21:21:26.110033 47538 sgd_solver.cpp:106] Iteration 55500, lr = 5e-14
I0630 21:24:31.957792 47538 solver.cpp:228] Iteration 55600, loss = 0.0688359
I0630 21:24:31.959530 47538 solver.cpp:244]     Train net output #0: loss = 0.0705068 (* 1 = 0.0705068 loss)
I0630 21:24:31.959547 47538 sgd_solver.cpp:106] Iteration 55600, lr = 5e-14
I0630 21:27:37.770328 47538 solver.cpp:228] Iteration 55700, loss = 0.0605706
I0630 21:27:37.771895 47538 solver.cpp:244]     Train net output #0: loss = 0.0607822 (* 1 = 0.0607822 loss)
I0630 21:27:37.771911 47538 sgd_solver.cpp:106] Iteration 55700, lr = 5e-14
I0630 21:30:43.203655 47538 solver.cpp:228] Iteration 55800, loss = 0.0837524
I0630 21:30:43.204769 47538 solver.cpp:244]     Train net output #0: loss = 0.0835106 (* 1 = 0.0835106 loss)
I0630 21:30:43.204783 47538 sgd_solver.cpp:106] Iteration 55800, lr = 5e-14
I0630 21:33:48.873458 47538 solver.cpp:228] Iteration 55900, loss = 0.0725675
I0630 21:33:48.875183 47538 solver.cpp:244]     Train net output #0: loss = 0.0610861 (* 1 = 0.0610861 loss)
I0630 21:33:48.875213 47538 sgd_solver.cpp:106] Iteration 55900, lr = 5e-14
I0630 21:36:52.220330 47538 solver.cpp:454] Snapshotting to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_56000.caffemodel
I0630 21:36:53.105897 47538 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /shenlab/lab_stor6/suny/infant/Model32_32_32_n1000_r15_nomo-retrain-BCP-18/train-9/_iter_56000.solverstate
I0630 21:36:53.906756 47538 solver.cpp:337] Iteration 56000, Testing net (#0)
I0630 21:39:46.927997 47538 solver.cpp:404]     Test net output #0: accuracy = 0.95977
I0630 21:39:46.928834 47538 solver.cpp:404]     Test net output #1: loss = 0.0700565 (* 1 = 0.0700565 loss)
I0630 21:39:49.249464 47538 solver.cpp:228] Iteration 56000, loss = 0.0672206
I0630 21:39:49.249523 47538 solver.cpp:244]     Train net output #0: loss = 0.059089 (* 1 = 0.059089 loss)
I0630 21:39:49.249537 47538 sgd_solver.cpp:106] Iteration 56000, lr = 5e-14
I0630 21:42:53.562932 47538 solver.cpp:228] Iteration 56100, loss = 0.0665216
I0630 21:42:53.565136 47538 solver.cpp:244]     Train net output #0: loss = 0.068667 (* 1 = 0.068667 loss)
I0630 21:42:53.565176 47538 sgd_solver.cpp:106] Iteration 56100, lr = 5e-14
I0630 21:45:59.804867 47538 solver.cpp:228] Iteration 56200, loss = 0.0667032
I0630 21:45:59.806206 47538 solver.cpp:244]     Train net output #0: loss = 0.0648689 (* 1 = 0.0648689 loss)
I0630 21:45:59.806221 47538 sgd_solver.cpp:106] Iteration 56200, lr = 5e-14
I0630 21:49:05.789710 47538 solver.cpp:228] Iteration 56300, loss = 0.0707604
I0630 21:49:05.793026 47538 solver.cpp:244]     Train net output #0: loss = 0.0619411 (* 1 = 0.0619411 loss)
I0630 21:49:05.793049 47538 sgd_solver.cpp:106] Iteration 56300, lr = 5e-14
I0630 21:52:11.258113 47538 solver.cpp:228] Iteration 56400, loss = 0.0703994
I0630 21:52:11.260083 47538 solver.cpp:244]     Train net output #0: loss = 0.0682551 (* 1 = 0.0682551 loss)
I0630 21:52:11.260108 47538 sgd_solver.cpp:106] Iteration 56400, lr = 5e-14
*** Aborted at 1593568424 (unix time) try "date -d @1593568424" if you are using GNU date ***
PC: @     0x7ffef37e8b30 ([vdso]+0xb2f)
*** SIGTERM (@0x4e6eb00001f3f) received by PID 47538 (TID 0x7f5c69c20b00) from PID 7999; stack trace: ***
    @     0x7f5c679a04b0 (unknown)
    @     0x7ffef37e8b30 ([vdso]+0xb2f)
    @     0x7f5c67a80876 __clock_gettime
    @     0x7f5c3f26d24e (unknown)
    @     0x7f5c3f300965 (unknown)
    @     0x7f5c3f258363 (unknown)
    @     0x7f5c3f24ae0d (unknown)
    @     0x7f5c3f24c27a (unknown)
    @     0x7f5c3f162d34 (unknown)
    @     0x7f5c3f163350 (unknown)
    @     0x7f5c3f2b4af5 cuMemcpy
    @     0x7f5c69128a72 (unknown)
    @     0x7f5c69104c51 (unknown)
    @     0x7f5c6912eb28 cudaMemcpy
    @     0x7f5c696ee1c0 caffe::caffe_gpu_memcpy()
    @     0x7f5c694f3a80 caffe::SyncedMemory::to_gpu()
    @     0x7f5c694f2c19 caffe::SyncedMemory::gpu_data()
    @     0x7f5c69501362 caffe::Blob<>::gpu_data()
    @     0x7f5c69664f83 caffe::SGDSolver<>::Regularize()
    @     0x7f5c69663486 caffe::SGDSolver<>::ApplyUpdate()
    @     0x7f5c69684fb6 caffe::Solver<>::Step()
    @     0x7f5c69685939 caffe::Solver<>::Solve()
    @           0x40bae7 train()
    @           0x407704 main
    @     0x7f5c6798b830 __libc_start_main
    @           0x407eb9 _start
    @                0x0 (unknown)
resume_training.sh: line 3: 47538 Terminated              /home/yuesun/caffe3/build/tools/caffe train --solver=solver.prototxt -gpu 6 --snapshot=_iter_44000.solverstate
